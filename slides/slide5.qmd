---
title: Modelling with categorical predictors
description: "[Slide 5]{.tag-workshop}"
format: anu-light-revealjs
image: /images/slide5-cover.jpeg
date: 2025/02/19
webr:
  packages:
    - ggplot2
    - dplyr
    - abd
    - skimr
    - agridat
    - emmeans
---




## [Revisiting carbon dioxide and growth rate in algae]{.page-data}

```{r}
#| include: false
source("setup.R")
```
<div style="display:none;">{{< fa thumbs-up >}}</div>


```{webr}
#| autorun: true
#| include: false
library(tidyverse)
theme_set(theme_bw(base_size = 24))
options(width = 75)
```

::: {.columns}
::: {.column width="50%"}

- Growth rates of 14 unicellular alga _Chlamydomonas_ after 1,000 generations of selection under `High` and `Normal` levels of carbon dioxide were examined.

::: f2

```{webr}
#| autorun: true
#| fig-width: 6
#| fig-height: 6
AlgaeCO2 |> 
  summarise(n = n(),
            mean = mean(growthrate),
            sd = sd(growthrate),
            .by = treatment) 
```

:::

:::

::: {.column width="50%" .f2}

```{webr}
#| autorun: true
#| fig-width: 6
#| fig-height: 6
data(AlgaeCO2, package = "abd")
ggplot(AlgaeCO2, aes(treatment, growthrate)) + 
  geom_point(size = 4)
```

:::
:::





::: aside 

Collins, S. and G. Bell. 2004. Phenotypic consequences of 1,000 generations of selection at elevated CO<sub>2</sub> in a green alga. Nature 431: 566-569.
:::

# [One categorical predictor]{.page-break}

## [One-way ANOVA model]{.page-concept}

- A **one-way ANOVA model** is just a linear model where the response variable is modelled as a function of a single categorical explanatory variable.
- For $i=1, \ldots, t$ and $j = 1, \ldots, n_i$, $$y_{ij} = \beta_0 + \beta_{1i} + \epsilon_{ij}, \qquad \epsilon_{ij}\stackrel{iid}{\sim} N(0, \sigma^2),$$ where $t$ is the number of levels of the factor `treatment` and $n_i$ is the number of observations in the $i$-th level of the factor.
- In this model, $\beta_{1i}$ is the effect of the $i$-th level of the factor `treatment`.


```{webr}
coef(lm(growthrate ~ treatment, data = AlgaeCO2))
```

## [Dummy variables]{.page-rproj}

- When we fit a model with categorical explanatory variables, categorical variables are converted into a numerical representations, e.g. using a set of dummy variables.
- A **dummy variable** is a binary representation of one level of a categorical variable where 1 indicates the presence of that level and 0 indicating the absence of that level.

::: f2

```{webr}
model.matrix(~treatment, data = AlgaeCO2)
```

:::

## [Constraints and contrasts]{.page-concept}

- For $i=1, \ldots, t$ and $j = 1, \ldots, n_i$, 

$$y_{ij} = \beta_0 + \beta_{1i} + \epsilon_{ij}, \qquad \epsilon_{ij}\stackrel{iid}{\sim} N(0, \sigma^2).$$

```{webr}
coef(lm(growthrate ~ treatment, data = AlgaeCO2))
```

- So far the coefficient estimate for $\beta_{11}$ or it's associated dummy variable is not shown. 
- By default, `lm()` uses the **treatment constraint**, where the first level of the factor is the reference level (i.e. $\beta_{11} = 0$).
- The constraint is necessary to **make the model identifiable**.





## [One-way ANOVA model vs two-sample t-test]{.page-rproj}

- To test if the growth rates of algae under `high CO2` and `normal CO2` levels of carbon dioxide are different, we can use a two-sample t-test:

::: f2

```{webr}
t.test(growthrate ~ treatment, data = AlgaeCO2, var.equal = TRUE)$p.value
```

:::

. . . 

- Alternatively, we can fit a model with the `treatment` as a factor and test if the effect of `treatment` is significant:


::: f2

```{webr}
broom::tidy(lm(growthrate ~ treatment, data = AlgaeCO2))
```

:::

. . . 

- The p-value for the `treatment` factor is the same as the p-value for the above two-sample t-test!


# [Two categorical predictors]{.page-break}

## [Tooth Growth in Guinea Pigs]{.page-data}

::: {.columns}
::: {.column width="50%"}

- To study the effect of Vitamin C on tooth growth of guinea pigs, the length of odontoblasts (`len`) was collected on 60 guinea pigs at three `dose` levels of Vitamin C (0.5, 1, and 2 mg/day) with two delivery methods (orange juice or ascorbic acid) (`supp`).

<details class="f2"><summary>Code for the data</summary>

```{webr}
#| autorun: true
tooth <- ToothGrowth |> 
  mutate(dosef = factor(dose))
```
</details>

:::

::: {.column width="50%"}

::: f2

```{webr}
#| autorun: true
ggplot(tooth, aes(dosef, len, color = supp)) + 
  geom_jitter(width = 0.1)
```

:::
:::
:::








## [Two-way ANOVA model with no interaction]{.page-rproj}

- A **two-way ANOVA model** is just a linear model where the response variable is modelled as a function of _two_ categorical explanatory variables, A and B, say.
- For $i=1, \ldots, a$, $j = 1, \ldots, b$ and $k = 1, \dots, n_{ij}$, $$y_{ijk} = \beta_0 + \beta_{1i} + \beta_{2j} + \epsilon_{ijk}, \qquad \epsilon_{ijk}\stackrel{iid}{\sim} N(0, \sigma^2),$$ where $a$ and $b$ are the number of levels of factor A and B, and $n_{ij}$ is the number of observations in the $i$-th level of the factor A and $j$-th level of factor B.
- The treatment constraint means that $\beta_{11} = \beta_{21} = 0$.




```{webr}
coef(lm(len ~ dosef + supp, data = tooth))
```


## [Two-way ANOVA model with interaction]{.page-rproj}

- If the two-way ANOVA model includes an interaction term, $$y_{ijk} = \beta_0 + \beta_{1i} + \beta_{2j} + \beta_{3,ij} + \epsilon_{ijk}, \qquad \epsilon_{ijk}\stackrel{iid}{\sim} N(0, \sigma^2),$$ then the treatment constraint means that $\beta_{11} = \beta_{21} = \beta_{3,1j}= \beta_{3,i1} = 0$ for all $i = 1, \ldots, a$ and $j = 1, \ldots, b$. 
```{webr}
coef(lm(len ~ dosef + supp + dosef:supp, data = tooth))
```

## [ANOVA table]{.page-rproj} {.scrollable}

`r scroll`

- The ANOVA table shows the decomposition of the total sum of squares, $\sum_{i=1}^n (y_i - \bar{y})^2$, into different sources of variation.
- The F statistic is the ratio of the mean square of the corresponding source to the mean square of the residuals (like a "signal-to-noise" ratio).
- The p-value is based on a F-test if this "signal-to-noise" is large or not. 

```{webr}
#| autorun: true
anova(lm(len ~ dosef * supp, data = tooth))
```

- The F-test suggests that the interaction effect is significant.

- <i class="fas fa-exclamation-triangle"></i> The order of the predictors matter if the data is "unbalanced" with respect to the categorical variables (the number of observations differ across the combined levels of the factors).



## [Categorical or numerical variable?]{.page-concept}

::: incremental

- We've been using dose as a factor, but sometimes it is unclear as to whether a particular explanatory variable should be regarded as a **factor** (categorical explanatory variable) or a **numerical covariate**.
- If a predictor is a factor then you cannot use the model to predict for factor levels that were not observed in the data.
- If a predictor is numerical, then you can interpolate (and extrapolate) for values not within the data. 
- In fact, you'll find that if a factor with $t$ levels corresponds to numerical values, then [_a polynomial regression model of degree $t-1$ will be equivalent to the ANOVA model_]{.primary}.

:::

## [ANOVA model]{.page-rproj}

```{webr}
fit1 <- lm(len ~ dosef * supp, data = tooth)
```

- The above model is equivalent to predicting the red points below:

::: f2

```{webr}
#| autorun: true
#| fig-width: 10
ggplot(tooth, aes(dose, len)) +
  stat_summary(fun = mean, geom = "point", color = "red", alpha = 0.8, size = 8) + 
  geom_point(alpha = 0.8) +
  facet_wrap(~supp, labeller = label_both)
```

:::


## [Linear regression model]{.page-rproj}

```{webr}
fit2 <- lm(len ~ dose * supp, data = tooth)
```

- The above model is equivalent to predicting the blue line below:

::: f2

```{webr}
#| autorun: true
#| fig-width: 10
ggplot(tooth, aes(dose, len)) +
  geom_smooth(method = "lm", se = FALSE, color = "blue", formula = y ~ x) +
  geom_point(alpha = 0.8) +
  facet_wrap(~supp, labeller = label_both)
```

:::


## [Polynomial regression model]{.page-rproj}

```{webr}
fit3 <- lm(len ~ poly(dose, 2) * supp, data = tooth)
```

- The above model is equivalent to predicting the purple points below:

::: f2

```{webr}
#| autorun: true
#| fig-width: 10
ggplot(tooth, aes(dose, len)) +
  geom_smooth(method = "lm", se = FALSE, color = "purple", formula = y ~ poly(x, 2)) +
  geom_point(alpha = 0.8) +
  facet_wrap(~supp, labeller = label_both)
```

:::

## [ANOVA vs. linear regression vs. polynomial regression]{.page-rproj}

::: f3

```{webr}
#| autorun: true
#| fig-width: 10
ggplot(tooth, aes(dose, len)) +
  stat_summary(fun = mean, geom = "point", color = "red", alpha = 0.8, size = 8) +
  geom_smooth(method = "lm", se = FALSE, color = "blue", formula = y ~ x) +
  geom_smooth(method = "lm", se = FALSE, color = "purple", formula = y ~ poly(x, 2)) +
  geom_point(alpha = 0.8) +
  facet_wrap(~supp, labeller = label_both)
```

:::


- Notice that the purple lines go through all the red points -- this is because the polynomial regression model is equivalent to the ANOVA model.

# [Categorical and numerical predictors]{.page-break} {background-color="#F5EDDE"}




## [Longevity of fruitflies]{.page-data} 

**Aim**: Study longevity of fruitflies depending on sexual activity and thorax length

::: {.columns .f2}

::: {.column width="55%"}

```{r fig-fruitfly, dev.args=list(bg = "transparent")}
#| code-fold: true
library(tidyverse)
gfly <- faraway::fruitfly |> 
  mutate(activity = factor(activity, levels = c("isolated", "low", "high", "one", "many"))) |> 
  ggplot(aes(x = thorax, y = longevity, color = activity)) + 
  geom_point(data = ~select(., -activity), color = "lightgrey") +
  geom_point(size = 4) + 
  facet_wrap(~activity, labeller = label_both) +
  guides(color = "none") + 
  colorspace::scale_color_discrete_qualitative()

gfly
```

```{r}
#| echo: false
cols <- colorspace::qualitative_hcl(n = 5)
```


:::

::: {.f2 .column width="45%"}

- 125 fruitflies were divided randomly into 5 groups of 25 each. 
- The response was the longevity of the fruitfly in days. 
- One group was kept solitary (["isolated"]{style='color:`r cols[1]`'}).  
- Another was kept individually with a virgin female each day (["low"]{style='color:`r cols[2]`'}).
- Another group was given 8 virgin females per day (["high"]{style='color:`r cols[3]`'}). 
- As an additional control the fourth and fifth groups were kept with one (["one"]{style='color:`r cols[4]`'}) or eight (["many"]{style='color:`r cols[5]`'}) pregnant females per day. 
- Pregnant fruitflies will not mate. 
- The thorax length of each male was measured as this was known to affect longevity. 
- One observation in the many group has been lost.

:::

:::


## [Linear model 1]{.page-rproj}

`lm(longevity ~ thorax + activity + thorax:activity)`

$\texttt{longevity}_i = \beta_0 + \beta_1\texttt{thorax}_i + \beta_{2,T(i)} + \beta_{3,T(i)}\texttt{thorax}_i + \epsilon_i$

<details class="f2">

::: {.columns .f2}

::: {.column width="50%"}

where 

- $\beta_0$ is the overall intercept, 
- $\beta_1$ is the effect of thorax length on longevity,
- $\beta_{2,T(i)}$ is the effect of activity on longevity,
- $T(i)$ maps to the activity type of the $i$-th observation,
- $\beta_{3,T(i)}$ is the interaction effect between thorax length and activity type, and
- $\epsilon_i$ is the error term.

:::

::: {.column width="50%"}

Note that:

- We assume $\epsilon_i  \stackrel{iid}{\sim} N(0, \sigma^2)$.
- We use the constraints: $\beta_{2,1} = 0$ and $\beta_{3,1} = 0$.
- $\beta_0 + \beta_{2,k}$ is the intercept for the $k$-th activity type.
- $\beta_1 + \beta_{3,k}$ is the slope for the $k$-th activity type.

:::

:::

</details>


::: {.columns .f2}

::: {.column width="55%"}

```{r fig-fruitfly2}
#| code-fold: true
gfly + geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 2)
```

:::

::: {.column width="45%"}

```{r}
#| code-fold: true
#| fig-width: 10
flyfit1 <- lm(longevity ~ thorax + activity + thorax:activity, data = faraway::fruitfly) |> 
  broom::augment() |> 
  mutate(activity = factor(activity, levels = c("isolated", "low", "high", "one", "many"))) 
gres <- flyfit1 |> 
  ggplot(aes(.fitted, .resid, color = activity)) + 
  geom_point(data = ~select(., -activity), color = "lightgrey") + 
  geom_point(size = 4) +
  #facet_wrap(~activity, labeller = label_both) +
  guides(color = "none") +
  geom_hline(yintercept = 0, color = "black", linetype = 2) +
  colorspace::scale_color_discrete_qualitative() +
  labs(x = "Fitted values", y = "Residual", title = "Residual vs fitted values plot")

gres

```


:::

:::

## [Linear model 2]{.page-rproj}

`lm(log10(longevity) ~ thorax + activity + thorax:activity)`

$\log_{10}(\texttt{longevity}_i) = \beta_0 + \beta_1\texttt{thorax}_i + \beta_{2,T(i)} + \beta_{3,T(i)}\texttt{thorax}_i + \epsilon_i$


::: {.columns .f2}

::: {.column width="55%"}

```{r fig-fruitfly3}
#| code-fold: true
gfly + geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 2) +
  scale_y_log10()
```

:::

::: {.f2 .column width="45%"}


```{r}
#| code-fold: true
#| fig-width: 10
flyfit2 <- lm(log10(longevity) ~ thorax + activity + thorax:activity, data = faraway::fruitfly) |> 
  broom::augment() |> 
  mutate(.fitted = 10^.fitted) |> 
  mutate(activity = factor(activity, levels = c("isolated", "low", "high", "one", "many"))) 

gres %+% flyfit2
```

:::

:::





## [Linear model 3]{.page-rproj}

`lm(log10(longevity) ~ thorax + activity)`

$\log_{10}(\texttt{longevity}_i) = \beta_0 + \beta_1\texttt{thorax}_i + \beta_{2,T(i)} + \epsilon_i$

<details class="f2">
```{r}
fit1 <- lm(log10(longevity) ~ thorax + activity, data = faraway::fruitfly)
fit2 <- lm(log10(longevity) ~ thorax + activity + thorax:activity, data = faraway::fruitfly)
anova(fit1, fit2)
```
</details>

::: {.columns .f2}

::: {.column width="55%"}

```{r fig-fruitfly4}
#| code-fold: true
fit <- lm(log10(longevity) ~ -1 + thorax + activity, data = faraway::fruitfly)
est <- tibble(slope = coef(fit)[1], 
              intercept = coef(fit)[-1],
              activity = str_remove(names(coef(fit)[-1]), "^activity")) |> 
mutate(activity = factor(activity, levels = c("isolated", "low", "high", "one", "many"))) 
gfly + geom_abline(aes(slope = slope, intercept = intercept), color = "black", linewidth = 2, data = est) + scale_y_log10()
```

:::

::: {.f2 .column width="45%"}

```{r}
#| code-fold: true
#| fig-width: 10


gres %+% (broom::augment(fit) |> 
  mutate(activity = factor(activity, levels = c("isolated", "low", "high", "one", "many"))))

```

:::

:::


# [Multiple testing]{.page-break} {background-color="#F5EDDE"}

## [Fertilizer brands on wheat yield]{.page-data}

```{webr data}
#| include: false
set.seed(435)
wheat <- data.frame(yield = rnorm(200, 5, 1)) |> 
  mutate(fertilizer = rep(c(LETTERS[1:9], "0"), each = 20))
```

::: {.columns}
::: {.column width="35%"}

- **9 fertilizer brands** (labelled A, B, C, D, E, F, G, H, I) and a **control** (labelled 0) were tested on 20 wheat plots each.
- <i class="fas fa-bullseye"></i> The study wanted to identify which fertilizer brand is the least to most effective, and whether they were signficantly different from each other.

:::

::: {.column width="65%" .f2}

```{webr}
#| autorun: true
wheat |> 
  mutate(fertilizer = reorder(fertilizer, yield, median)) |>
  ggplot(aes(fertilizer, yield)) +
  geom_boxplot()
```


:::
:::

## [Estimated marginal means]{.page-rproj}

```{webr}
#| autorun: true
library(emmeans)
fit <- lm(yield ~ fertilizer, data = wheat)
emm <- emmeans(fit, ~ fertilizer)
emm |> as.data.frame() |> arrange(desc(emmean))
```

## [Pairwise comparisons (with no adjustments)]{.page-rproj}


```{webr}
#| fig-height: 12
#| autorun: true
pairs(emm)
# plot(pairs(emm)) + geom_vline(xintercept = 0, linetype = "dashed")
```

- Fertilizer brand D is significantly better than the control


## [Multiple testing]{.page-concept} 

::: {.columns}
::: {.column width="17%"}

![](/images/xkcd/significant.png){width="100%"}
[Source: [xkcd](https://xkcd.com/)]{.f2}

:::

::: {.column width="83%"}

- When conducting multiple tests, the probability of making a Type I error increases.
- The more tests you conduct, the more likely you are to find a significant result by chance even if there is no true effect.
- The **Bonferroni correction** is a simple way to adjust for multiple testing by dividing the significance level by the number of tests.

```{webr}
pairs(emm, adjust = "bonferonni")
```



:::
:::


## [Data generating process for wheat yield]{.page-code}

::: f2

```{webr data}
```

:::


- Notice here that there is actually **no real differences between the fertilizers**!
- Any significant difference found is due to random chance.


# [Summary]{.page-break}

- When fitting linear models, categorical variables (factors) are converted to numerical values under the hood, e.g. by converting to dummy variables.
- **ANOVA table** shows the decomposition of the sum of squares into different sources of variation.
- **F-tests in ANOVA** show the significance of the different sources of variation.
- **ANOVA model is a special case of linear regression models**. 
- If a factor can be represented numerically, ANOVA model is a special case of a polynomial regression model.
- **Multiple testing** increases the probability of making a Type I error, so the significance level should be adjusted accordingly.


# [Exercise time]{.page-exercise} {background-color="#F5EDDE"}

[<i class="fas fa-terminal"></i> Go to Exercise 5](/exercises/exercise05.html){.button-next} <br><br>

[<i class="fas fa-caret-square-right"></i> Next slide](/slides/slide6.html){.button-next} <br><br>

[<i class="fas fa-fast-backward"></i> Back to start](/slides/slide5.html){.button-next}

