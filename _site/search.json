[
  {
    "objectID": "slides/slide4.html#ethical-considerations",
    "href": "slides/slide4.html#ethical-considerations",
    "title": "Discussion & Conclusion",
    "section": "Ethical considerations",
    "text": "Ethical considerations\n\nBias and fairness: LLM can perpetuate existing social biases if they are trained on biased data or by reinforcing stereotypes.\nTransparency and interpretability: Difficult to understand how the LLM arrived at a particular answer or prediction.\nJob replacement and worker displacement: LLMs can replace human workers\nData sharing and usage: Usage of sensitive and protected information in training.\nMisinformation: Spread of false or misleading information, reinforcing echo chambers or amplifying malicious actors.\nAccountability: Who should be held accountable when a LLM makes an error?\nLong-term impact on society: As LLM get increasing integrated in society, how would it impact the society in the lon-term?\n\n\n\nNote: the main points was inspired by llama3.1:8b."
  },
  {
    "objectID": "slides/slide4.html#section",
    "href": "slides/slide4.html#section",
    "title": "Discussion & Conclusion",
    "section": "",
    "text": "Let’s discuss\n\n\nHow do LLMs complement or hinder statistical thinking?\n\nWhat role should LLMs play in decision-making processes and research?\n\nHow will LLMs impact the training and development of future statisticians and data scientists?\n\nWhat are the use cases of LLM for you (if any)?"
  },
  {
    "objectID": "slides/slide2.html#chatgpt",
    "href": "slides/slide2.html#chatgpt",
    "title": "Landscape of Large Language Models",
    "section": "ChatGPT",
    "text": "ChatGPT\n\nChatGPT was released to public on 30th November 2022.\nChatGPT gained a staggering 100 million active users in 2 months1.\n\n\n\n\nChatGPT Heralds an Intellectual Revolution\n\n25 February 2023\n\n\nBy Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher\n\n\nGenerative artificial intelligence presents a philosophical and practical challenge on a scale not experienced since the start of the Enlightenment.\nA new technology bids to transform the human cognitive process as it has not been shaken up since the invention of printing. The technology that printed the Gutenberg Bible in 1455 made abstract human thought communicable generally and rapidly. But new technology today reverses that process. Whereas the printing press caused a profusion of modern human thought, the new technology achieves its distillation and elaboration. In the process, it creates a gap between human knowledge and human understanding. If we are to navigate this transformation successfully, new concepts of human thought and interaction with machines will need to be developed. This is the essential challenge of the Age of Artificial Intelligence.\n…\nMr. Kissinger served as secretary of state, 1973-77, and White House national security adviser, 1969-75. Mr. Schmidt was CEO of Google, 2001-11 and executive chairman of Google and its successor, Alphabet Inc., 2011-17. Mr. Huttenlocher is dean of the Schwarzman College of Computing at the Massachusetts Institute of Technology. They are authors of “The Age of AI: And Our Human Future.” The authors thank Eleanor Runde for her research.\n\n\n\nGPT = Generative Pre-trained Transformer\n\n\nHu, Krystal (2023) ChatGPT sets record for fastest-growing user base - analyst note. Reuters."
  },
  {
    "objectID": "slides/slide2.html#chatbot-timeline",
    "href": "slides/slide2.html#chatbot-timeline",
    "title": "Landscape of Large Language Models",
    "section": "Chatbot timeline",
    "text": "Chatbot timeline\n\n\n\n\n+\n-\n\n\n\n\n\n\nRefresh of browser may be needed for timeline to render correctly\n Data Source: https://en.wikipedia.org/wiki/List_of_chatbots (Accessed on 11/08/2024)"
  },
  {
    "objectID": "slides/slide2.html#related-concepts",
    "href": "slides/slide2.html#related-concepts",
    "title": "Landscape of Large Language Models",
    "section": "Related concepts",
    "text": "Related concepts\n\nOverlapping but different focuses often using related methods.\n\n\n\n\n\n\n chat with user\n\n\n\n\n\n multiple purposes\n\n\n\n\n\n new creative content\n\n\n\n\n\nNote: not all LLMs power chatbots and genAI but most do.\nWe’ll look at the architecture of LLM later in the workshop.\n\n\n\n\nA large language models (LLM) is a computational model capable of general-purpose language generation and other natural language processing (NLP) tasks.\nMost LLMs are artificial neural networks built with a decoder-only transformer-based architecture.\nGenerative Pre-trained Transformers (GPT) are a type of LLM"
  },
  {
    "objectID": "slides/slide2.html#rise-of-large-language-models",
    "href": "slides/slide2.html#rise-of-large-language-models",
    "title": "Landscape of Large Language Models",
    "section": "Rise of large language models",
    "text": "Rise of large language models\n\n\n\n\n+\n-\n\n\n\n\n\n\n\nRefresh of browser may be needed for timeline to render correctly\n Data Source: https://en.wikipedia.org/wiki/Large_language_model#List (Accessed on 11/08/2024)\n\n\n\nA large language model (LLM) is a computational model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification.\nGenerative pre-trained transformers (GPT) are a type of LLM.\nGenerative artificial intelligence (GenAI) is artificial intelligence capable of generating new creative content."
  },
  {
    "objectID": "slides/slide2.html#using-a-llm",
    "href": "slides/slide2.html#using-a-llm",
    "title": "Landscape of Large Language Models",
    "section": "Using a LLM",
    "text": "Using a LLM\n\n\n\nVendor API\n\n\n          …\n\nRequires internet access\nRequires account with vendor\nOngoing payment for usage\n\n\n\nLocal LLM\n\n\n GPT4All   LM Studio   Jan   llama.cpp   llamafile   Ollama   NextChat  …\n\nNo internet access required\nNo account required\nSeveral GB of hard disk space required\nAt least 16GB RAM required for 7b parameter LLMs"
  },
  {
    "objectID": "slides/slide2.html#section",
    "href": "slides/slide2.html#section",
    "title": "Parametric distributions to describe and simulate data",
    "section": "",
    "text": "Many distribution in nature appears to conform a normal distribution.\nsum of many independent random values, then that value will follow a normal distribution regardless of how the individual terms are distributed.\nmost sufficiently complex natural phenomenon tends to be the sum of many small random factors.\nBoth your examples (size, concentration) can’t even be below zero. If your proposed distribution doesn’t have support over the reals, it’s by definition not normal.\nThe average influence of many small effects"
  },
  {
    "objectID": "slides/slide2.html#ollama",
    "href": "slides/slide2.html#ollama",
    "title": "Landscape of Large Language Models",
    "section": " Ollama",
    "text": "Ollama\n\n\n Models:\n\nllama3.2:1b\nllama3.2:3b\nllama3.1:8b\nllama3.1:70b\nllama3.1:405b\ngemma2:2b\ngemma2:9b\ngemma2:27b\nllava:7b\n…\n\n\n\ncurl http://localhost:11434/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.2:1b\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n\n\n\n Pricing: FREE.\nThe model name has a suffix with the number of parameters, e.g. llama3.1:8b has about 8 billion parameters.\nLarger number of parameters requires larger RAM (~16GB RAM required for 7b)."
  },
  {
    "objectID": "slides/slide2.html#which-llm-to-use",
    "href": "slides/slide2.html#which-llm-to-use",
    "title": "Landscape of Large Language Models",
    "section": "Which LLM to use?",
    "text": "Which LLM to use?\n\n\nLLM leaderboards, e.g. Open LLM Leaderboard and LLM Arena.\nSmaller number of model parameters may not perform as well for complex tasks.\n\nThere are some specialised LLMs, e.g. \n\ndall-e-3 generates images from user text input\nllava:7b is a multi-modal model and can take image input\nmathstral:7b is designed for math reasoning and scientific discovery\ndeepseek-coder-v2:16b comparable to gpt-4-turbo in code-specific tasks\nmeditron:7b adapted from llama2 for medical domain\n\nCurrently I use mostly:\n\nOpen AI: gpt-4o, gpt-4o-mini and dall-e-3 with payment of US$5 so far\nOllama: llama3.1:8b and llava:7b"
  },
  {
    "objectID": "slides/slide2.html#predictive-model",
    "href": "slides/slide2.html#predictive-model",
    "title": "Landscape of Large Language Models",
    "section": "Predictive model",
    "text": "Predictive model\n\n\n\nLarge language model at its core predicts the next word given a sequence of words.\n\n\n\n\n\n\n\nThe prediction makes use of patterns recognised from linguistic features trained on a large corpus of text.\n\n\n\n\nInput:  All models are wrong, but some are \n\n\n\nUpdated input:\n All models are wrong, but some are useful \n\n\n\n\n\n\nUpdated input:\n All models are wrong, but some are useful. \n\n\n\n\n\n    LLM  \n\n\n useful \n\n\n\n\n\n . \n\n\n\n\n &lt;|end|&gt; \n\n\n\n\nOutput:   useful."
  },
  {
    "objectID": "slides/slide2.html#tokenization",
    "href": "slides/slide2.html#tokenization",
    "title": "Landscape of Large Language Models",
    "section": "Tokenization",
    "text": "Tokenization\nInput  Where there’s a will, there’s a \n\nToken  Where    there   ’s    a    will   ,    there   ’s    a \nToken ID  11977   1354   802   261   738   11   1354   802   261 \n    LLM  \n 2006 \n way \n   \n\n\nSee also Open AI tokenizer: https://platform.openai.com/tokenizer"
  },
  {
    "objectID": "slides/slide2.html#tokens-are-not-necessary-words",
    "href": "slides/slide2.html#tokens-are-not-necessary-words",
    "title": "Landscape of Large Language Models",
    "section": "Tokens are not necessary words",
    "text": "Tokens are not necessary words\n\nEvery LLM has its own tokenizer with varying vocabulary size.\nRule of thumb for common English text:  1 token = ~4 characters = ~0.75 words \n\n summary   summarise   summarize   summarising   summarizations \n\n summary   summ   ar   ise   summ   ar   ize   summ   ar   ising   summ   ar   izations \n\n 3861   141249   277   1096   750   5066   25434"
  },
  {
    "objectID": "slides/slide2.html#special-tokens",
    "href": "slides/slide2.html#special-tokens",
    "title": "Landscape of Large Language Models",
    "section": "Special tokens",
    "text": "Special tokens\n\nIn practice,  summarise  may be tokenized as  summ   ##ar   ##ise  where “##” indicates another token prefixes it.\n\n\n\nDue to popularity of chat tokens since 2023, tokenizers have adapted to a conversational direction with special tokens to indicate speaker role, such as\n\n &lt;|system|&gt;  – high-level instructions\n &lt;|user|&gt; – user (usually human) queries or prompts,\n &lt;|assistant|&gt;  – typically the model’s response, and\nother, e.g.  &lt;|tool|&gt; ."
  },
  {
    "objectID": "slides/slide2.html#token-distribution",
    "href": "slides/slide2.html#token-distribution",
    "title": "Landscape of Large Language Models",
    "section": "Token distribution",
    "text": "Token distribution\nInput:  Where there’s a will, there’s a \n\nOutput is randomly sampled from likely tokens weighted by their respective probabilities.\n\n\n\n\nOriginal distribution:\n\nToken Probability\n2006 \n 301 \n 35 \n 4443 \n 4 \n … \n\n\n\nSmall top_p:\n\nToken Probability\n2006 \n 301 \n\n\n\nHigh temperature\n\nToken Probability\n2006 \n 301 \n 35 \n 4443 \n 4 \n … \n\n\n\n\n\nseed ensures the same random sample given the same input (important for reproducibility!), but the same seed may not yield the same result across different systems."
  },
  {
    "objectID": "slides/slide2.html#prompt-engineering",
    "href": "slides/slide2.html#prompt-engineering",
    "title": "Landscape of Large Language Models",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\nPrompt engineering is the process of designing and refining the prompts for a language model to generate specific types of output.\n\n\nchat1 &lt;- elmer::chat_ollama(model = \"llama3.1:8b\", \n                            seed = 1,\n                            api_args = list(temperature = 0),\n                            echo = TRUE)\n\n\n\nSuppose we want to classify the sentiment of the text as positive or negative.\n\n\nchat1$chat('Classify the text as positive or negative.\n           \"This is a great book!\"') \n\nI would classify this text as **positive**. The use of the word \"great\" \nindicates a strong and enthusiastic endorsement of the book."
  },
  {
    "objectID": "slides/slide2.html#instruction-based-prompt",
    "href": "slides/slide2.html#instruction-based-prompt",
    "title": "Landscape of Large Language Models",
    "section": "Instruction-based prompt",
    "text": "Instruction-based prompt\n\nYou can give more specific instructions regarding the format.\n\n\nchat2 &lt;- elmer::chat_ollama(model = \"llama3.1:8b\", \n                            system_prompt = \"Just give the answer.\",\n                            seed = 1,\n                            api_args = list(temperature = 0),\n                            echo = TRUE)\n\n\n\nThe response is now concise.\n\n\nchat2$chat('Classify the text as positive or negative.\n           \"This is a great book!\"')\n\nPositive.\n\n\n\nIn this case, a similar answer would be generated if system prompt was included in the user prompt."
  },
  {
    "objectID": "slides/slide2.html#zero-shot-prompt",
    "href": "slides/slide2.html#zero-shot-prompt",
    "title": "Landscape of Large Language Models",
    "section": "Zero-shot prompt",
    "text": "Zero-shot prompt\n\nWhen LLM are given no examples of the task to carry out, this is referred to as zero-shot prompt.\n\n\nchat2$chat('Which discipline does machine learning belong to?')\n\n\n\nComputer Science.\n\n\n\n\nchat2$chat('Which discipline does logistic regression belong to?')\n\n\n\nStatistics and Machine Learning.\n\n\n\n\n\n\nLLM can be fine-tuned by training on a new labelled data, but this is computationally expensive and out of scope for typical analysts.\n\n\n\n\nPrompt engineering with one- or few-shot prompt is a low cost approach to provide in-context learning."
  },
  {
    "objectID": "slides/slide2.html#in-context-learning",
    "href": "slides/slide2.html#in-context-learning",
    "title": "Landscape of Large Language Models",
    "section": "In-context learning",
    "text": "In-context learning\n\nIf examples of expected response are provided in the prompt, these are called one-shot prompt (if one example) or a few-shot prompt (if more than one example).\n\n\nchat2$chat('Which discipline does machine learning belong to?\n           Examples:\n\n           Technique: Regression\n           Discipline: Statistics\n           \n           Technique: Deep learning\n           Discipline: Data Science\n           \n           Technique: Database Management\n           Discipline: Computer Science')\n\n\n\nData Science.\n\n\n\n\nchat2$chat('Which discipline does logistic regression belong to?')\n\n\n\nStatistics and Machine Learning, but more specifically, it belongs to the \ndiscipline of Statistics."
  },
  {
    "objectID": "slides/slide2.html#chain-of-thought",
    "href": "slides/slide2.html#chain-of-thought",
    "title": "Landscape of Large Language Models",
    "section": "Chain-of-thought",
    "text": "Chain-of-thought\n\nChain-of-thought aims to make the LLM “think” before answering.\nReasoning is a core component of human intelligence and LLM can mimic “reasoning” from memorisation and pattern matching trained from large corpus of text.\n\n\nchat2$chat('Regression is a primarly tool for statisticians. \n           Which discipline does logistic regression belong to?')\n\n\n\nStatistics.\n\n\n\n\nHere is another example where we want to calculate the median:\n\n\nchat2$chat(\"What is the median of 1, 4 and 5?\")\n\n\n\n3.\n\n\n\n\n\nProvide some cue for reasoning.\n\n\nchat2$chat(\"The median is the middle value of the sorted list of numbers. \n           What is the median of 1, 4 and 5?\")\n\n\n\nSince the numbers are already in order (1, 4, 5), the median is the middle \nnumber, which is 4."
  },
  {
    "objectID": "slides/slide2.html#prompt-engineering-components",
    "href": "slides/slide2.html#prompt-engineering-components",
    "title": "Landscape of Large Language Models",
    "section": "Prompt engineering components",
    "text": "Prompt engineering components\nSome common components include:\n\n\nInstruction The task (be specific as possible).\nFormat The response format. E.g. “return the value only” and “return as JSON”.\nExample Example(s) of input and expected response.\n\nContext Additional information about the context of the task.\nPersona Describe the role of the LLM. E.g. “You are a statistics tutor”.\nAudience Describe the target audience. E.g. “Explain it to a high school student”.\nTone The tone of the text. E.g. “Respond professionally”."
  },
  {
    "objectID": "slides/slide2.html#self-consistency",
    "href": "slides/slide2.html#self-consistency",
    "title": "Landscape of Large Language Models",
    "section": "Self-consistency",
    "text": "Self-consistency\n\nTo ensure the responses are reliable, you can generate the response to the same prompt multiple times and select the mode.\n\n\nchat2$chat(\"What is the mean of 1, 9 and 5?\")\n\n(1 + 9 + 5) / 3 = 15 / 3 = 5.\n\n\n\n\nchat2$chat(\"What is the mean of 1, 9 and 5?\")\n\n15.\n\n\n\n\n\nchat2$chat(\"What is the mean of 1, 9 and 5?\")\n\n(1 + 9 + 5) / 3 = 15 / 3 = 5.\n\n\n\n\n\nchat2$chat(\"What is the mean of 1, 9 and 5?\")\n\n15/3 = 5.\n\n\n\n\n\nchat2$chat(\"What is the mean of 1, 9 and 5?\")\n\n15."
  },
  {
    "objectID": "slides/slide2.html#section-1",
    "href": "slides/slide2.html#section-1",
    "title": "Landscape of Large Language Models",
    "section": "",
    "text": "🤔 Pondering\n(for later)\n\n\n\nHow do LLMs complement or hinder statistical thinking?\n\nWhat role should LLMs play in decision-making processes and research?\n\nHow will LLMs impact the training and development of future statisticians and data scientists?\n\nWhat are the use cases of LLM for you (if any)?\n    \n\n\n   \n  \n\n\n\n\nemitanaka.org/workshop-LLM-2024/"
  },
  {
    "objectID": "demo/demo3.html",
    "href": "demo/demo3.html",
    "title": "Applications to real data",
    "section": "",
    "text": "This demo assumes that you have all the software requirements.\nlibrary(tidyverse)\nlibrary(SAI)\nlibrary(elmer)\nWe’ll use LLMs to help us with the following data processing tasks:\nMake sure to validate by doing spot checks or otherwise!\nLLM may propagate majority view so take caution on its usage, particularly for classification tasks."
  },
  {
    "objectID": "demo/demo3.html#airbnb-reviews-data",
    "href": "demo/demo3.html#airbnb-reviews-data",
    "title": "Applications to real data",
    "section": "1 AirBnB reviews data",
    "text": "1 AirBnB reviews data\nThe airbnb_reviews data from the SAI package contains AirBnB reviews in Sydney, Australia. We look at the listing “Heart of Rockdale 2” (ID 35428495) with host Jason. The host describes the neighbourhood of the listing as below.\n\ngood location easy to access all Sydney has to offer..\n\nThis listing has 20 reviews shown below.\n\nreviews &lt;- airbnb_reviews |&gt; \n  filter(listing_id == 35428495) |&gt; \n  pull(review_text)\n\nreviews\n\n [1] \"Excellent place to stay for single person travelling. All necessities are there hair dryer, kitchenette, cutlery, clean towels and so on. Highly recommended.\"                                                                                                                                                                                                                                                                             \n [2] \"Good privacy and self contained.\"                                                                                                                                                                                                                                                                                                                                                                                                          \n [3] \"Convenient location, east check in and clean space. Would stay again.\"                                                                                                                                                                                                                                                                                                                                                                     \n [4] \"다음날 공항에 가기 전 묵기 좋았습니다&lt;br/&gt;깔끔해서 묵기 편했습니다&lt;br/&gt;하지만 난방기구가 하나도 없어서 저는 밤새 덜덜 떨면서 자야 했습니다...🥲&lt;br/&gt;너무 추운거 빼고는 완벽했습니다\"                                                                                                                                                                                                                                                       \n [5] \"Great location, walking distance to train station, cafes, restaurants and Lady Robinson's beach. If you need to work or stream, bring your own internet.\"                                                                                                                                                                                                                                                                                  \n [6] \"Good stay overall!\"                                                                                                                                                                                                                                                                                                                                                                                                                        \n [7] \"Great little single person room, good for short .&lt;br/&gt;It has a kitchenette, clean and usable toilet and shower.&lt;br/&gt;Lots of good food in Rockdale within walking distance\"                                                                                                                                                                                                                                                                 \n [8] \"Thanks Jason, was perfect for what I needed\"                                                                                                                                                                                                                                                                                                                                                                                               \n [9] \"Clean & tidy place, Convient location with proximity to shops,airport & train.\"                                                                                                                                                                                                                                                                                                                                                            \n[10] \"Very last minute booking due to delayed flight, very close to airport. Thanks for the accomodation Jason! Highly recommend :)\"                                                                                                                                                                                                                                                                                                             \n[11] \"it's a tidy clean home. and Jason is nice . it's just the time i arrived was late and the light is not on. as a girl i'll be a bit scared ,and really suggest jason to change the blind into some thicker material, that blind for girls are not very safe. and could put a inside locker chain. i know it's a female thing. but it will definitely make us feel safer. ty\"                                                                \n[12] \"An older style room with older furniture, but very clean and functional. Great communication from the owner.\"                                                                                                                                                                                                                                                                                                                              \n[13] \"Had a great stay. Fantastic location close to the airport and Jason was very accommodating and easy to communicate with.\"                                                                                                                                                                                                                                                                                                                  \n[14] \"Everything was perfect, great host\"                                                                                                                                                                                                                                                                                                                                                                                                        \n[15] \"Good basic accommodation for one person needing to make an early start for the airport.\"                                                                                                                                                                                                                                                                                                                                                   \n[16] \"Excellent for a quick stay\"                                                                                                                                                                                                                                                                                                                                                                                                                \n[17] \"Stayed here for 2.5 weeks and was really happy with the place. The unit was tiny, but had all the amenities I needed as a solo traveller. 10 min walk to the ocean and beaches, Rockdale train station, Anytime Fitness,  shopping centre and Coles supermarket. I work remotely, so the only thing I wish was better was the wifi, which was pretty spotty most days. I used my wifi hotspot or worked from a café, so that worked for me\"\n[18] \"Super handy to Sydney Airport, very prompt and clear communication, and totally reasonable, simple accommodation with everything that any reasonable maintenance person would happily need.\"                                                                                                                                                                                                                                               \n[19] \"thank you, clean convenient and quiet neighbourhood\"                                                                                                                                                                                                                                                                                                                                                                                       \n[20] \"Perfect for one night for solo travellors. All u need in a small bedsit. Can be cold though so either ask for another blanket or take a spare one.\"                                                                                                                                                                                                                                                                                        \n\n\n\n1.1 Sentiment score\n\nsentimenter &lt;- chat_ollama(model = \"llama3.1:8b\", \n                           system_prompt = \"Score the sentiment of the input text from 1 to 10 where 1 is the most negative and 10 is the most positive. Just return the sentiment score only.\",\n                    seed = 1,\n                    api_args =list(top_p = 0.1, \n                                   temperature = 0))\n\n# for each review, ask the `sentimenter` to score.\nsentiment &lt;- map_dbl(reviews, ~as.numeric(sentimenter$chat(.x)))\n\nmean(sentiment)\n\n[1] 8.75\n\n\nSo the mean sentiment of this listing is 8.75 out of 10. You can see the review text and sentiment score computed by the LLM in Table 1. Do you agree with the scoring? It’s a good idea to do some sample checks that it’s working as intended before processing your data in large scale.\n\n\n\n\nTable 1: The review text and corresponding sentiment score computed by the LLM.\n\n\n\n\n\n\n\n\n\n\nreviews\nsentiment\n\n\n\n\nExcellent place to stay for single person travelling. All necessities are there hair dryer, kitchenette, cutlery, clean towels and so on. Highly recommended.\n9\n\n\nGood privacy and self contained.\n8\n\n\nConvenient location, east check in and clean space. Would stay again.\n9\n\n\n다음날 공항에 가기 전 묵기 좋았습니다깔끔해서 묵기 편했습니다하지만 난방기구가 하나도 없어서 저는 밤새 덜덜 떨면서 자야 했습니다…🥲너무 추운거 빼고는 완벽했습니다\n6\n\n\nGreat location, walking distance to train station, cafes, restaurants and Lady Robinson’s beach. If you need to work or stream, bring your own internet.\n9\n\n\nGood stay overall!\n8\n\n\nGreat little single person room, good for short .It has a kitchenette, clean and usable toilet and shower.Lots of good food in Rockdale within walking distance\n9\n\n\nThanks Jason, was perfect for what I needed\n10\n\n\nClean & tidy place, Convient location with proximity to shops,airport & train.\n9\n\n\nVery last minute booking due to delayed flight, very close to airport. Thanks for the accomodation Jason! Highly recommend :)\n10\n\n\nit’s a tidy clean home. and Jason is nice . it’s just the time i arrived was late and the light is not on. as a girl i’ll be a bit scared ,and really suggest jason to change the blind into some thicker material, that blind for girls are not very safe. and could put a inside locker chain. i know it’s a female thing. but it will definitely make us feel safer. ty\n7\n\n\nAn older style room with older furniture, but very clean and functional. Great communication from the owner.\n8\n\n\nHad a great stay. Fantastic location close to the airport and Jason was very accommodating and easy to communicate with.\n10\n\n\nEverything was perfect, great host\n10\n\n\nGood basic accommodation for one person needing to make an early start for the airport.\n8\n\n\nExcellent for a quick stay\n9\n\n\nStayed here for 2.5 weeks and was really happy with the place. The unit was tiny, but had all the amenities I needed as a solo traveller. 10 min walk to the ocean and beaches, Rockdale train station, Anytime Fitness, shopping centre and Coles supermarket. I work remotely, so the only thing I wish was better was the wifi, which was pretty spotty most days. I used my wifi hotspot or worked from a café, so that worked for me\n9\n\n\nSuper handy to Sydney Airport, very prompt and clear communication, and totally reasonable, simple accommodation with everything that any reasonable maintenance person would happily need.\n10\n\n\nthank you, clean convenient and quiet neighbourhood\n9\n\n\nPerfect for one night for solo travellors. All u need in a small bedsit. Can be cold though so either ask for another blanket or take a spare one.\n8\n\n\n\n\n\n\n\n\n\n\n1.2 Summarise texts\nFor summarising the text, we need to parse all reviews. To do this we have to collapse all the review text into one but also have a way to signal that the reviews are separate. To do this we’ll quote each review and separate them by a comma.\n\nreview_all &lt;- paste0(paste0('\"', reviews,'\"'), collapse = \", \")\n\nsummariser &lt;- chat_ollama(model = \"llama3.1:8b\",\n                          system_prompt = \"The user will input reviews of a listing. Summarise the input text into one paragraph including the overall sentiment. Just return the summary.\",\n                          seed = 1,\n                          api_args = list(top_p = 0.1,\n                                          temperature = 0))\n\nsummariser$chat(review_all) |&gt; cat()\n\nThe listing is a simple, self-contained accommodation suitable for single travelers, with all the necessary amenities such as kitchenette, clean towels, and hair dryer. The location is convenient, close to public transport, shops, and beaches, making it ideal for short stays or early departures from Sydney Airport. While some guests noted that the room can be cold, especially at night, most reviewers praised the cleanliness, tidiness, and good communication with the owner. Overall, the sentiment is overwhelmingly positive, with many guests recommending the listing to others.\n\n\nWhat do you think about the summary it produced? Again, do some spot checks!\nBonus: you may have noticed that the fourth review is in another language. You can use LLM to identify and translate text. For convenience, SAI package does this for you as follows.\nWe’ll set the model for SAI first.\n\nsai_set_model(model_ollama(model = \"llama3.1:8b\"))\n\nWe can identify the language as:\n\nsai_what_language(reviews[4])\n\n[1] \"Korean\"\n\n\nAnd translate to English (default) as below:\n\nsai_translate(reviews[4]) |&gt; cat()\n\nI stayed here the night before flying out and it was great. The place is very clean and comfortable. However, there were no heating devices so I shivered all night. It was perfect except for the cold.\n\n\nThe above functions are convenient functions that use LLM under the hood."
  },
  {
    "objectID": "demo/demo3.html#salary",
    "href": "demo/demo3.html#salary",
    "title": "Applications to real data",
    "section": "2 Salary",
    "text": "2 Salary\nThe salary data from SAI contains the survey results from a 2021 Ask a Manager Salary Survey.\nWe’ll take a 400 random responses to reduce the time for demonstration.\n\nset.seed(1)\nsalary_sample &lt;- slice_sample(salary, n = 400)\n\n\n2.1 Clustering\nThe responders entered the job title by text, as such there are as many job titles as many responders. We may wish to group them thematically so we’ll cluster them using the LLM as below.\nIn this process, you may like to cluster the group based on a sub-sample (200 below) as LLM have a context window and the long list of all job titles may make the input text unwieldy long.\n\njob_all &lt;- paste0(paste0('\"', sample(salary_sample$job_title, 200), '\"'), collapse = \", \")\n\njob_grouper &lt;- chat_ollama(model = \"llama3.1:8b\",\n                          system_prompt = \"The input text is a list of job title from survey responses. Clean the job titles and group similar job titles together. Just return the groups only as a json object.\",\n                          seed = 1,\n                          api_args = list(top_p = 0.5,\n                                          temperature = 0,\n                                          response_format = list(type = \"json_object\")))\n\njob_groups &lt;- job_grouper$chat(job_all) |&gt; \n  jsonlite::fromJSON()\n\njob_groups\n\n$Management\n [1] \"Data Engineering Manager\"                  \n [2] \"Program Director\"                          \n [3] \"Library director\"                          \n [4] \"Sr Contracts Manager\"                      \n [5] \"Director of Customer Experience\"           \n [6] \"office manager\"                            \n [7] \"Payor Support Specialist\"                  \n [8] \"Head of Devops\"                            \n [9] \"Senior Program Manager\"                    \n[10] \"Digital Account Manager\"                   \n[11] \"Manager\"                                   \n[12] \"Customer Success Manager\"                  \n[13] \"EA\"                                        \n[14] \"Admin\"                                     \n[15] \"Executive assistant\"                       \n[16] \"VP Marketing/Merchandising/Creative\"       \n[17] \"Sr Manager\"                                \n[18] \"Human Resource Manager\"                    \n[19] \"Office Manager\"                            \n[20] \"HR Coordinator\"                            \n[21] \"IT Helpdesk Assistant\"                     \n[22] \"HR Operations Manager\"                     \n[23] \"Account coordinator\"                       \n[24] \"Research scientist\"                        \n[25] \"Government worker\"                         \n[26] \"Service Manager\"                           \n[27] \"Marketing Coordinator\"                     \n[28] \"Consultant\"                                \n[29] \"Administrative Assistant & Systems Analyst\"\n[30] \"Alliance Manager\"                          \n[31] \"Marketing Manager\"                         \n[32] \"Administrative Assistant\"                  \n[33] \"Manager, Access Services\"                  \n[34] \"Sr. Account Relationship Manager\"          \n[35] \"RN coordinator\"                            \n[36] \"Digital print technician\"                  \n[37] \"Benefits & Compensation Manager\"           \n[38] \"Director of Development\"                   \n[39] \"Senior Associate\"                          \n[40] \"Library Director\"                          \n[41] \"Team Lead Inbound Scheduling\"              \n[42] \"Grants Manager\"                            \n[43] \"HR Manager\"                                \n[44] \"Graduate Student\"                          \n[45] \"Director of Software Engineering\"          \n[46] \"Clinical Trainer\"                          \n[47] \"Quality Manager\"                           \n[48] \"Veterinary technician supervisor\"          \n[49] \"Executive Director\"                        \n\n$Engineering\n [1] \"Data Engineer\"                     \"Frontend Engineer\"                \n [3] \"Devops Engineer\"                   \"Software Engineer\"                \n [5] \"Senior Software Engineer\"          \"Cognitive implementation engineer\"\n [7] \"Water Resources Engineer\"          \"Staff Engineering Analyst\"        \n [9] \"Mechanical drafter\"                \"IT Business Analyst\"              \n[11] \"Web Developer\"                     \"Security engineer\"                \n[13] \"Software Dev\"                      \"Database Administrator\"           \n\n$Science\n [1] \"Postdoc\"                        \"Research manager\"              \n [3] \"Psychotherapist\"                \"Financial Controller\"          \n [5] \"Director of Research Services\"  \"Associate Professor\"           \n [7] \"Geologist\"                      \"Machine Learning Engineer\"     \n [9] \"Cytogenetics Technologist\"      \"Psychologist\"                  \n[11] \"Licensed Clinical Psychologist\" \"Partner\"                       \n[13] \"Actuary\"                        \"Chemical Engineer\"             \n\n$Education\n[1] \"Teacher\"                                \n[2] \"World Language teacher\"                 \n[3] \"High school teacher\"                    \n[4] \"EL kindergarten teacher\"                \n[5] \"Adjunct professor and exhibiting artist\"\n[6] \"Associate Director of Admissions\"       \n[7] \"Professor of [Humanities Discipline]\"   \n[8] \"Instructor\"                             \n\n$Law\n[1] \"Attorney\"                                  \n[2] \"Lawyer\"                                    \n[3] \"Patent attorney\"                           \n[4] \"Licensed Mental Health Counselor\"          \n[5] \"Global digital and social media HR manager\"\n\n$Finance\n[1] \"Financial Controller\"            \"Forecasting Analyst\"            \n[3] \"Billing Manager\"                 \"Loan Processor\"                 \n[5] \"Accounting Assistant\"            \"Bookkeeper\"                     \n[7] \"investment advisor\"              \"Director of Revenue Cycle & EHR\"\n\n$Healthcare\n[1] \"Psychotherapist\"                  \"RN coordinator\"                  \n[3] \"Veterinary technician supervisor\" \"Clinical Trainer\"                \n\n$IT\n[1] \"Communications Logistics Analyst\"   \"Communications Strategist\"         \n[3] \"Digital Account Manager\"            \"IT Helpdesk Assistant\"             \n[5] \"Web Developer\"                      \"Database Administrator\"            \n[7] \"Salesforce administrator/developer\" \"Software Engineer 2\"               \n\n$Marketing\n[1] \"Communications Strategist\"           \n[2] \"Senior Digital Marketing Executive\"  \n[3] \"Marketing and Communications Manager\"\n[4] \"Marketing Coordinator\"               \n[5] \"VP Membership and Programs\"          \n\n$Research\n[1] \"Postdoc\"                       \"Research manager\"             \n[3] \"Director of Research Services\" \"Research scientist\"           \n[5] \"Program Coordinator\"           \"Resource specialist\"          \n[7] \"Graduate Student\"             \n\n$Sales\n[1] \"Sales analyst\"              \"Solutions Consultant\"      \n[3] \"Lead Product Designer\"      \"VP Membership and Programs\"\n\n$Other\n[1] \"Communications associate\" \"stripper\"                \n[3] \"student\"                  \"Games Specialist\"        \n[5] \"product photographer\"     \"Waitress\"                \n\n\n\n\n2.2 Classification\nOnce we identify the classification groups like in Section 2.1 or otherwise, we can classify each job title to one of these groups as below. We’ll only classify 20 observations as this will be time consuming for a demonstration.\n\ngroups &lt;- paste0(names(job_groups), collapse = \", \")\njob_classifier &lt;- chat_ollama(model = \"llama3.1:8b\",\n                          system_prompt = paste0(\"Classify the input text to [\", groups,\"]. Just return the group only.\"),\n                          seed = 1,\n                          api_args = list(top_p = 0.5,\n                                          temperature = 0))\njobs &lt;- map_chr(salary_sample$job_title[1:20], ~job_classifier$chat(.x))\n\nThe resulting classification can be seen in Table 2. Do you agree with the classifications? Some I don’t agree with (e.g. Technical Writer grouped as Engineering but most others look good to me).\n\n\n\n\nTable 2: The classification of the job title to a group.\n\n\n\n\n\n\nJob Title\nGroup\n\n\n\n\nTechnical Writer\nEngineering\n\n\nExecutive assistant\nManagement\n\n\nArchivist\nOther\n\n\nAssociate Director of Admissions\nEducation\n\n\nSenior examiner (claims)\nLaw\n\n\nLibrary Director\nEducation\n\n\nMachine Learning Engineer\nEngineering\n\n\nAssistant Director, Finance\nFinance\n\n\nLibrarian\nEducation\n\n\nLearning Designer\nEducation\n\n\nSenior policy analyst\nLaw\n\n\nOperations Manager\nManagement\n\n\nLead Marketing Analyst\nMarketing\n\n\nProduction manager\nEngineering\n\n\nSr. Executive Assistant\nManagement\n\n\nRegulatory Manager\nLaw\n\n\nFinance Director\nFinance\n\n\nAssistant manager\nManagement\n\n\nSolicitor\nLaw\n\n\nBilling Manager\nFinance\n\n\n\n\n\n\n\n\nIt is best to scan all classification and if there is only a small issue, you can manually correct these. If there are more, you can give some examples of what is the correct classification to LLM and reclassify all.\n\n\n2.3 Standardise data\nIn the survey, respondents entered their country by text entry. If you look at the entries below, you’ll notice that there are many variations of the same country, e.g. “United States” and “USA”.\n\nsalary_sample |&gt; \n  # there is one entry, which is an \n  # answer to another question so remove for now\n  filter(nchar(country) &lt; 25) |&gt; \n  count(country, sort = TRUE) |&gt; \n  print(n = Inf)\n\n# A tibble: 29 × 2\n   country                      n\n   &lt;chr&gt;                    &lt;int&gt;\n 1 United States              141\n 2 USA                        128\n 3 US                          34\n 4 Canada                      23\n 5 United Kingdom               8\n 6 United States of America     8\n 7 U.S.                         7\n 8 UK                           7\n 9 Usa                          5\n10 Ireland                      4\n11 united states                4\n12 usa                          4\n13 Australia                    3\n14 Germany                      3\n15 England                      2\n16 Netherlands                  2\n17 The Netherlands              2\n18 Uk                           2\n19 United states                2\n20 CANADA                       1\n21 China                        1\n22 France                       1\n23 IS                           1\n24 India                        1\n25 Israel                       1\n26 New zealand                  1\n27 Philippines                  1\n28 SWITZERLAND                  1\n29 U.S                          1\n\n\nYou can use a method similar to Section 2.2 to standardise the country entries, however, this has been conveniently wrapped as a function sai_fct_match in the SAI package.\n\ncountry &lt;- sai_fct_match(\n  salary_sample$country,\n  levels = c(\n    \"United States America\",\n    \"Canada\",\n    \"United Kingdom\",\n    \"Ireland\",\n    \"Iceland\",\n    \"India\",\n    \"Israel\",\n    \"New Zealand\",\n    \"Switzerland\",\n    \"Philippines\",\n    \"China\",\n    \"France\",\n    \"Netherlands\",\n    \"Australia\",\n    \"Germany\"\n  )\n)\n\nThe above conversion can be seen in Table 3. You can notice that while most are correct, not all where mapped correctly. Since these are only small numbers of these, you can correct these manually.\n\n\n\n\nTable 3: Conversion of the country to select levels.\n\n\n\n\n\n\n\n\n\n\noriginal\nconverted\n\n\n\n\nUnited States\nUnited States America\n\n\nCanada\nCanada\n\n\nUSA\nUnited States America\n\n\nUS\nUnited States America\n\n\nUnited states\nUnited States America\n\n\nUnited States of America\nUnited States America\n\n\nNew zealand\nNew Zealand\n\n\nUnited Kingdom\nUnited Kingdom\n\n\nUK\nUnited Kingdom\n\n\nUk\nUnited Kingdom\n\n\nusa\nUnited States America\n\n\nUsa\nUnited States America\n\n\nGermany\nGermany\n\n\nAustralia\nAustralia\n\n\nIndia\nIndia\n\n\nIsrael\nIsrael\n\n\nunited states\nUnited States America\n\n\nNetherlands\nNetherlands\n\n\nSWITZERLAND\nSwitzerland\n\n\nU.S\nUnited States America\n\n\nU.S.\nUnited States America\n\n\nThe Netherlands\nNA\n\n\nI was brought in on this salary to help with the EHR and very quickly was promoted to current position but compensation was not altered.\nUnited States America\n\n\nIreland\nIreland\n\n\nFrance\nFrance\n\n\nChina\nChina\n\n\nEngland\nUnited Kingdom\n\n\nIS\nUnited States America\n\n\nPhilippines\nPhilippines\n\n\nCANADA\nCanada"
  },
  {
    "objectID": "demo/demo2.html",
    "href": "demo/demo2.html",
    "title": "Playing with model parameters",
    "section": "",
    "text": "This demo assumes that you have all the software requirements.\nWhile not all LLMs are the same, there are some parameters that are common across many of the LLM. Note that the names of these parameters (and its exact interpretation and specification) may differ across LLM. Ultimately, you have to dig into the documentation (or code) to find what parameters are available to you and how to use it.\nlibrary(elmer)\nI’ll be using Ollama with llama3.1:8b for the examples below, but you can replace these chat_ollama() with your preferred vendor and model instead. I’ll use gpt-4o-mini for the structured output example as this feature is not available in Ollama.\nWe’ll look at the use of different model parameters. For each parameter, let’s consider some “actors” and see what the response is like."
  },
  {
    "objectID": "demo/demo2.html#temperature",
    "href": "demo/demo2.html#temperature",
    "title": "Playing with model parameters",
    "section": "1 temperature",
    "text": "1 temperature\nA higher temperature results in a diverse response, while a lower temperature results in selection of more probable texts. In general, select a lower temperature for more predictable and sensible responses.\n\nbe_statistician &lt;- \"Respond like a statistician but keep it concise. No more than 80 words.\"\n\n\nsensible_statistician &lt;- chat_ollama(system_prompt = be_statistician,\n                                     seed = 1,\n                                     model = \"llama3.1:8b\",\n                                     api_args = list(temperature = 0),\n                                     echo = TRUE)\n\ncreative_statistician &lt;- chat_ollama(system_prompt = be_statistician,\n                                     seed = 1,\n                                     model = \"llama3.1:8b\", \n                                     api_args = list(temperature = 40),\n                                     echo = TRUE)\n\nsensible_statistician$chat(\"My p-value is 0.049. Is this significant?\")\n\nA p-value of 0.049 is indeed statistically significant, typically considered so\nat the 5% significance level (α = 0.05). However, it's worth noting that some \nresearchers consider a more stringent threshold, such as α = 0.01 or Bonferroni\ncorrection, to account for multiple comparisons.\n\ncreative_statistician$chat(\"My p-value is 0.049. Is this significant?\") \n\nNesting ambiguity concerns a researcher trying (a test at \nborderline-signiciance can make difficult calls (fuzz). This specific point \nmight result, when (null). P ≤ (you 5 &lt; a), not a clear signal to say your \ndiscovery statistically def the result meaningful – proceed discern between \n(signal statistical signiffie). The literature suggests not claiming without \nsubstantial power of rep in further replication attempts consider an interim \nnull result be wise. However. Many journals allow justifiable in well-present \nthis context is often tolerated so - no - p-val is 'mature sig, in your paper \n99%) likely ok' 99 per- to claim – that –' (say so  ' – no . – good go &lt; this) \nno' you've 'got the' answer.' – Yes 1.' significant a&lt;0/7: not a p &gt;5 the \nsignificance threshold set is arbitrary but most 95 percent convention holds \nits significance - but there lies your true – (soul-) value in any science is \nnot always by an empty p-stat. '"
  },
  {
    "objectID": "demo/demo2.html#top_p",
    "href": "demo/demo2.html#top_p",
    "title": "Playing with model parameters",
    "section": "2 top_p",
    "text": "2 top_p\ntop_p should be a value between 0 and 1 (inclusive). A value of less than 1 ensures that the most unlikely responses will not get selected, however high the temperature is. You can use top_p combined with a higher temperature to get restraint creative responses.\n\nrestraint_statistician &lt;- chat_ollama(system_prompt = be_statistician,\n                                      seed = 1,\n                                      model = \"llama3.1:8b\", \n                                      api_args = list(temperature = 40, \n                                                      top_p = 0.5),\n                                      echo = TRUE)\n\nrestraint_statistician$chat(\"My p-value is 0.049. Is this significant?\") \n\nA value of 0.049 is just barely below the conventional significance threshold \nof 0.05. However, due to the \"p-hacking\" issue, some researchers consider \nvalues between 0.04 and 0.06 as not fully reliable. It's a borderline case. I'd\nrecommend conducting a power analysis or exploring alternative explanations \nbefore concluding significance."
  },
  {
    "objectID": "demo/demo2.html#seed",
    "href": "demo/demo2.html#seed",
    "title": "Playing with model parameters",
    "section": "3 seed",
    "text": "3 seed\nThe seed ensures that the same random sample is chosen.\n\nbe_pirate &lt;- \"Respond like a pirate but keep it to 10 words.\"\npirate1 &lt;- chat_ollama(model = \"llama3.1:8b\",\n                       system_prompt = be_pirate,\n                       seed = 1,\n                       echo = TRUE)\npirate2 &lt;- chat_ollama(model = \"llama3.1:8b\",\n                       system_prompt = be_pirate,\n                       seed = 2,\n                       echo = TRUE)\npirate3 &lt;- chat_ollama(model = \"llama3.1:8b\",\n                       system_prompt = be_pirate,\n                       seed = 1,\n                       echo = TRUE)\n\nAbove pirate1 and pirate3 have the same seed, whilst pirate2 have a different seed. The other model parameters are all the same (default) for all three pirates.\n\npirate1$chat(\"Hi!\")\n\nMatey, lovely day fer sailin', be ye?\n\npirate2$chat(\"Hi!\")\n\nArrr, welcome aboard me ship, matey, come aboard!\n\npirate3$chat(\"Hi!\")\n\nMatey, lovely day fer sailin', be ye?"
  },
  {
    "objectID": "demo/demo2.html#stop",
    "href": "demo/demo2.html#stop",
    "title": "Playing with model parameters",
    "section": "4 stop",
    "text": "4 stop\nstop words specify when the LLM should stop generating new texts.\n\npirate4 &lt;- chat_ollama(model = \"llama3.1:8b\",\n                       system_prompt = be_pirate,\n                       seed = 1,\n                       api_args = list(stop = \"matey\"),\n                       echo = TRUE)\n\nNotice below, the sentence stops midway as the next word was likely “matey”, the stop word.\n\npirate4$chat(\"Hi\")\n\nMe hearty, Arrr, welcome aboard"
  },
  {
    "objectID": "demo/demo2.html#response_format",
    "href": "demo/demo2.html#response_format",
    "title": "Playing with model parameters",
    "section": "5 response_format",
    "text": "5 response_format\nThe default response format is text, but you can have a more structured output with JSON output.\n\n5.1 JSON format\nThe response_format is useful for getting a structured response. For data processing tasks, this is arguably the most useful feature. If you use JSON format, you need to make sure that you tell the system that you want the format as JSON somewhere, otherwise you may end up getting a lot of white spaces.\n\nstatistician &lt;- chat_ollama(model = \"llama3.1:8b\",\n                            seed = 1,\n                            system_prompt = paste0(be_statistician, \" Return the format as json.\"),\n                            api_args = list(response_format = list(type = \"json_object\"),\n                                            temperature = 0),\n                            echo = TRUE)\n\nThe answer is in JSON format.\n\nout &lt;- statistician$chat(\"Could you tell me what the probability of getting a head four times if I toss the coin 4 times? Just return the probability.\")\n\n{\n\"probability\": 0.0625\n}\n\n\nBut it’s stored as a character.\n\nclass(out)\n\n[1] \"character\"\n\n\nLet’s convert this to a list object by converting the character to list using jsonlite::fromJSON().\n\njsonlite::fromJSON(out)\n\n$probability\n[1] 0.0625\n\n\nThe user prompt asks to specifically return the probability only, but sometimes the output format can have different JSON output.\n\n\n5.2 Structured output\nIf you need a strict format, then Open AI models starting with GPT-4o allows this by specifying the JSON schema. Be warned specifying this is rather cumbersome as seen next.\nIn R, you can write the schema as a list (it will convert to JSON object for you). The list has to have a particular structure. In the top level, you have to include type = \"json_schema\" and specify what the schema is in json_schema = list(...). In the json_schema you will need to define another list containing the named elements strict (a logical value indicating whether it needs to strictly adhere to the schema or not), name (a short name of the schema), an optional description, and schema (where you actually define your output schema).\nWithin schema, you need to define another list where at each level, you specify the type (e.g. type = \"number\" for a numerical output, see Table 1 for other types and their corresponding class in R), properties if type = \"object\" or items if type = \"array\", an optional description, what elements are required, and whether additional properties can be returned or not (additionalProperties). You can also limit the choice of the output to selected entries using enum or anyOf.\n\n\n\nTable 1: Table of supported types in structured output.\n\n\n\n\n\nJSON type\nR class\n\n\n\n\n“string”\n“character”\n\n\n“number”\n“numeric”\n\n\n“boolean”\n“logical”\n\n\n“integer”\n“integer”\n\n\n“object”\n“list”\n\n\n“array”\n“data.frame”\n\n\n\n\n\n\nSuppose that we want the output with a structure shown in Figure 1.\n\n\n\n\n\n\nflowchart LR\n  response(\"response\\n(list)\") --&gt; steps(\"steps\\n(data.frame)\")\n  response --&gt; final_answer(\"final_answer\\n(numeric)\")\n  steps --&gt; explanation(\"explanation\\n(character)\")\n  steps --&gt; output(\"output\\n(character)\")\n  final_answer\n  linkStyle default stroke: black\n\n\n\n\nFigure 1: The desired structured output.\n\n\n\n\n\nThe schema in Figure 1 is coded as a list below.\n\njson_schema &lt;- list(\n  type = \"json_schema\",\n  json_schema = list(\n    strict = TRUE,\n    name = \"math_reasoning\",\n    description = \"Provide the reasoning behind the answer.\",\n    schema = list(\n      type = \"object\",\n      properties = list(\n        steps = list(\n          description = \"Provide the steps to the answer.\",\n          type = \"array\",\n          items = list(\n            type = \"object\",\n            properties = list(\n              explanation = list(type = \"string\"),\n              output = list(type = \"string\")\n            ),\n            required = c(\"explanation\", \"output\"),\n            additionalProperties = FALSE\n          )\n        ),\n        final_answer = list(type = \"number\",\n                            description = \"Give the numerical answer.\")\n      ),\n      required = c(\"steps\", \"final_answer\"),\n      additionalProperties = FALSE\n    )\n  )\n)\n\nThe schema stored in json_schema is parsed to response_format below.\n\ntame_statistician &lt;- chat_openai(\n  system_prompt = paste0(be_statistician, \" Return the format as json.\"),\n  model = \"gpt-4o-mini\",\n  seed = 1,\n  api_args = list(\n    response_format = json_schema,\n    temperature = 0\n  )\n)\n\nThe output is shown below.\n\nout &lt;- tame_statistician$chat(\"Could you tell me what the probability of getting a head four times if I toss the coin 4 times?\") |&gt; \n  jsonlite::fromJSON()\n\nout\n\n$steps\n                                                                                                      explanation\n1                           Identify the total number of outcomes when tossing a coin 4 times, which is 2^4 = 16.\n2                              Determine the number of favorable outcomes for getting 4 heads, which is 1 (HHHH).\n3 Calculate the probability as the number of favorable outcomes divided by the total outcomes: P(4 heads) = 1/16.\n  output\n1     16\n2      1\n3   1/16\n\n$final_answer\n[1] 0.0625\n\n\nLooking at the structure, you can see it matches with the desired output in Figure 1.\n\nstr(out)\n\nList of 2\n $ steps       :'data.frame':   3 obs. of  2 variables:\n  ..$ explanation: chr [1:3] \"Identify the total number of outcomes when tossing a coin 4 times, which is 2^4 = 16.\" \"Determine the number of favorable outcomes for getting 4 heads, which is 1 (HHHH).\" \"Calculate the probability as the number of favorable outcomes divided by the total outcomes: P(4 heads) = 1/16.\"\n  ..$ output     : chr [1:3] \"16\" \"1\" \"1/16\"\n $ final_answer: num 0.0625"
  },
  {
    "objectID": "demo/demo2.html#max_tokens-or-max_completion_tokens",
    "href": "demo/demo2.html#max_tokens-or-max_completion_tokens",
    "title": "Playing with model parameters",
    "section": "6 max_tokens or max_completion_tokens",
    "text": "6 max_tokens or max_completion_tokens\nOpen AI originally used max_tokens but deprecated this so now it is named max_completion_tokens. max_tokens still works for older models but you may need to use max_completion_tokens for future models. Ollama uses max_tokens.\n\nhaiku &lt;- chat_ollama(model = \"llama3.1:8b\",\n                     seed = 1,\n                     system_prompt = \"Be poetic.\",\n                     api_args = list(max_tokens = 17),\n                     echo = TRUE)\n\nshort &lt;- chat_ollama(model = \"llama3.1:8b\",\n                     seed = 2,\n                     system_prompt = \"Be poetic.\",\n                     api_args = list(max_tokens = 5),\n                     echo = TRUE)\n\nhaiku$chat(\"Tell me more about p-values?\")\n\nOh, the humbling tale of p-values,\n\nA statistical test, oft-praised\n\nshort$chat(\"Tell me more about p-values?\")\n\nThe mystical realm of p"
  },
  {
    "objectID": "demo/demo1.html",
    "href": "demo/demo1.html",
    "title": "Interfacing with large language models",
    "section": "",
    "text": "This demo assumes that you have all the software requirements.\nTo access the LLM API via curl, we can use httr2 R package (as shown in Section 2), but the elmer R package (Section 3) provides a more user-friendly interface so we use the latter as our primary method. Finally, for those interested in producing a Shiny web app, shinychat and Shiny Assistant will be briefly demonstrated in Section 4.\nI will demonstrate using two methods via: Open AI and Ollama. You can choose to code along with one or both, or none! As mentioned before, there will likely not be time to debug individual technical issues."
  },
  {
    "objectID": "demo/demo1.html#using-open-ai",
    "href": "demo/demo1.html#using-open-ai",
    "title": "Interfacing with large language models",
    "section": "2.1 Using Open AI",
    "text": "2.1 Using Open AI\n\njson &lt;- request(base_url = \"https://api.openai.com/v1/chat/completions\") |&gt; \n  req_headers('Authorization' = paste('Bearer', Sys.getenv(\"OPENAI_API_KEY\")),\n              'Content-Type' = 'application/json') |&gt; \n  req_body_json(data = list(model = \"gpt-4o-mini\",\n                            messages = list(list(role = \"user\",\n                                                 content = content)))) |&gt; \n  req_perform() |&gt; \n  resp_body_json()\n\ncat(json$choices[[1]]$message$content)\n\nuseful. This phrase, often attributed to the statistician George E. P. Box, emphasizes that while no model can perfectly represent reality, many can still provide valuable insights and predictions. The key is to understand the limitations of a model and to use it appropriately within its context. It's about leveraging the model's strengths while recognizing its shortcomings."
  },
  {
    "objectID": "demo/demo1.html#using-ollama",
    "href": "demo/demo1.html#using-ollama",
    "title": "Interfacing with large language models",
    "section": "2.2 Using Ollama",
    "text": "2.2 Using Ollama\n\njson &lt;- request(base_url = \"http://localhost:11434/api/chat\") |&gt; \n  req_body_json(data = list(model = \"llama3.1:8b\",\n                            messages = list(list(role = \"user\",\n                                                 content = content)),\n                            stream = FALSE)) |&gt; \n  req_perform() |&gt; \n  resp_body_json()\n\ncat(json$message$content)\n\nA famous quote from George Box!\n\n\"Essentially, all models are wrong, but some are useful.\"\n\n― George E. P. Box, statistician and mathematician\n\nBox was a renowned expert in statistics and modeling, and his quote highlights the importance of understanding the limitations of any model or prediction system.\n\nIn essence, it means that no mathematical model can perfectly capture reality, as there will always be some degree of error or uncertainty involved. However, by acknowledging these limitations and selecting models based on their usefulness and applicability to a specific problem, we can still gain valuable insights and make informed decisions.\n\nThis quote is often cited in the context of data science, machine learning, and statistics, serving as a reminder that:\n\n1. **Models are simplifications**: They reduce complex phenomena to manageable mathematical expressions.\n2. **Data is noisy**: There will always be some degree of error or variability in observations.\n3. **Uncertainty exists**: It's impossible to capture all the nuances and complexities of reality with absolute precision.\n\nDespite these limitations, models can still provide valuable predictions, insights, and guidance for decision-making, as long as they are carefully selected, validated, and used within their realm of applicability.\n\nWhat inspired you to ask about this quote? Do you have any specific context or interest in modeling, statistics, or data science?"
  },
  {
    "objectID": "demo/demo1.html#using-ai-vendors-api",
    "href": "demo/demo1.html#using-ai-vendors-api",
    "title": "Interfacing with large language models",
    "section": "3.1 Using AI vendor’s API",
    "text": "3.1 Using AI vendor’s API\nelmer currently supports the AI vendors in Table 1. To use the API, you need to sign up for an account with the vendor and obtain an API key (you may need to pay for some small credit to use this). We will only focus on Open AI where I have put a credit of US$5 (so far) to use their services. The API key can be set in a similar manner to Open AI API key (described in Section 1), but using the corresponding environmental variable name.\n\n\n\n\nTable 1: AI vendors\n\n\n\n\n\n\n\nAI vendor\nName\nLink\nEnvironmental Variable\n\n\n\n\nAnthropic\nclaude\nhttps://www.anthropic.com/claude\nANTHROPIC_API_KEY\n\n\nGoogle\ngemini\nhttps://gemini.google.com/\nGOOGLE_API_KEY\n\n\nGitHub (waitlist only)\ngithub\nhttps://github.com/marketplace/models\nGITHUB_PAT\n\n\nGroq\ngroq\nhttps://groq.com\nGROQ_API_KEY\n\n\nOllama\nollama\nhttps://ollama.com/\nN/A\n\n\nOpen AI\nopenai\nhttps://platform.openai.com/\nOPENAI_API_KEY\n\n\nPerplexity AI\nperplexity\nhttps://www.perplexity.ai\nPERPLEXITY_API_KEY\n\n\n\n\n\n\n\n\n\n\n\nOnce you have set up the API key, you can use the elmer package to interact with the AI vendor’s API.\n\nchat_openai &lt;- chat_openai(model = \"gpt-4o-mini\", seed = 1, echo = TRUE)\n\nchat_openai$chat(\"Tell me a statistics joke!\")\n\nWhy did the statistician bring a ladder to the bar?\n\nBecause he heard the drinks were on the house!"
  },
  {
    "objectID": "demo/demo1.html#using-a-local-llm",
    "href": "demo/demo1.html#using-a-local-llm",
    "title": "Interfacing with large language models",
    "section": "3.2 Using a local LLM",
    "text": "3.2 Using a local LLM\n\nchat_ollama &lt;- chat_ollama(model = \"llama3.1:8b\", seed = 1, echo = TRUE)\n\nchat_ollama$chat(\"Tell me a statistics joke!\")\n\nA stats joke has to be \"number one\" in your book, right?\n\nHere's the joke:\n\nWhy did the mean go to therapy?\n\nBecause it was feeling a little \"off-average\"!\n\n(Sorry, I know it's a bit of a statistician's pun... but that's just a p-value \nchance, right?)\n\n\nWhich joke was funnier? 😄"
  },
  {
    "objectID": "demo/demo1.html#interactive-usage",
    "href": "demo/demo1.html#interactive-usage",
    "title": "Interfacing with large language models",
    "section": "3.3 Interactive usage",
    "text": "3.3 Interactive usage\nYou can use a chatbot via console:\n\nchat_console(chat_ollama) # live_console(chat_ollama) if you have a newer version\n\nOr alternatively, via the browser:\n\nchat_browser(chat_ollama) # live_browser(chat_ollama) if you have a newer version"
  },
  {
    "objectID": "demo/demo1.html#shinychat",
    "href": "demo/demo1.html#shinychat",
    "title": "Interfacing with large language models",
    "section": "4.1 shinychat",
    "text": "4.1 shinychat\nYou can easily make a Shiny web app that incorporates a nice chat user interface using shinychat.\nlibrary(shiny)\nlibrary(shinychat)\n\nui &lt;- fluidPage(\n  chat_ui(\"chat\")\n)\n\nserver &lt;- function(input, output, session) {\n  chat &lt;- elmer::chat_openai(system_prompt = \"You're a helpful statistics tutor.\")\n  \n  observeEvent(input$chat_user_input, {\n    stream &lt;- chat$stream_async(input$chat_user_input)\n    chat_append(\"chat\", stream)\n  })\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "demo/demo1.html#shiny-assistant",
    "href": "demo/demo1.html#shiny-assistant",
    "title": "Interfacing with large language models",
    "section": "4.2 Shiny Assistant",
    "text": "4.2 Shiny Assistant\nShiny Assistant is an AI assistant to help you build Shiny apps! See the blog post about it here and to use it, go to https://gallery.shinyapps.io/assistant."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Statistics with R",
    "section": "",
    "text": "Optimal viewing experience\n\n\n\nPlease note that this website is best viewed using desktop or laptop computers using Google Chrome."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Introduction to Statistics with R",
    "section": "",
    "text": "Optimal viewing experience\n\n\n\nPlease note that this website is best viewed using desktop or laptop computers using Google Chrome."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Introduction to Statistics with R",
    "section": "🎯 Learning objectives",
    "text": "🎯 Learning objectives"
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Introduction to Statistics with R",
    "section": "🔧 Software requirements",
    "text": "🔧 Software requirements\nPlease ensure that you download and install\n\nthe latest version of R,\nan interactive development environment like RStudio Desktop, and\nthe following packages by opening RStudio Desktop, then copy and paste the command below in the Console section, pushing Enter after pasting.\n\ninstall.packages('tidyverse')\n\nFor Window users, you may need to install Rtools to install R packages."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Introduction to Statistics with R",
    "section": "🕜 Schedule",
    "text": "🕜 Schedule\n\n\n\n\n\nDay\nPerth\nBrisbane\nAdelaide\nAEDT\nContent\n\n\n\n\nTue\n08:00am\n10:00am\n10:30am\n11:00am\nIntroductions\n\n\n\n08:10am\n10:10am\n10:40am\n11:10am\nParametric distributions to describe and simulate data\n\n\n\n09:30am\n11:30am\n12:00pm\n12:30pm\nBreak\n\n\n\n10:30am\n12:30pm\n01:00pm\n01:30pm\nIntroduction to statistical inference\n\n\n\n12:00pm\n02:00pm\n02:30pm\n03:00pm\nBreak\n\n\n\n12:15pm\n02:15pm\n02:45pm\n03:15pm\nSimple linear regression\n\n\nWed\n08:00am\n10:00am\n10:30am\n11:00am\nModelling with continuous responses\n\n\n\n09:30am\n11:30am\n12:00pm\n12:30pm\nBreak\n\n\n\n10:30am\n12:30pm\n01:00pm\n01:30pm\nModelling with categorical predictors\n\n\n\n12:00pm\n02:00pm\n02:30pm\n03:00pm\nBreak\n\n\n\n12:15pm\n02:15pm\n02:45pm\n03:15pm\nModelling with categorical response\n\n\n\n01:35pm\n03:35pm\n04:05pm\n04:35pm\nWrap-up"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Introduction to Statistics with R",
    "section": "📚 Slides",
    "text": "📚 Slides\n\n\n\n\n\n\n\n\n\n\nIntroductions\n\n\nSlide 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nParametric distributions to describe and simulate data\n\n\nSlide 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to statistical inference\n\n\nSlide 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple linear regression\n\n\nSlide 4\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with continuous responses\n\n\nSlide 5\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical predictors\n\n\nSlide 6\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical response\n\n\nSlide 7\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrap-up\n\n\nSlide 8\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#demos",
    "href": "index.html#demos",
    "title": "Introduction to Statistics with R",
    "section": "️ Demos",
    "text": "️ Demos\n\n\n\n\n\n\n\n\n\n\nInterfacing with large language models\n\n\nDemo 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying with model parameters\n\n\nDemo 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplications to real data\n\n\nDemo 3\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#sec-license",
    "href": "index.html#sec-license",
    "title": "Introduction to Statistics with R",
    "section": " License",
    "text": "License\nThese  workshop materials by Emi Tanaka is licensed under CC BY-NC-ND 4.0 – which means you can share the link with your colleagues, peers, friends, family and so on, so long as due credit is given to the author. However, you cannot commercialise or create derivatives from this work without the permission of the author (emi.tanaka@anu.edu.au)."
  },
  {
    "objectID": "slides/slide1.html#schedule",
    "href": "slides/slide1.html#schedule",
    "title": "Introductions",
    "section": "Schedule*",
    "text": "Schedule*\n\n\n\nTime (AEDT)\nTopic\n\n\n\n\n1.30PM - 1.35PM\nIntroductions\n\n\n1.35PM - 3.00PM\nLandscape of Large Language Models\n\n\n\nR Demo #1 and #2\n\n\n3.00PM - 3.15PM\nBreak\n\n\n3.15PM - 4.25PM\nArchitectures of Large Language Models\n\n\n\nR Demo #3\n\n\n4.25PM - 4.45PM\nDiscussion & Conclusion\n\n\n\n\n\n*May go out of schedule"
  },
  {
    "objectID": "slides/slide3.html#overview-of-training-a-llm",
    "href": "slides/slide3.html#overview-of-training-a-llm",
    "title": "Architecture of Large Language Models",
    "section": "Overview of training a LLM",
    "text": "Overview of training a LLM\n\n  Corpus (raw) \n\n   Preprocessed Training Data      Tokenized Training Data      Base LLM      Fine-tuned LLM  \n\n  Corpus (labelled)"
  },
  {
    "objectID": "slides/slide3.html#corpora-for-training-data",
    "href": "slides/slide3.html#corpora-for-training-data",
    "title": "Architecture of Large Language Models",
    "section": "Corpora for training data",
    "text": "Corpora for training data\n\n  Corpus (raw) \n\n\nLLMs are trained on large diverse datasets such as books, Wikipedia, websites, code, scientific articles and social network platforms.\n\n\n\nFor example, LLaMA1 used:\n\n(67%) CommonCrawl: web archives from 2017 to 2020\n(15%) C4: pre-processed CommonCrawl\n(4.5%) GitHub: repos distributed under Apache, BSD, and MIT licenses\n(4.5%) Wikipedia: online encyclopaedia\n(4.5%) Gutenberg and Books3: books from Project Gutenberg and the Pile dataset\n(2.5%) ArXiv: scientific preprints\n(2%) Stack Overflow: a high quality Q&A website\n\n\n\nTouvron et al. (2023) “LLaMA: Open and Efficient Foundation Language Models,” Feb. 27, 2023, arXiv preprint: arXiv:2302.13971"
  },
  {
    "objectID": "slides/slide3.html#corpus-size-used-for-training-increasing-over-time",
    "href": "slides/slide3.html#corpus-size-used-for-training-increasing-over-time",
    "title": "Architecture of Large Language Models",
    "section": "Corpus size used for training increasing over time",
    "text": "Corpus size used for training increasing over time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: not all vendors publicly document their corpus size for training."
  },
  {
    "objectID": "slides/slide3.html#tokenization",
    "href": "slides/slide3.html#tokenization",
    "title": "Architecture of Large Language Models",
    "section": "Tokenization",
    "text": "Tokenization\nInput  Where there’s a will, there’s a \n\nToken  Where    there   ’s    a    will   ,    there   ’s    a \nToken ID  11977   1354   802   261   738   11   1354   802   261 \n    LLM  \n 2006 \n way \n   \n\n\nSee also Open AI tokenizer: https://platform.openai.com/tokenizer"
  },
  {
    "objectID": "slides/slide3.html#embeddings",
    "href": "slides/slide3.html#embeddings",
    "title": "Architecture of Large Language Models",
    "section": "Embeddings",
    "text": "Embeddings\n\n\nLanguage modelling typically use (token) embeddings.\nEmbedding models convert items to numerical vectors such that similar items are closer together than dissimilar items based on this embedding space.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText embedding models are often based on artificial neural networks."
  },
  {
    "objectID": "slides/slide3.html#artificial-neuron",
    "href": "slides/slide3.html#artificial-neuron",
    "title": "Architecture of Large Language Models",
    "section": "Artificial neuron",
    "text": "Artificial neuron\n\n\nThe artificial neuron is an elementary unit of an artificial neural network.\nThe artificial neuron receives inputs \\boldsymbol{x} = (x_{1}, \\dots,x_{p})^\\top that is typically combined as a weighted sum: z = b + \\sum_{j=1}^pw_jx_{j} = b +  \\boldsymbol{w}^\\top\\boldsymbol{x}, where \\boldsymbol{w} = (w_1, \\dots, w_p)^\\top are weights and b referred to as bias.\nThe z then get passed into the activation function, h(z), e.g. \n\nLinear: h(z) = z,\nSigmoid: h(z) = (1+e^{-z})^{-1} (a.k.a. a logistic function), and\nReLU: h(z) =  \\max(0, z)."
  },
  {
    "objectID": "slides/slide3.html#visualising-an-artifical-neuron",
    "href": "slides/slide3.html#visualising-an-artifical-neuron",
    "title": "Architecture of Large Language Models",
    "section": "Visualising an artifical neuron",
    "text": "Visualising an artifical neuron\n\n\n\n\n\nInput layer\n1\n\nx_1\n\nx_2\n\n\n\n\n\nOutput layer   h = ReLU  \nh(z)\n    \n\n\n\n\n\n\n\nWhen x_1 = 1 and x_2 = 3, then \\begin{align*}z &= b + w_1x_1 + w_2 x_2\\\\ &= 1 + 0.5 \\times 1 - 3\\times 3 = -7.5.\\end{align*}\nUsing ReLU, the prediction is \\max(0, z) = 0."
  },
  {
    "objectID": "slides/slide3.html#artifical-neural-network-regression",
    "href": "slides/slide3.html#artifical-neural-network-regression",
    "title": "Architecture of Large Language Models",
    "section": "Artifical neural network: regression",
    "text": "Artifical neural network: regression\n\n\n\n\n\nInput layer\n\n1\n\nx_1\n\nx_2\n\n\n\n\n\nHidden layer  h_1 = ReLU \n1\n\nh_1(z_{11})\n\nh_1(z_{12})\n\n\n\n\n\n\nOutput layer  h_2 = Linear    \nh_2(z_{21})\n  \n\n\n\n\n \n\nThe number of nodes in the input layer is constrained by the (modified) input data.\nThe number of nodes in the output layer is constrained by the desired output (regression or classification)."
  },
  {
    "objectID": "slides/slide3.html#artifical-neural-network-classification",
    "href": "slides/slide3.html#artifical-neural-network-classification",
    "title": "Architecture of Large Language Models",
    "section": "Artifical neural network: classification",
    "text": "Artifical neural network: classification\n\n\n\n\n\nInput layer\n\n1\n\nx_1\n\nx_2\n\n\n\n\n\nHidden layer  h_1 = ReLU \n1\n\nh_1(z_{11})\n\nh_1(z_{12})\n\n\n\n\n\n\nOutput layer  h_2 = Softmax \nh_2(\\boldsymbol{z}, 1)\n\nh_2(\\boldsymbol{z}, 2)\n\nh_2(\\boldsymbol{z}, 3)\n\n\n\n\n\nAssume classification to K classes.\n\nSoftmax:\nh(\\boldsymbol{z}, i) = \\dfrac{\\exp(z_i)}{\\sum_{j=1}^K\\exp(z_j)}\nOutput node i contains the “probability score” associated with class i."
  },
  {
    "objectID": "slides/slide3.html#feed-forward-neural-network",
    "href": "slides/slide3.html#feed-forward-neural-network",
    "title": "Architecture of Large Language Models",
    "section": "Feed forward neural network",
    "text": "Feed forward neural network\n\n\n\n\nFeed forward neural networks, also called deep neural networks, add more hidden layers.\nThe output depends on the parameters, \\boldsymbol{\\theta} = (\\underbrace{\\boldsymbol{b}^\\top}_{\\text{biases}},\\underbrace{\\boldsymbol{w}^\\top}_{\\text{weights}})^\\top.\nThe number of parameters increases exponentially with more layers, but you gain flexibility in modelling.\nThese parameters are calibrated (or trained) by:\n\nDefining an objective (or loss) function (like the mean square error), and\nFinding parameters \\boldsymbol{\\theta} that optimise this objective function (using techniques like stochastic gradient descent and backpropagation)."
  },
  {
    "objectID": "slides/slide3.html#embedding-model-word2vec-for-illustration-of-an-embedding-process",
    "href": "slides/slide3.html#embedding-model-word2vec-for-illustration-of-an-embedding-process",
    "title": "Architecture of Large Language Models",
    "section": "Embedding model: Word2Vec for illustration of an embedding process",
    "text": "Embedding model: Word2Vec for illustration of an embedding process\n\nWord2Vec1 is one of the early unsupervised word embedding models based on a three-layer neural network using a fixed window size.\n\n\nTraining data:  Statisticians analyse data  Training mode: Continuous Bag Of Words Vocabulary size: 5     Window size: 3     Aim: Predict middle word\n\n\n\nStatisticians\n1 0 0 0 0\n\n\n\ndata\n0 0 1 0 0\n\n\n\n\n\nInput\n         \n\n\n\n \n     \n\n\n\nOutput\n         \n\n\n 0.01 0.89 0.04 0.01 0.01\n\n\n\n\nActual:\n\n\nanalyse\n0 1 0 0 0\n\n\n\n\n\n                        \n\nTomas Mikolov et al (2013) Efficient Estimation of Word Representations in Vector Space. https://arxiv.org/abs/1301.3781"
  },
  {
    "objectID": "slides/slide3.html#transformer-model",
    "href": "slides/slide3.html#transformer-model",
    "title": "Architecture of Large Language Models",
    "section": "Transformer model",
    "text": "Transformer model\n\n\n\nPopular LLM are variants of a pre-trained transformer model.\nThe original transformer model1 consist of:\n\nInput embeddings of current and previous positions\nPositional embeddings\nA stack of transformer blocks (N=6) with each containing:\n\nAn attention layer with multiple attention heads\nNormalisation layers\nFeed forward neural network with 3 hidden layers: Linear, ReLU, then Linear\n\nUn-embedding layer (Softmax)\n\n\n\n\n\n\nOriginal transformer model by Vaswani et al (2017)\n\n\n\n\n\nhttps://kikaben.com/transformers-encoder-decoder/\nhttps://www.datacamp.com/tutorial/how-transformers-work\n\nVaswani et al. (2017) Attention is All you Need. 31st Conference on Neural Information Processing Systems"
  },
  {
    "objectID": "slides/slide3.html#positional-embeddings",
    "href": "slides/slide3.html#positional-embeddings",
    "title": "Architecture of Large Language Models",
    "section": "Positional embeddings",
    "text": "Positional embeddings\nInput  The paired t-test p-value is 0.049, so it is statistically significant \nToken  The  paired   t   -test  p   -value   is   0  .  049  ,  so  it  is  statistically  signicant \n\n\nContext length: below 10 (typically much larger, e.g. 4096 for llama3.1:8b)\n\n\n The  paired   t   -test  p   -value   is   0  .  049 \n\n\n\n\n Transformer blocks are blind to position of token, so incorporate information about relative or absolute positions of tokens for the subsequent steps.\n\n\n\n\nPosition embedding in the original transformer is represented by unique frequencies and offsets of the wave:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPE(pos, 2i) = \\sin(pos/10000^{2i/n}) and\nPE(pos, 2i + 1) = \\cos(pos/10000^{2i/n})\n\nwhere i is dimension in the encoding and pos is the token position."
  },
  {
    "objectID": "slides/slide3.html#attention-head-projection-matrices",
    "href": "slides/slide3.html#attention-head-projection-matrices",
    "title": "Architecture of Large Language Models",
    "section": "Attention head: Projection matrices",
    "text": "Attention head: Projection matrices\n\n The goal of attention layer is to incorporate relevant information of previous tokens into the current token.\n\n\n The  paired   t   -test  p   -value   is   0  .  049 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose the current position is  049  – the neural network doesn’t know what this token refers to without looking at the previous tokens.\nThe attention head consists of query, key, and value projection matrices."
  },
  {
    "objectID": "slides/slide3.html#attention-head-relevance-scoring",
    "href": "slides/slide3.html#attention-head-relevance-scoring",
    "title": "Architecture of Large Language Models",
    "section": "Attention Head: Relevance scoring",
    "text": "Attention Head: Relevance scoring\n\nEmbedding matrix is multiplied with each of the projection matrices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\times\n\n\nThe query vector of the current position:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=\n\n\n\nResult \\rightarrow Softmax(Result)"
  },
  {
    "objectID": "slides/slide3.html#attention-head-combining-information",
    "href": "slides/slide3.html#attention-head-combining-information",
    "title": "Architecture of Large Language Models",
    "section": "Attention Head: Combining information",
    "text": "Attention Head: Combining information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\times\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum above and the new token embedding that incorporates relevant information from other tokens is:"
  },
  {
    "objectID": "slides/slide3.html#summary",
    "href": "slides/slide3.html#summary",
    "title": "Introduction to statistical inference",
    "section": "Summary",
    "text": "Summary\n\nHATVC - Hypothesis, Assumption, Test statistic, Verify, Conclusion\nBinomial test for testing probability of an event\nt-test for comparing means\nP-value, critical value or confidence interval for decision making\nStatistical significance is not the same as practical significance"
  },
  {
    "objectID": "slides/slide3.html#benchmark-mmlu",
    "href": "slides/slide3.html#benchmark-mmlu",
    "title": "Architecture of Large Language Models",
    "section": "Benchmark: MMLU",
    "text": "Benchmark: MMLU\n\nMeasuring Massive Multitask Language Understanding (MMLU)1 is a public benchmark containing ~16,000 multiple choice questions (4 choices) spanning 57 academic subjects.\n\n\n\nWhich three systems of the human body function together to move and control body parts?\n\nnervous, skeletal, and muscular\nmuscular, endocrine, and excretory\ndigestive, excretory, and reproductive\ncirculatory, endocrine, and respiratory\n\nCorrect answer:\n\n\n\n\nAn enhanced version MMLU-Pro2 containing 12,000 multiple choice questions (10 choices) across 14 domains with more challenging college-level problems.\n\n\nCorrect: A\n\n\nD. Hendrycks et al. (2021) Measuring Massive Multitask Language Understanding. http://arxiv.org/abs/2009.03300Y. Wang et al (2024) MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark http://arxiv.org/abs/2406.01574"
  },
  {
    "objectID": "slides/slide3.html#benchmark-musr",
    "href": "slides/slide3.html#benchmark-musr",
    "title": "Architecture of Large Language Models",
    "section": "Benchmark: MuSR",
    "text": "Benchmark: MuSR\n\nMultistep Soft Reasoning (MuSR)1: free text narratives on murder mysteries, object placements and team allocation.\n\n\nEmily took her final stroll in the park last night, forever, when her life was snuffed out under the mask of night. The cause of death was a single fatal shot from a pistol. Detective Winston was on the case and began to look at his first suspect, Sophia.\nSophia had a string of bad luck recently when someone who she thought was a friend, Emily, stole her entire inheritance. Her evening strolls in the park became franc pacing while she reconciled the fortune she lost. Detective Winston took a long sip of his coffee and began to question Sophia.\n‘Quite the marksmen I see’ - pointing to a picture of her holding a recently shot buck up.\n‘Yeah, my dad loved taking me shooting’ - Sophia replied sheepishly\n\nIdentify the killer. Killers have a motive, means, and opportunity …\n\nZ. Sprague et al. (2024) MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning. http://arxiv.org/abs/2310.16049"
  },
  {
    "objectID": "slides/slide3.html#benchmark-humaneval",
    "href": "slides/slide3.html#benchmark-humaneval",
    "title": "Architecture of Large Language Models",
    "section": "Benchmark: HumanEval",
    "text": "Benchmark: HumanEval\n\nHumanEval1 is a dataset of hand-written coding problems.\nThe evaluation of the LLM is based on the unit tests associated with the code it generates.\n\n\n\n\nExample 1\nYou will be given a string of words separated by commas or spaces. Your task is to split the string into words and return an array of the words.\nFor example:\nwords_string(“Hi, my name is John”) == [“Hi”, “my”, “name”, “is”, “John”]\nwords_string(“One, two, three, four, five, six”) == [“One”, “two”, “three”, “four”, “five”, “six”]\n\n\n\n\nExample 2\ndef is_prime(n):  \n   \"\"\"Return true if a given number is prime, and false otherwise.\n   &gt;&gt;&gt; is_prime(6) \n   False \n   &gt;&gt;&gt; is_prime(101) \n   True \n   &gt;&gt;&gt; is_prime(11) \n   True \n   &gt;&gt;&gt; is_prime(13441) \n   True \n   &gt;&gt;&gt; is_prime(61) \n   True \n   &gt;&gt;&gt; is_prime(4) \n   False \n   &gt;&gt;&gt; is_prime(1) \n   False \n   \"\"\"\n\n\n\nM. Chen et al. (2021) Evaluating Large Language Models Trained on Code. http://arxiv.org/abs/2107.03374"
  },
  {
    "objectID": "slides/slide3.html#other-evaluations",
    "href": "slides/slide3.html#other-evaluations",
    "title": "Architecture of Large Language Models",
    "section": "Other evaluations",
    "text": "Other evaluations\n\n\n\nHuman evaluation can involve:\n\nAccept/Reject of the response\nScoring the quality of the response on various aspects (e.g. answer relevancy, correctness, hallucination, responsible metrics, and so on).\nPick preferred response between two responses (reinforcement learning)\n\n\n\n\n\n\n\nMy interaction with ChatGPT on 2024-10-09\n\n\n\n\n\n\n\nLLM evaluating LLM1: e.g. Prometheus2 uses LLM to evaluate other LLMs\n\n\nL. Zheng et al. (2024) Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. Proceedings of the 37th International Conference on Neural Information Processing SystemsS. Kim et al. (2023) Prometheus: Inducing Fine-grained Evaluation Capability in Language Models. http://arxiv.org/abs/2310.08491"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Introduction to Statistics with R",
    "section": "️ Exercises",
    "text": "️ Exercises\n\n\n\n\n\n\n\n\n\n\nSimulating data from parametric distributions\n\n\nExercise 1\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "exercises/demo1.html",
    "href": "exercises/demo1.html",
    "title": "Interfacing with large language models",
    "section": "",
    "text": "This demo assumes that you have all the software requirements."
  },
  {
    "objectID": "exercises/exercise01.html",
    "href": "exercises/exercise01.html",
    "title": "Simulating data from parametric distributions",
    "section": "",
    "text": "This demo assumes that you have all the software requirements."
  },
  {
    "objectID": "slides/slide2.html#schedule",
    "href": "slides/slide2.html#schedule",
    "title": "Parametric distributions",
    "section": "Schedule*",
    "text": "Schedule*\n\n\n\nTime (AEDT)\nTopic\n\n\n\n\n1.30PM - 1.35PM\nIntroductions\n\n\n1.35PM - 3.00PM\nLandscape of Large Language Models\n\n\n\nR Demo #1 and #2\n\n\n3.00PM - 3.15PM\nBreak\n\n\n3.15PM - 4.25PM\nArchitectures of Large Language Models\n\n\n\nR Demo #3\n\n\n4.25PM - 4.45PM\nDiscussion & Conclusion\n\n\n\n\n\n*May go out of schedule"
  },
  {
    "objectID": "slides/slide2.html#normal-distribution",
    "href": "slides/slide2.html#normal-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Normal distribution",
    "text": "Normal distribution\n\nA continuous distribution that is symmetric and bell-shaped.\nThe probability density function is:\n\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{exp}\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n\n\n\nviewof mu = Inputs.number({step: 0.5, label: \"μ\", value: 0})\nviewof sd = Inputs.number({step: 0.01, label: \"σ\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX \\sim N(\\mu, \\sigma^2) where \\mu is the mean and \\sigma^2 is the variance.\nThe standard normal distribution is N(0, 1)."
  },
  {
    "objectID": "slides/slide2.html#central-limit-theorem",
    "href": "slides/slide2.html#central-limit-theorem",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "slides/slide3.html#normal-distribution",
    "href": "slides/slide3.html#normal-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Normal distribution",
    "text": "Normal distribution"
  },
  {
    "objectID": "slides/slide3.html#central-limit-theorem",
    "href": "slides/slide3.html#central-limit-theorem",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "slides/slide3.html",
    "href": "slides/slide3.html",
    "title": "Introduction to statistical inference",
    "section": "",
    "text": "• t-test • P-value • Confidence interval • Statistical significance"
  },
  {
    "objectID": "slides/slide6.html",
    "href": "slides/slide6.html",
    "title": "Modelling with categorical predictors",
    "section": "",
    "text": "• Dummy variables • Constraints and contrasts • Interpretation for categorical predictors"
  },
  {
    "objectID": "slides/slide5.html",
    "href": "slides/slide5.html",
    "title": "Modelling with continuous responses",
    "section": "",
    "text": "• Symbolic model formulae • F-test • More model diagnostics • Model interpretation"
  },
  {
    "objectID": "slides/slide2.html#coin-flips",
    "href": "slides/slide2.html#coin-flips",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Coin flips",
    "text": "Coin flips\n\nSuppose I have a coin that I’m going to flip\nTwo possible outcomes: tail  and head \nFor an unbiased coin, probability for each outcome is 0.5."
  },
  {
    "objectID": "slides/slide2.html#binary-outcomes",
    "href": "slides/slide2.html#binary-outcomes",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Binary outcomes",
    "text": "Binary outcomes\n\n\n\nFlipping a coin\n\nPossible outcomes: (A) tail  or (B) head \nFor an unbiased coin, probability for each outcome is 0.5.\n\n\n\nSingleton pregnancy in women\n\nPossible outcomes: (A) a baby boy or (B) a baby girl ignoring irregularities, intersex, etc\nProbability for each outcome is 0.5.\n\n\n\nFederal election\n\nPossible outcomes: (A) Labor party or (B) Liberal party (ignoring other parties and formation of majority or minority government)\nProbability for Labor party winning??"
  },
  {
    "objectID": "slides/slide2.html#random-binary-outcomes",
    "href": "slides/slide2.html#random-binary-outcomes",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Random binary outcomes",
    "text": "Random binary outcomes\n\n\n\nFlipping a coin\n\nPossible outcomes: (A) tail  or (B) head \nFor an unbiased coin, probability for each outcome is 0.5.\n\n\n\nSingleton pregnancy in women\n\nPossible outcomes: (A) a baby boy or (B) a baby girl ignoring irregularities, intersex, etc\nProbability for each outcome is 0.5.\n\n\n\n\nFederal election\n\nPossible outcomes: (A) Labor party or (B) Liberal party (ignoring other parties and formation of majority or minority government)\nProbability for Labor party winning??\n\n\n\nWinning a chess match\n\nPossible outcomes: (A) Win or (B) Lose\nProbability of winning depends on the skill level of the players"
  },
  {
    "objectID": "slides/slide2.html#binomial-distribution",
    "href": "slides/slide2.html#binomial-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Binomial distribution",
    "text": "Binomial distribution\n\nSuppose we have n = 30 independent Bernoulli trials with p = 0.2.\n\n\n\n\n\n\n\n\n\n\nThe sum of n independent Bernoulli random variables follows a binomial distribution.\n\n\n\n\n\n\n\n\n\n\nOr we can simulate the sum directly:"
  },
  {
    "objectID": "slides/slide2.html#benoulli-distribution",
    "href": "slides/slide2.html#benoulli-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Benoulli distribution",
    "text": "Benoulli distribution\n\nAn event with two possible outcomes: A or B\nThe probability of A is p and the probability of B is 1-p\n\n\n\n[1] 0"
  },
  {
    "objectID": "slides/slide2.html#bernoulli-distribution",
    "href": "slides/slide2.html#bernoulli-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nA random event with two possible outcomes: A or B\nThe probability of A is p and the probability of B is 1-p\nA Bernoulli trial for say p = 0.5 in  is shown below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOr we encode A = 1 and B = 0:"
  },
  {
    "objectID": "slides/slide7.html",
    "href": "slides/slide7.html",
    "title": "Modelling with categorical response",
    "section": "",
    "text": "• Logistic regression • Relative risk and odds ratio • Chi-square test"
  },
  {
    "objectID": "slides/slide2.html#bernoulli-random-variables",
    "href": "slides/slide2.html#bernoulli-random-variables",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Bernoulli random variables",
    "text": "Bernoulli random variables\n\nSuppose we have n = 30 independent Bernoulli trials with p = 0.2.\n\n\n\n\n\n\n\n\n\n\nThe sum of n independent Bernoulli random variables follows a binomial distribution."
  },
  {
    "objectID": "cheatsheet.html",
    "href": "cheatsheet.html",
    "title": "Cheatsheet",
    "section": "",
    "text": "viewof i = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"],\n  {\n    value: [\"Torgersen\", \"Biscoe\"],\n    label: \"Islands:\",\n  }\n)"
  },
  {
    "objectID": "slides/slide2.html#a-random-binary-outcome",
    "href": "slides/slide2.html#a-random-binary-outcome",
    "title": "Parametric distributions to describe and simulate data",
    "section": "A random binary outcome",
    "text": "A random binary outcome\n\n\n\nFlipping a coin\n\nPossible outcomes: (A) tail  or (B) head \nFor an unbiased coin, probability for each outcome is 0.5.\n\n\n\nSingleton pregnancy in women\n\nPossible outcomes: (A) a baby boy or (B) a baby girl ignoring irregularities, intersex, etc\nProbability for each outcome is 0.5.\n\n\n\n\nFederal election\n\nPossible outcomes: (A) Labor party or (B) Liberal party (ignoring other parties and formation of majority or minority government)\nProbability for Labor party winning??\n\n\n\nWinning a chess match\n\nPossible outcomes: (A) Win or (B) Lose\nProbability of winning depends on the skill level of the players"
  },
  {
    "objectID": "slides/slide2.html#the-number-of-successes-out-of-n-bernoulli-trials",
    "href": "slides/slide2.html#the-number-of-successes-out-of-n-bernoulli-trials",
    "title": "Parametric distributions to describe and simulate data",
    "section": "The number of successes out of n Bernoulli trials",
    "text": "The number of successes out of n Bernoulli trials\nX = X_1 + X_2 + \\cdots + X_n \\sim B(n, p)\n\nX_i \\sim \\text{Bernoulli}(p) where p is the probability of success,\nX_i = 1 if i-th trial is a success, otherwise X_i = 0,\nall the trials are independent and p is constant for all trials,\nX is the number of successes out of n trials.\n\n\n\n\nFlipping the same coin mulitple times\n\nThe number of heads out of 10 flips of a coin."
  },
  {
    "objectID": "slides/slide2.html#a-binomial-random-variable",
    "href": "slides/slide2.html#a-binomial-random-variable",
    "title": "Parametric distributions to describe and simulate data",
    "section": "A Binomial random variable",
    "text": "A Binomial random variable\nX = X_1 + X_2 + \\cdots + X_n \\sim B(n, p)\n\nX_i \\sim \\text{Bernoulli}(p) where p is the probability of success,\nX_i = 1 if i-th trial is a success, otherwise X_i = 0,\nall the trials are independent and p is constant for all trials,\nX \\in \\{0, 1, \\ldots, n\\} is the number of successes out of n trials.\n\n\n\n\n\nExpected value: E(X) = np\nVariance: \\text{Var}(X) = np(1-p)\nStandard deviation: \\text{SD}(X) = \\sqrt{np(1-p)}\n\n\n\n\nProbability mass function:\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}"
  },
  {
    "objectID": "slides/slide2.html#binomial-probability-mass-function",
    "href": "slides/slide2.html#binomial-probability-mass-function",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Binomial probability mass function",
    "text": "Binomial probability mass function\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose I flip an unbiased coin 10 times (so n = 10, p = 0.5).\nWhat is the probability that exactly 3 are heads?"
  },
  {
    "objectID": "slides/slide2.html#simulating-binomial-random-variables",
    "href": "slides/slide2.html#simulating-binomial-random-variables",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Simulating Binomial random variables",
    "text": "Simulating Binomial random variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating coin flips and count the number of heads"
  },
  {
    "objectID": "slides/slide2.html#in-silico-experiments",
    "href": "slides/slide2.html#in-silico-experiments",
    "title": "Parametric distributions to describe and simulate data",
    "section": "In-silico experiments",
    "text": "In-silico experiments\nComputer-based simulations"
  },
  {
    "objectID": "slides/slide2.html#use-in-silico-experiments-to-understand-statistics",
    "href": "slides/slide2.html#use-in-silico-experiments-to-understand-statistics",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Use in-silico experiments to understand statistics",
    "text": "Use in-silico experiments to understand statistics\n\nComputer-based simulations are “cheap”.\nUnderstand how statistics behave under known data-generating process.\n\n\n\n\nviewof n_exp = Inputs.number([5, Infinity], {step: 1, label: \"n_exp\", value: 5})\nviewof n_trials = Inputs.number([1, Infinity], {step: 1, label: \"n_trials\", value: 10})\nviewof prob = Inputs.range([0, 1], {step: 0.05, label: \"prob\", value: 0.5})"
  },
  {
    "objectID": "slides/slide2.html#a-random-continuous-variable",
    "href": "slides/slide2.html#a-random-continuous-variable",
    "title": "Parametric distributions to describe and simulate data",
    "section": "A random continuous variable",
    "text": "A random continuous variable\n\n\n\nHeights of adults\n\n\n\n\n\n\n\n\n\n\n\nYields of a sorghum variety at a location in India\n\n\n\n\n\n\n\n\n\n\n\n\nWheat flour retail prices in India, 2022 April\n\n\n\n\n\n\n\n\n\n\n\nTotal download of R packages on February 2024"
  },
  {
    "objectID": "slides/slide2.html#summary",
    "href": "slides/slide2.html#summary",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Summary",
    "text": "Summary\n\nParametric distributions can describe the distribution of data with just a handful of parameters."
  },
  {
    "objectID": "slides/slide2.html#parametric-distributions",
    "href": "slides/slide2.html#parametric-distributions",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Parametric distributions",
    "text": "Parametric distributions\n\n\n\n\n\n\n\n\n\nName\nDistribution\nDescription\nFunctions\n\n\n\n\nBernoulli\nB(1, p)\nBinary outcomes\nrbinom, dbinom, pbinom, qbinom\n\n\nBinomial\nB(n, p)\nNumber of successes in a fixed number of Bernoulli trials\nrbinom, dbinom, pbinom, qbinom\n\n\nNormal\nN(\\mu, \\sigma^2)\nContinuous distribution that is symmetric and bell-shaped\nrnorm, dnorm, pnorm, qnorm\n\n\nt-distribution\nt_d\nContinuous distribution that is symmetric and bell-shaped, but has heavier tails than the normal distribution\nrt, dt, pt, qt"
  },
  {
    "objectID": "slides/slide2.html#parametric-distributions-more",
    "href": "slides/slide2.html#parametric-distributions-more",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Parametric distributions more",
    "text": "Parametric distributions more\n\n Playing with parametric distributions\nhttps://emitanaka.org/workshop-intro-stats/games/games01.html"
  },
  {
    "objectID": "slides/slide2.html#parametric-distributions-summary",
    "href": "slides/slide2.html#parametric-distributions-summary",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Parametric distributions: summary",
    "text": "Parametric distributions: summary\n\n\n\n\n\n\n\n\n\nName\nDistribution\nDescription\nFunctions\n\n\n\n\nBernoulli\nB(1, p)\nBinary outcomes\nrbinom, dbinom, pbinom, qbinom\n\n\nBinomial\nB(n, p)\nNumber of successes in a fixed number of Bernoulli trials\nrbinom, dbinom, pbinom, qbinom\n\n\nNormal\nN(\\mu, \\sigma^2)\nContinuous distribution that is symmetric and bell-shaped\nrnorm, dnorm, pnorm, qnorm\n\n\nt-distribution\nt_d\nContinuous distribution that is symmetric and bell-shaped, but has heavier tails than the normal distribution\nrt, dt, pt, qt\n\n\n\nr - random number generation, d - density function, p - cumulative distribution function, q - quantile function"
  },
  {
    "objectID": "slides/slide2.html#t-distribution",
    "href": "slides/slide2.html#t-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "t distribution",
    "text": "t distribution\n\nThe t-distribution is a continuous distribution that is symmetric and bell-shaped, but has heavier tails than the standard normal distribution.\nThe t-distribution is used when the sample size is small and the population standard deviation is estimated from the sample.\nThe grey area is N(0, 1) for comparison.\n\n\n\n\nviewof df = Inputs.number([0, Infinity], {step: 1, label: \"degrees of freedom\", value: 1})\n\n\n\n\n\n\n\nAs the degrees of freedom increases, the t-distribution approaches the standard normal distribution."
  },
  {
    "objectID": "slides/slide2.html#why-normal-distribution",
    "href": "slides/slide2.html#why-normal-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Why normal distribution?",
    "text": "Why normal distribution?\n\nA number of distribution in nature appears to conform a normal distribution (if you ignore the fact that some values can never be negative).\n\n\nCentral limit theorem: If a random variable is the mean (or sum) of independent random values, then that value will follow a normal distribution regardless of how the individual terms are distributed."
  },
  {
    "objectID": "slides/slide2.html#probability-calculation-for-continuous-distributions",
    "href": "slides/slide2.html#probability-calculation-for-continuous-distributions",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Probability calculation for continuous distributions",
    "text": "Probability calculation for continuous distributions\n\nThe probability of a continuous random variable falling in a specific range is the area under the curve.\n\n\n\n\n\n\n\n\n\n\n\n\nP(X &lt; 2) where X \\sim N(0, 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP(X &gt; 2) where X \\sim N(1, 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP(0 &lt; X &lt; 2) where X \\sim N(0, 1)"
  },
  {
    "objectID": "slides/slide3.html#is-this-coin-unbiased",
    "href": "slides/slide3.html#is-this-coin-unbiased",
    "title": "Introduction to statistical inference",
    "section": "Is this coin unbiased?",
    "text": "Is this coin unbiased?\n\n\n\n\n\n\n\n\n\nSuppose I have a coin that I’m going to flip \nIf the coin is unbiased, what is the probability it will show heads?\nYup, the probability should be 0.5.\nSo how would I test if a coin is biased or unbiased?\nWe’ll collect some data.\nExperiment 1: I flipped the coin 10 times and this is the result:\n\n\n\n\n\nThe result is 7 head and 3 tails. So 70% are heads.\nDo you believe the coin is biased based on this data?"
  },
  {
    "objectID": "slides/slide3.html#testing-coin-bias",
    "href": "slides/slide3.html#testing-coin-bias",
    "title": "Introduction to statistical inference",
    "section": "Testing coin bias",
    "text": "Testing coin bias\n\nExperiment 2: Suppose now I flip the coin 100 times and this is the outcome:\n\n\n\nWe observe 70 heads and 30 tails. So again 70% are heads.\nBased on this data, do you think the coin is biased?"
  },
  {
    "objectID": "slides/slide3.html#frequentist-hypotheses-testing-framework",
    "href": "slides/slide3.html#frequentist-hypotheses-testing-framework",
    "title": "Introduction to statistical inference",
    "section": "(Frequentist) hypotheses testing framework",
    "text": "(Frequentist) hypotheses testing framework\n\nSuppose X is the number of heads out of n independent tosses.\nLet p be the probability of getting a head for this coin.\nHypotheses: H_0: p = 0.5 vs. H_1: p \\neq 0.5\n\nAssumptions: Each toss is independent with equal chance of getting a head.\n\nTest statistic: X \\sim B(n, p). Recall E(X) = np. The observed test statistic is denoted x.\nVerify: P-value P(\\mid X - np\\mid \\geq \\mid x - np\\mid ), critical value or confidence interval\n Conclusion: Reject null hypothesis when the p-value is less than some significance level \\alpha. Usually \\alpha = 0.05."
  },
  {
    "objectID": "slides/slide3.html#confidence-intervals",
    "href": "slides/slide3.html#confidence-intervals",
    "title": "Introduction to statistical inference",
    "section": "Confidence intervals",
    "text": "Confidence intervals"
  },
  {
    "objectID": "slides/slide3.html#judicial-system",
    "href": "slides/slide3.html#judicial-system",
    "title": "Introduction to statistical inference",
    "section": "Judicial system",
    "text": "Judicial system\n\n\n\n\n\n\n\n Evidence by test statistic\n Judgement by p-value, critical value or confidence interval"
  },
  {
    "objectID": "slides/slide3.html#experiment-1-and-2",
    "href": "slides/slide3.html#experiment-1-and-2",
    "title": "Introduction to statistical inference",
    "section": "Experiment 1 and 2",
    "text": "Experiment 1 and 2\n\n\nExperiment 1\n\nx = 7 heads, out of n = 10 tosses\nThe p-value is P(|X - 5| \\geq 2) \\approx 0.34 \n\n\n\n\n\n\n\n\n\n\nExperiment 2\n\nx = 70 heads, out of n = 100 tosses\nThe p-value is P(|X - 50| \\geq 20) \\approx 0.00008."
  },
  {
    "objectID": "slides/slide3.html#judicial-system-vs-statistical-significance",
    "href": "slides/slide3.html#judicial-system-vs-statistical-significance",
    "title": "Introduction to statistical inference",
    "section": "Judicial system vs Statistical significance",
    "text": "Judicial system vs Statistical significance\n\n\n\n\n\n\n\n\n\n\n Evidence by test statistic\n Judgement by p-value, critical value or confidence interval"
  },
  {
    "objectID": "slides/slide3.html#experimental-results",
    "href": "slides/slide3.html#experimental-results",
    "title": "Introduction to statistical inference",
    "section": "Experimental results",
    "text": "Experimental results\n\n\nExperiment 1\n\nx = 7 heads, out of n = 10 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 5| \\geq 2) \\approx 0.34\n\n\n\nExperiment 2\n\nx = 70 heads, out of n = 100 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 50| \\geq 20) \\approx 0.000079."
  },
  {
    "objectID": "slides/slide3.html#binomial-test",
    "href": "slides/slide3.html#binomial-test",
    "title": "Introduction to statistical inference",
    "section": "Binomial test",
    "text": "Binomial test\nH_0: p = 0.5 vs. H_1: p \\neq 0.5\n\n\n\nExperiment 1\n\nx = 7 heads, out of n = 10 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 5| \\geq 2) \\approx 0.34\n\n\n\nExperiment 2\n\nx = 70 heads, out of n = 100 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 50| \\geq 20) \\approx 0.000079."
  },
  {
    "objectID": "slides/slide3.html#p-values",
    "href": "slides/slide3.html#p-values",
    "title": "Introduction to statistical inference",
    "section": "P-values",
    "text": "P-values\n\n Reject null hypothesis when the p-value is less than some significance level \\alpha.\nUsually \\alpha = 0.05.\nThe p-value is the probability of observing a test statistic as extreme as the one observed, under the null hypothesis H_0.\nIf the p-value is small, it suggests that the observed data is unlikely to have occurred under the null hypothesis.\nA high p-value suggests that the observed data is consistent with the null hypothesis, it doesn’t mean that the null hypothesis is true.\n\nPopular misconception:\n\nThe p-value is not the probability that the null hypothesis is true or false.\nRemember that NHST is a test of significance, not a test of acceptance or truth."
  },
  {
    "objectID": "index.html#gamess",
    "href": "index.html#gamess",
    "title": "Introduction to Statistics with R",
    "section": "️ Gamess",
    "text": "️ Gamess\nThe games below open up an interactive dashboard for you to play around with. There is no coding required.\n\n\n\n\n\n\n\n\nPlaying with parametric distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentral limit theorem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSignificance testing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuess the correlation\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#games",
    "href": "index.html#games",
    "title": "Introduction to Statistics with R",
    "section": "️ Games",
    "text": "️ Games\nThe games below open up an interactive dashboard for you to play around with. There is no coding required so you can focus on distilling the statistical concepts.\n\n\n\n\n\n\n\n\nPlaying with parametric distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentral limit theorem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSignificance testing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuess the correlation\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/slide3.html#hatpc",
    "href": "slides/slide3.html#hatpc",
    "title": "Introduction to statistical inference",
    "section": " HATPC",
    "text": "HATPC\nHypothesis, Assumption, Test statistic, V-erify, Conclusion"
  },
  {
    "objectID": "slides/slide3.html#hatpc-hypothesis-assumption-test-statistic-p-value-conclusion",
    "href": "slides/slide3.html#hatpc-hypothesis-assumption-test-statistic-p-value-conclusion",
    "title": "Introduction to statistical inference",
    "section": "HATPC: Hypothesis, Assumption, Test statistic, P-value, Conclusion",
    "text": "HATPC: Hypothesis, Assumption, Test statistic, P-value, Conclusion"
  },
  {
    "objectID": "slides/slide3.html#hypothesis-assumption-test-statistic-p-value-conclusion",
    "href": "slides/slide3.html#hypothesis-assumption-test-statistic-p-value-conclusion",
    "title": "Introduction to statistical inference",
    "section": "Hypothesis, Assumption, Test statistic, P-value, Conclusion",
    "text": "Hypothesis, Assumption, Test statistic, P-value, Conclusion"
  },
  {
    "objectID": "slides/slide3.html#binomial-test-two-sided",
    "href": "slides/slide3.html#binomial-test-two-sided",
    "title": "Introduction to statistical inference",
    "section": "Binomial test (two-sided)",
    "text": "Binomial test (two-sided)\nH_0: p = 0.5 vs. H_1: p \\neq 0.5\nAssumption: each toss is independent with equal chance of getting a head.\n\n\n\nExperiment 1\n\nx = 7 heads, out of n = 10 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 5| \\geq 2) \\approx 0.34\n\n\n\nExperiment 2\n\nx = 70 heads, out of n = 100 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 50| \\geq 20) \\approx 0.000079."
  },
  {
    "objectID": "slides/slide3.html#null-significance-hypothesis-testing",
    "href": "slides/slide3.html#null-significance-hypothesis-testing",
    "title": "Introduction to statistical inference",
    "section": "Null significance hypothesis testing",
    "text": "Null significance hypothesis testing\n\nSuppose X is the number of heads out of n independent tosses.\nLet p be the probability of getting a head for this coin.\nHypotheses: H_0: p = 0.5 vs. H_1: p \\neq 0.5\n\nAssumptions: Each toss is independent with equal chance of getting a head.\n\nTest statistic: X \\sim B(n, p). Recall E(X) = np. The observed test statistic is denoted x.\nVerify: P-value P(\\mid X - np\\mid \\geq \\mid x - np\\mid ), critical value or confidence interval\n Conclusion: Reject null hypothesis when the p-value is less than some significance level \\alpha. Usually \\alpha = 0.05."
  },
  {
    "objectID": "slides/slide3.html#null-hypothesis-significance-testing",
    "href": "slides/slide3.html#null-hypothesis-significance-testing",
    "title": "Introduction to statistical inference",
    "section": "Null hypothesis significance testing",
    "text": "Null hypothesis significance testing\nHypothesis and Assumptions\n\nSuppose X is the number of heads out of n independent tosses.\nLet p be the probability of getting a head for this coin.\nHypotheses: H_0: p = 0.5 vs. H_1: p \\neq 0.5\n\nAssumptions: Each toss is independent with equal chance of getting a head."
  },
  {
    "objectID": "slides/slide3.html#binomial-test-one-sided",
    "href": "slides/slide3.html#binomial-test-one-sided",
    "title": "Introduction to statistical inference",
    "section": "Binomial test (one-sided)",
    "text": "Binomial test (one-sided)\nH_0: p = 0.5 vs. H_1: p &gt; 0.5\n\n\n\n\n\n\n\n\nH_0: p = 0.5 vs. H_1: p &lt; 0.5"
  },
  {
    "objectID": "slides/slide3.html#power-of-a-test",
    "href": "slides/slide3.html#power-of-a-test",
    "title": "Introduction to statistical inference",
    "section": "Power of a test",
    "text": "Power of a test\n\nThe power of a test is the probability of rejecting H_0 when H_1 is true.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor H_0: p = 0.5 vs. H_1: p \\neq 0.5, if the number of trials is 5, then it doesn’t matter what your test statistic is, the p-value is always greater than 0.05!\n\n This means that this test has zero power."
  },
  {
    "objectID": "slides/slide3.html#type-1-and-2-errors",
    "href": "slides/slide3.html#type-1-and-2-errors",
    "title": "Introduction to statistical inference",
    "section": "Type 1 and 2 errors",
    "text": "Type 1 and 2 errors\n\n\n\n\nProbability to reject H_0\nProbability to not reject H_0\n\n\n\n\nIf H_0 is true\n\\alpha\n1 - \\alpha\n\n\nIf H_1 is true\n1 - \\beta\n\\beta"
  },
  {
    "objectID": "slides/slide3.html#power-of-a-nhst",
    "href": "slides/slide3.html#power-of-a-nhst",
    "title": "Introduction to statistical inference",
    "section": "Power of a NHST",
    "text": "Power of a NHST\n\nThe power of a test is the probability of rejecting H_0 when H_1 is true.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor H_0: p = 0.5 vs. H_1: p \\neq 0.5, if the number of trials is 5, then it doesn’t matter what your test statistic is, the p-value is always greater than 0.05!\n\n This means that this test has zero power."
  },
  {
    "objectID": "slides/slide3.html#power-of-a-hypothesis-test",
    "href": "slides/slide3.html#power-of-a-hypothesis-test",
    "title": "Introduction to statistical inference",
    "section": "Power of a hypothesis test",
    "text": "Power of a hypothesis test\n\nThe power of a test is the probability of rejecting H_0 when H_1 is true.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor H_0: p = 0.5 vs. H_1: p \\neq 0.5, if the number of trials is 5, then it doesn’t matter what your test statistic is, the p-value is always greater than 0.05!\n\n This means that this test has zero power."
  },
  {
    "objectID": "slides/slide3.html#null-hypothesis-significance-testing-hypothesis-and-assumptions",
    "href": "slides/slide3.html#null-hypothesis-significance-testing-hypothesis-and-assumptions",
    "title": "Introduction to statistical inference",
    "section": "Null hypothesis significance testing: Hypothesis and Assumptions",
    "text": "Null hypothesis significance testing: Hypothesis and Assumptions\n\nSuppose X is the number of heads out of n independent tosses.\nLet p be the probability of getting a head for this coin.\nHypotheses: H_0: p = 0.5 vs. H_1: p \\neq 0.5\n\nAssumptions: Each toss is independent with equal chance of getting a head.\n\nTest statistic: X \\sim B(n, p). Recall E(X) = np. The observed test statistic is denoted x.\nVerify: P-value P(\\mid X - np\\mid \\geq \\mid x - np\\mid ), critical value or confidence interval\n Conclusion: Reject null hypothesis when the p-value is less than some significance level \\alpha. Usually \\alpha = 0.05."
  },
  {
    "objectID": "slides/slide3.html#null-hypothesis-significance-testing-1",
    "href": "slides/slide3.html#null-hypothesis-significance-testing-1",
    "title": "Introduction to statistical inference",
    "section": "Null hypothesis significance testing",
    "text": "Null hypothesis significance testing\nTest statistic, Verify and Conclusion\n\nTest statistic: X \\sim B(n, p). Recall E(X) = np. The observed test statistic is denoted x.\nVerify: P-value P(\\mid X - np\\mid \\geq \\mid x - np\\mid ), critical value or confidence interval\n Conclusion: Reject null hypothesis when the p-value is less than some significance level \\alpha. Usually \\alpha = 0.05."
  },
  {
    "objectID": "slides/slide3.html#binomial-proportion-confidence-interval",
    "href": "slides/slide3.html#binomial-proportion-confidence-interval",
    "title": "Introduction to statistical inference",
    "section": "Binomial proportion confidence interval",
    "text": "Binomial proportion confidence interval\n\nA confidence interval is a range of values that is likely to contain the true value of the parameter.\n\n\nA (two-sided) 95% confidence interval for p (using Clopper and Pearson method) is given as:\n\n\n\n\n\n\n\n\n\n\nIf H_0: p = p_0 vs H_1: p \\neq p_0 and the 100(1-\\alpha)% confidence interval contains p_0, then we fail to reject the null hypothesis at \\alpha significance level.\n\\alpha = 0.05 \\rightarrow 95% confidence interval is a common choice."
  },
  {
    "objectID": "slides/slide3.html#confidence-interval",
    "href": "slides/slide3.html#confidence-interval",
    "title": "Introduction to statistical inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nApp"
  },
  {
    "objectID": "slides/slide3.html#testing-for-the-mean",
    "href": "slides/slide3.html#testing-for-the-mean",
    "title": "Introduction to statistical inference",
    "section": "Testing for the mean",
    "text": "Testing for the mean\nH_0: \\mu = \\mu_0 vs. H_1: \\mu \\neq \\mu_0\n\n\n\nAssumptions: Population data is normally distributed, or otherwise the sample size n is large.\nTest statistic: t = \\dfrac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} \\sim t_{n-1}, where:\n\n\\bar{X} is the sample mean,\nS is the sample standard deviation,\nn is the sample size.\n\n\n\n\nVerify: P-value = P(|t| \\geq |t_{\\text{obs}}|)"
  },
  {
    "objectID": "slides/slide3.html#testing-for-the-mean-one-sample-t-test",
    "href": "slides/slide3.html#testing-for-the-mean-one-sample-t-test",
    "title": "Introduction to statistical inference",
    "section": "Testing for the mean: one-sample t-test",
    "text": "Testing for the mean: one-sample t-test\nH_0: \\mu = \\mu_0 vs. H_1: \\mu \\neq \\mu_0\nSample n times from a population with mean \\mu.\n\nAssumptions: Population data is normally distributed, or otherwise the sample size n is large.\nTest statistic: t = \\dfrac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} \\sim t_{n-1}, where:\n\n\\bar{X} is the sample mean,\nS is the sample standard deviation,\nn is the sample size."
  },
  {
    "objectID": "slides/slide3.html#p-value-one-sample-t-test",
    "href": "slides/slide3.html#p-value-one-sample-t-test",
    "title": "Introduction to statistical inference",
    "section": "P-value: one-sample t-test",
    "text": "P-value: one-sample t-test\n\nVerify: P-value = P(|t| \\geq |t_{\\text{obs}}|)"
  },
  {
    "objectID": "slides/slide3.html#one-sample-t-test-testing-for-the-mean",
    "href": "slides/slide3.html#one-sample-t-test-testing-for-the-mean",
    "title": "Introduction to statistical inference",
    "section": "One-sample t-test: testing for the mean",
    "text": "One-sample t-test: testing for the mean\nH_0: \\mu = \\mu_0 vs. H_1: \\mu \\neq \\mu_0\nSample n times from a population with mean \\mu.\n\nAssumptions: Population data is normally distributed, or otherwise the sample size n is large.\nTest statistic: t = \\dfrac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} \\sim t_{n-1}, where:\n\n\\bar{X} is the sample mean,\nS is the sample standard deviation,\nn is the sample size."
  },
  {
    "objectID": "slides/slide3.html#one-sample-t-test-p-value",
    "href": "slides/slide3.html#one-sample-t-test-p-value",
    "title": "Introduction to statistical inference",
    "section": "One-sample t-test: P-value",
    "text": "One-sample t-test: P-value\n\nVerify: P-value = P(|t| \\geq |t_{\\text{obs}}|)"
  }
]