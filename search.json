[
  {
    "objectID": "playground.html",
    "href": "playground.html",
    "title": " Playground",
    "section": "",
    "text": "This page is a playground with all R packages in the installation guide already installed. It may take a while to download all the required packages.\nThis page is only useful if your computer does not have R or you cannot install all the R packages necessary for the workshop. Otherwise, you can just run the code in your own computer."
  },
  {
    "objectID": "exercises/exercise03.html#exercise-3.1-mammal-body-and-brain-size",
    "href": "exercises/exercise03.html#exercise-3.1-mammal-body-and-brain-size",
    "title": "Simple linear regression",
    "section": "Exercise 3.1: Mammal body and brain size",
    "text": "Exercise 3.1: Mammal body and brain size\nConsider the mammal dataset which contains the body weight in kg and brain weight in grams of 62 mammals. This data is avaiable by typing mammal in this exercise consoles.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCheck your data first before modelling!\n\n\n\nExercise 3.1.1\nFirst let‚Äôs look at the numerical summary of the data. In particular, check if there are any missing values, unusual values or outliers.\n\n\n\n\n\n\n\n\n\n\n\nskimr::skim(mammal)\nskimr::skim(mammal)\n\n\n\n\n\n\n\n\nExercise 3.1.2\nNext, let‚Äôs look at the graphical summaries of the data. Create a scatter plot of brain weight against body weight.\n\n\n\n\n\n\n\n\n\n\n\nggplot(mammal) +\n  aes(body, brain) +\n  geom_point()\nggplot(mammal) +\n  aes(body, brain) +\n  geom_point()\n\n\n\n\n\n\n\n\nExercise 3.1.3\nLooks like there are a few points that have much larger body and brain weight. Let‚Äôs consider taking a log transformation for both \\(x\\) and \\(y\\) axis.\n\n\n\n\n\n\n\n\n\n\n\nggplot(mammal) +\n  aes(body, brain) +\n  geom_point() +\n  scale_y_log10() +\n  scale_x_log10()\nggplot(mammal) +\n  aes(body, brain) +\n  geom_point() +\n  scale_y_log10() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\nExercise 3.1.4\nWhat is the correlation between the log of body and the log of brain weight? Calculate using the log with base 10.\n\n\n\n\n\n\n\n\n\nThe correlation is pretty high!\n\n\ncor(log10(mammal$body), log10(mammal$brain))\ncor(log10(mammal$body), log10(mammal$brain))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3.1.5\nLet‚Äôs fit a simple linear regression model to predict brain weight from body weight and look at the summary of the model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nDid you take the log transformation of the variables?\nlm(log10(brain) ~ ______, data = mammal)\n\n\n\n\n\n\n\nfit &lt;- lm(log10(brain) ~ log10(body), data = mammal)\nsummary(fit)\nfit &lt;- lm(log10(brain) ~ log10(body), data = mammal)\nsummary(fit)\n\n\n\n\n\n\n\n\n\n\nBased on the above the fitted model is:\n\\[\\log_{10}(\\hat{\\texttt{brain}}) = 0.927 + 0.752 \\times \\log_{10}(\\texttt{body})\\] or transforming back to the original scale:\n\\[\\hat{\\texttt{brain}} = 10^{0.927 + 0.752 \\times \\log_{10}(\\texttt{body})}\\]\n\n\n\n\n\n\nExercise 3.1.6\nLet‚Äôs have a look at some model diagnostics to see if there are any issues with the model. Create some plots to assess the assumption that the errors are independently and identically normally distributed. Do you have any concerns about the model fit?\n\n\n\n\n\n\n\n\n\nThe residuals look approximately normally distributed (as indicated by the bell curve shape in the histogram and Q-Q plot). There are no noticeable trends or unusual patterns that can be seen in the residual plots.\n\n\n\n\n\n\n\n\nOkay, given that we observe no violations of the model assumptions from above, let‚Äôs proceed with some inferences from this model.\n\n\n\nExercise 3.1.7\nWhat is the 95% confidence interval for the slope of the model? You don‚Äôt need to transform the variables back to the original scale in thie exercise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCheck out what the function confint does in R.\nhelp(confint)\n\n\n\n\n\nThe 95% confidence interval for the slope is given as:\n\n\nconfint(fit, \"log10(body)\")\nconfint(fit, \"log10(body)\")\n\n\nOr alternatively, this can be extracted using the tidy function from the broom package:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3.1.8\nGiven the model from the previous exercise, predict the mean brain weight when the body weight is 100kg and its 99% confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNote that here we have to transform the predicted value to the original scale by taking the inverse function (the inverse of the \\(\\log_{10}(x)\\) functions is \\(10^x\\)). In R, the \\(10^x\\) function is given by 10^x where x is a numeric value.\n10^predict(fit, ______, interval = \"confidence\", level = 0.99)\n\n\n\n\n\nThe predicted brain weight (in g) when the body weight is 100kg is:\n\n\n10^predict(fit, newdata = data.frame(body = 100), \n           interval = \"confidence\", level = 0.99)\n10^predict(fit, newdata = data.frame(body = 100), \n           interval = \"confidence\", level = 0.99)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.1",
    "href": "exercises/exercise01.html#exercise-1.1",
    "title": "Parametric distributions",
    "section": "Exercise 1.1",
    "text": "Exercise 1.1\nTry simulating a sequence of 100 Bernoulli trials with a success probability of 0.3.\n\n\n\n\n\n\n\n\n\n\n\nrbinom(100, 1, 0.3)\nrbinom(100, 1, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nBernoulli trials are a special case of binomial trials.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nA Bernoulli trial has only one trial and the probability of success is 0.3.\nHow many trials do you want to simulate?\nrbinom(______, 1, 0.3)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.2",
    "href": "exercises/exercise01.html#exercise-1.2",
    "title": "Parametric distributions",
    "section": "Exercise 1.2",
    "text": "Exercise 1.2\nNow try generating a sequence of 20 random numbers, each representing the number of successes in 100 independent Bernoulli trials with a success probability of 0.3.\n\n\n\n\n\n\n\n\n\n\n\nrbinom(20, 100, 0.3)\nrbinom(20, 100, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe number of successes from independent Bernoulli trials follows a binomial distribution.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nThe number of Bernoulli trials is 100 for each simulation.\nHow many numbers did you want to simulate?\nrbinom(______, 100, 0.3)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.3",
    "href": "exercises/exercise01.html#exercise-1.3",
    "title": "Parametric distributions",
    "section": "Exercise 1.3",
    "text": "Exercise 1.3\nKylie Kelce is expecting a fourth baby girl. All four of her children are girls. What is the probability this occurs?\n\n\n\n\n\n\n\n\n\n\n\ndbinom(4, 4, 0.5)\ndbinom(4, 4, 0.5)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe sex of each child is independent of the others and the chance of either male or female sex is approximately 0.5.\ndbinom(______, 4, 0.5)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.4",
    "href": "exercises/exercise01.html#exercise-1.4",
    "title": "Parametric distributions",
    "section": "Exercise 1.4",
    "text": "Exercise 1.4\nI have 40 plants each with a 0.8 probability of surviving in a given environment. What is the probability that equal to or more than 30 plants would survive in this environment?\n\n\n\n\n\n\n\n\n\n\n\n1 - pbinom(29, 40, 0.8)\n1 - pbinom(29, 40, 0.8)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember that the converse of greater than or equal to 30 is less than or equal to 29 if we are only considering integers.\n1 - pbinom(______, 40, 0.8)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.5",
    "href": "exercises/exercise01.html#exercise-1.5",
    "title": "Parametric distributions",
    "section": "Exercise 1.5",
    "text": "Exercise 1.5\nAn adult height is typically about 1.75m with standard deviation of 7cm for males in Australia. Gough Whitlam was 1.94m in height. What is the probability that a random Australian male is taller than Gough Whitlam?\n\n\n\n\n\n\n\n\n\n\n\n1 - pnorm(194, 175, 7)\n1 - pnorm(194, 175, 7)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember that the mean and standard deviation should have the same unit of measurement.\n1 - pnorm(194, ______, 7)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.6",
    "href": "exercises/exercise01.html#exercise-1.6",
    "title": "Parametric distributions",
    "section": "Exercise 1.6",
    "text": "Exercise 1.6\nIn a population of a particular species of fish, the length of the fish is normally distributed with a mean of 175mm and a standard deviation of 7mm. Simulate a scenario were twenty fish were caught and measured. What proportion of fishes were longer than 194mm?\nHow does the proportion compare to the answer in Exercise 5?\n\n\n\n\n\n\n\n\n\nNotice that the this scenario is similar to Exercise 5, except the proportion is calculated from a finite sample, whereas the previous exercise was calculated considering the distribution in the population.\n\n\nfish_lengths &lt;- rnorm(20, 175, 7)\nmean(fish_lengths &gt; 194)\nfish_lengths &lt;- rnorm(20, 175, 7)\nmean(fish_lengths &gt; 194)"
  },
  {
    "objectID": "exercises/exercise01.html#exercise-1.7",
    "href": "exercises/exercise01.html#exercise-1.7",
    "title": "Parametric distributions",
    "section": "Exercise 1.7",
    "text": "Exercise 1.7\nFor this exericse, the dplyr and ggplot2 packages have been loaded.\n\n\n\n\n\n\n\n\nThe sugarcane data cotains 2,056 observations of sugarcane yield from a uniformity trial. This sugarcane data is also already loaded in the exercise environment with a glimpse of the data below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a histogram of the yield variable with 30 bins but show the \\(y\\)-axis as a density instead of counts.\n\n\n\n\n\n\n\n\n\n\n\nggplot(sugarcane, aes(x = yield)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, color = \"white\") \nggplot(sugarcane, aes(x = yield)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, color = \"white\") \n\n\n\n\n\n\nEstimate the mean and standard deviation of the yield variable.\n\n\n\n\n\n\n\n\n\n\n\nsugarcane |&gt; \n  summarise(mean = mean(yield), sd = sd(yield))\nsugarcane |&gt; \n  summarise(mean = mean(yield), sd = sd(yield))\n\n\n\n\n\n\nAssuming that the yield is normally distributed with the mean and standard deviation estimated from the data, try plotting this estimated density onto the histogram with 30 bins.\n\n\n\n\n\n\n\n\n\n\n\nggplot(sugarcane, aes(x = yield)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 30, \n                 color = \"white\") +\n  geom_function(fun = \\(x) dnorm(x, \n                                 mean(sugarcane$yield),\n                                 sd(sugarcane$yield)),\n                color = \"red\", linewidth = 1.5)\nggplot(sugarcane, aes(x = yield)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 30, \n                 color = \"white\") +\n  geom_function(fun = \\(x) dnorm(x, \n                                 mean(sugarcane$yield),\n                                 sd(sugarcane$yield)),\n                color = \"red\", linewidth = 1.5)"
  },
  {
    "objectID": "exercises/exercise04.html#exercise-1",
    "href": "exercises/exercise04.html#exercise-1",
    "title": "Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nDoes brain weight for different mammal species depend on body weight?\nTo answer this question the following questions use the following data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrbinom(100, 1, 0.3)\nrbinom(100, 1, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nBernoulli trials are a special case of binomial trials.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nA Bernoulli trial has only one trial and the probability of success is 0.3.\nHow many trials do you want to simulate?\nrbinom(______, 1, 0.3)"
  },
  {
    "objectID": "slides/slidex.html#data-dreging",
    "href": "slides/slidex.html#data-dreging",
    "title": "Wrap-up",
    "section": "Data dreging",
    "text": "Data dreging\n Source: xkcd"
  },
  {
    "objectID": "slides/slidex.html#resources",
    "href": "slides/slidex.html#resources",
    "title": "Wrap-up",
    "section": "Resources",
    "text": "Resources\n\nWelham et al (2015) Statistical Methods in Biology: Design and Analysis of Experiments and Regression. CRC Press.\nWhitlock and Schluter (2015) The Analysis of Biological Data. W. H. Freeman and Company. 2nd edition.\nFaraday (2009) Linear Models with R. CRC Press."
  },
  {
    "objectID": "slides/slide4.html#crop-yield-due-to-nitrogen-and-rainfall",
    "href": "slides/slide4.html#crop-yield-due-to-nitrogen-and-rainfall",
    "title": "Modelling with continuous responses",
    "section": " Crop yield due to nitrogen and rainfall",
    "text": "Crop yield due to nitrogen and rainfall\n\n\n\n\n\n\n\n\n\n\n\n200 randomly selected farms planted with the same wheat variety in a particular region recorded:\n\nthe average nitrogen content in their soil (kg/ha) and\nthe total amount of rainfall (mm) they received in a particular year.\n\nThe yield of wheat (tonnes/ha) was recorded for each farmer."
  },
  {
    "objectID": "slides/slide4.html#exploring-multivariate-or-multivariable-data",
    "href": "slides/slide4.html#exploring-multivariate-or-multivariable-data",
    "title": "Modelling with continuous responses",
    "section": "Exploring multivariate or multivariable data",
    "text": "Exploring multivariate or multivariable data\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate data: multiple dependent variables.\nMultivariable data: multiple independent variables.\nWhat is independent and dependent variable can be context specific.\nIn this example, we know yield is dependent on nitrogen and rainfall so we have a multivariable data."
  },
  {
    "objectID": "slides/slide4.html#quadratic-function",
    "href": "slides/slide4.html#quadratic-function",
    "title": "Modelling with continuous responses",
    "section": "Quadratic function",
    "text": "Quadratic function\n\nThe quadratic function is a polynomial function of order 2 with the form:\n\ny = f(x) = a + b x + c x^2\n\n\n\n\nviewof a = Inputs.number({step: 0.1, value: 2, label: \"a\"})\nviewof b = Inputs.number({step: 0.1, value: 0, label: \"b\"})\nviewof c = Inputs.number({step: 0.1, value: 1, label: \"c\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny =  +  x +  x^2"
  },
  {
    "objectID": "slides/slide4.html#fitting-multiple-linear-regression-model-in-r",
    "href": "slides/slide4.html#fitting-multiple-linear-regression-model-in-r",
    "title": "Modelling with continuous responses",
    "section": "Fitting multiple linear regression model in R",
    "text": "Fitting multiple linear regression model in R\nAssuming that x1 and x2 are numerical variables, the following model\n\n\nlm(y ~ 1 + x1 + x2 + I(x2^2))\n\n is equivalent to fitting the model: \n\ny_i = \\beta_01 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_2^2 + \\epsilon_i,\n\n\n\nassuming \\epsilon_i \\sim NID(0, \\sigma^2)\n\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2, \\beta_3)^\\top are the coefficients to be estimated.\nI() is used to indicate that x2^2 is taken as-is as another variable.\nNotice the one-to-one correspondence between the symbolic model formula and the mathematical model."
  },
  {
    "objectID": "slides/slide4.html#goodness-of-fit-measures-for-the-additive-model",
    "href": "slides/slide4.html#goodness-of-fit-measures-for-the-additive-model",
    "title": "Modelling with continuous responses",
    "section": "Goodness-of-fit measures for the additive model",
    "text": "Goodness-of-fit measures for the additive model\n\n\n\n\n\n\n\n\n\n\n\nR^2, also called the coefficient of determination, is the proportion of the variance in the dependent variable that is explained by the independent variables.\nR^2 increases as the number of predictors in the model increases.\nThe adjusted R^2 is a modified version of R^2 that adjusts for the number of predictors in the model.\nR^2 is between 0 and 1, where 1 indicates a perfect fit."
  },
  {
    "objectID": "slides/slide4.html#model-diagnostic-for-m1",
    "href": "slides/slide4.html#model-diagnostic-for-m1",
    "title": "Modelling with continuous responses",
    "section": "Model diagnostic for M1",
    "text": "Model diagnostic for M1"
  },
  {
    "objectID": "slides/slide4.html#interaction-plot",
    "href": "slides/slide4.html#interaction-plot",
    "title": "Modelling with continuous responses",
    "section": "Interaction plot",
    "text": "Interaction plot\n\n\n\n\n\n\n\n\n\n\n\nThe lines crossover slightly suggesting there may be some weak interaction effect between nitrogen and rainfall."
  },
  {
    "objectID": "slides/slide4.html#fitting-interaction-effects-in-r",
    "href": "slides/slide4.html#fitting-interaction-effects-in-r",
    "title": "Modelling with continuous responses",
    "section": "Fitting interaction effects in R",
    "text": "Fitting interaction effects in R\nAssuming that x1 and x2 are numerical variables, the following model\n\n\nlm(y ~ 1 + x1 + x2 + I(x2^2) + x1:x2 + x1:I(x2^2))\n\n is equivalent to fitting the model: \n\ny_i = \\beta_01 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_2^2 + \\beta_4 x_1x_2 + \\beta_5 x_1x_2^2 + \\epsilon_i,\n\n\n\nassuming \\epsilon_i \\sim NID(0, \\sigma^2)\n\\beta_1, \\beta_2 and \\beta_3 are referred to as the main effects.\n\\beta_4 and \\beta_5 are the interaction effects."
  },
  {
    "objectID": "slides/slide4.html#symbolic-model-formula",
    "href": "slides/slide4.html#symbolic-model-formula",
    "title": "Modelling with continuous responses",
    "section": "Symbolic model formula",
    "text": "Symbolic model formula\n\nIntercept included by default: y ~ 1 + x1 + x2 is equivalent to y ~ x1 + x2.\nRemoving intercept: y ~ 0 + x1 + x2 and y ~ -1 + x1 + x2 both remove the intercept term in the model.\nMain and interaction effects: y ~ x1 * x2 is equivalent to y ~ x1 + x2 + x1:x2.y ~ x1 * x2 * x3 is equivalent to ¬†¬†¬†¬†¬†¬†y ~ x1 + x2 + x3 + x1:x2 + x1:x2 + x2:x3 + x1:x2:x3.\nMain effects and two-way interaction effects only: y ~ (x1 + x2 + x3)^2 and y ~ x1 * x2 * x3 - x1:x2:x3 is equivalent to ¬†¬†¬†¬†¬†¬†y ~ x1 + x2 + x3 + x1:x2 + x1:x2 + x2:x3."
  },
  {
    "objectID": "slides/slide4.html#two-models-side-by-side",
    "href": "slides/slide4.html#two-models-side-by-side",
    "title": "Modelling with continuous responses",
    "section": "Two models side by side",
    "text": "Two models side by side\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Additive\n                Interaction\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.27271\n                  2.41624\n                \n                \n                  \n                  (0.52169)\n                  (1.26400)\n                \n                \n                  nitrogen\n                  0.07151\n                  0.03161\n                \n                \n                  \n                  (0.00263)\n                  (0.01063)\n                \n                \n                  rainfall\n                  0.05435\n                  0.04358\n                \n                \n                  \n                  (0.00216)\n                  (0.00649)\n                \n                \n                  I(rainfall^2)\n                  -0.00005\n                  -0.00005\n                \n                \n                  \n                  (0.00000)\n                  (0.00001)\n                \n                \n                  nitrogen √ó rainfall\n                  \n                  0.00008\n                \n                \n                  \n                  \n                  (0.00006)\n                \n                \n                  nitrogen √ó I(rainfall^2)\n                  \n                  0.00000\n                \n                \n                  \n                  \n                  (0.00000)\n                \n                \n                  Num.Obs.\n                  200\n                  200\n                \n                \n                  R2\n                  0.881\n                  0.918\n                \n                \n                  R2 Adj.\n                  0.879\n                  0.916\n                \n                \n                  AIC\n                  652.4\n                  580.7\n                \n                \n                  BIC\n                  668.9\n                  603.8\n                \n                \n                  Log.Lik.\n                  -321.208\n                  -283.339\n                \n                \n                  F\n                  482.714\n                  436.509\n                \n                \n                  RMSE\n                  1.21\n                  1.00"
  },
  {
    "objectID": "slides/slide4.html#model-diagnostics-for-m2",
    "href": "slides/slide4.html#model-diagnostics-for-m2",
    "title": "Modelling with continuous responses",
    "section": "Model diagnostics for M2",
    "text": "Model diagnostics for M2"
  },
  {
    "objectID": "slides/slide4.html#comparing-to-a-nested-model-using-the-f-test",
    "href": "slides/slide4.html#comparing-to-a-nested-model-using-the-f-test",
    "title": "Modelling with continuous responses",
    "section": "Comparing to a nested model using the F-test",
    "text": "Comparing to a nested model using the F-test\n\nM1: \\texttt{yield}_i = \\beta_0 + \\beta_1 \\texttt{nitrogen}_i + \\beta_2 \\texttt{rainfall}_i + \\beta_3 \\texttt{rainfall}_i^2 + \\epsilon_i  M2: \\texttt{yield}_i = \\beta_0 + \\beta_1 \\texttt{nitrogen}_i + \\beta_2 \\texttt{rainfall}_i + \\beta_3 \\texttt{rainfall}_i^2 + \\beta_4 \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i + \\qquad\\qquad\\qquad\\qquad\\beta_5 \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i^2 + \\epsilon_i\n\nHypotheses:\nH_0: \\beta_4 = \\beta_5 = 0 (equivalent to M1) H_A: At least one of \\beta_4 or \\beta_5 is not equal to 0"
  },
  {
    "objectID": "slides/slide4.html#comparing-models-using-aic-or-bic",
    "href": "slides/slide4.html#comparing-models-using-aic-or-bic",
    "title": "Modelling with continuous responses",
    "section": "Comparing models using AIC or BIC",
    "text": "Comparing models using AIC or BIC\n\n\n\nIf the models are not nested, we can use AIC or BIC to compare models.\nLower AIC or BIC indicates a better model.\nAIC penalizes model complexity with a penalty term of 2p where p is the number of regression parameters.\nBIC penalizes model complexity with a penalty term of p\\log_e(n) where n is the number of observations.\n\n\nAIC is better for prediction purposes, while BIC is better for explanation (usually results in a simpler model)."
  },
  {
    "objectID": "slides/slide4.html#model-interpretation",
    "href": "slides/slide4.html#model-interpretation",
    "title": "Modelling with continuous responses",
    "section": "Model interpretation",
    "text": "Model interpretation\n\nM2: \\hat{\\texttt{yield}}_i = 2.41624 + 0.03161\\times \\texttt{nitrogen}_i + 0.04358\\times \\texttt{rainfall}_i -0.00005\\times \\texttt{rainfall}_i^2 +\\qquad\\qquad\\qquad\\qquad0.00008\\times \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i +0.00000\\times \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i^2"
  },
  {
    "objectID": "slides/slide4.html#data-generating-process-for-crop-yield",
    "href": "slides/slide4.html#data-generating-process-for-crop-yield",
    "title": "Modelling with continuous responses",
    "section": " Data generating process for crop yield",
    "text": "Data generating process for crop yield\n\n\n\n\n\n\n\n\n\nM2: \\hat{\\texttt{yield}}_i = 2.41624 + 0.03161\\times \\texttt{nitrogen}_i + 0.04358\\times \\texttt{rainfall}_i -0.00005\\times \\texttt{rainfall}_i^2 +\\qquad\\qquad\\qquad\\qquad0.00008\\times \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i +0.00000\\times \\texttt{nitrogen}_i \\times \\texttt{rainfall}_i^2"
  },
  {
    "objectID": "slides/slide4.html#multicollinearity",
    "href": "slides/slide4.html#multicollinearity",
    "title": "Modelling with continuous responses",
    "section": "Multicollinearity",
    "text": "Multicollinearity"
  },
  {
    "objectID": "slides/slide4.html#summary",
    "href": "slides/slide4.html#summary",
    "title": "Modelling with continuous responses",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/slide3.html#case-study-seed-weight-from-seed-length",
    "href": "slides/slide3.html#case-study-seed-weight-from-seed-length",
    "title": "Simple linear regression",
    "section": "Case study  Seed weight from seed length",
    "text": "Case study  Seed weight from seed length\n\n\n\nSeed length is expected to be a major contributor to differences in seed weight for wheat.\n190 seeds selected at random from a line of diploid wheat, Triticum monococcum for length and weight.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData source: Welham et al.¬†(2015) Statistical Methods in Biology: Design and Analysis of Experiments and Regression."
  },
  {
    "objectID": "slides/slide3.html#correlation-coefficient",
    "href": "slides/slide3.html#correlation-coefficient",
    "title": "Simple linear regression",
    "section": "Correlation coefficient",
    "text": "Correlation coefficient\n\nThe sample Pearson correlation coefficient, denoted as r, is a measure of the strength of a linear relationship between two variables (x and y).\n\nr = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2\\sum_{i=1}^n(y_i - \\bar{y})^2}}\n\nThe correlation coefficient ranges from -1 to 1."
  },
  {
    "objectID": "slides/slide3.html#interpretation-of-correlation-coefficient",
    "href": "slides/slide3.html#interpretation-of-correlation-coefficient",
    "title": "Simple linear regression",
    "section": "Interpretation of correlation coefficient",
    "text": "Interpretation of correlation coefficient\n\n\n\nThe sign of the correlation coefficient indicates the direction of the relationship.\n\n\n\n\n|r|\nInterpretation\n\n\n\n\n0.8 - 1.0\nVery strong association\n\n\n0.6 - 0.8\nStrong association\n\n\n0.4 - 0.6\nModerate association\n\n\n0.2 - 0.4\nWeak association\n\n\n0.0 - 0.2\nVery weak association\n\n\n\n\n\n\nviewof nsample = Inputs.number([20, 1000], {step: 20, value: 200, label: \"Number of samples\"})\nviewof r = Inputs.range([-1,1], {step: 0.05, value: 0.8, label: \"Correlation coefficient\"})"
  },
  {
    "objectID": "slides/slide3.html#wrong-interpretation-of-correlation-coefficient",
    "href": "slides/slide3.html#wrong-interpretation-of-correlation-coefficient",
    "title": "Simple linear regression",
    "section": "Wrong interpretation of correlation coefficient",
    "text": "Wrong interpretation of correlation coefficient\n\n\n Source: xkcd\n\nCorrelation doesn‚Äôt provide the direction of the relationship.\nWe cannot say just because x and y are highly correlated, x causes y or vice versa ‚Äì correlation is not causation!\n\n\n\nCorrelation also only measures a linear relationship, so low correlation doesn‚Äôt mean that there is no relationship.\n\n\n\n\n\n\n\n\n\n\nCorrelation coefficient: -0.0217634"
  },
  {
    "objectID": "slides/slide3.html#summary-statistics-can-be-misleading",
    "href": "slides/slide3.html#summary-statistics-can-be-misleading",
    "title": "Simple linear regression",
    "section": "Summary statistics can be misleading",
    "text": "Summary statistics can be misleading\n\n\n\nYou can have a bivariate data with the exact same marginal mean, variance and correlation but the relationship between the two variables can be very different.\nAlways plot your data!"
  },
  {
    "objectID": "slides/slide3.html#simple-linear-regression",
    "href": "slides/slide3.html#simple-linear-regression",
    "title": "Simple linear regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nWe seek to model the relationship between:\n\nthe mean of a response variable, y, and\na single explanatory variable (or predictor/covariate) x.\n\nFor observations i = 1, 2, \\ldots, n:\n\n\ny_i  = \\beta_0 + \\beta_1x_i + \\epsilon_i\n\n\n\n\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1\\end{bmatrix} are referred to as the regression parameters/coefficients.\n\nintercept slope error for the i-th observation, and assume \\epsilon_i \\sim NID(0, \\sigma^2), i.e.¬†normally and independently distributed with mean 0 and variance \\sigma^2."
  },
  {
    "objectID": "slides/slide3.html#least-squares-estimates",
    "href": "slides/slide3.html#least-squares-estimates",
    "title": "Simple linear regression",
    "section": "Least Squares Estimates",
    "text": "Least Squares Estimates\n\n\n\n\n\n\n\n\n\n\n\n\nFind \\hat \\beta_0 and \\hat \\beta_1 that minimize the sum of squares:\n\n\\text{RSS}(\\beta_0, \\beta_1) = \\sum_{i=1}^n \\left(y_i - (\\beta_0 + \\beta_1 x_i)\\right)^2\n\nThe least squares estimates can be found by using calculus.\nVisually, we can try changing the regression parameters below:\n\n\nviewof intercept_1 = Inputs.number({step: 0.1, value: -27.9, label: \"Œ≤ÃÇ‚ÇÄ\"})\nviewof slope_1 = Inputs.number({step: 0.1, value: 17.2, label: \"Œ≤ÃÇ1\"})"
  },
  {
    "objectID": "slides/slide3.html#fitting-linear-models-in-r",
    "href": "slides/slide3.html#fitting-linear-models-in-r",
    "title": "Simple linear regression",
    "section": "Fitting linear models in R",
    "text": "Fitting linear models in R\n\\texttt{Weight}_i=\\beta_0 + \\beta_1\\texttt{Length}_i + e_i\n\n\n\n\n\n\n\n\n\nThe least square estimates are: \\hat{\\beta}_0 = -27.93 and \\hat{\\beta}_1 = 17.17."
  },
  {
    "objectID": "slides/slide3.html#fitted-values",
    "href": "slides/slide3.html#fitted-values",
    "title": "Simple linear regression",
    "section": "Fitted values",
    "text": "Fitted values\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe fitted values are the red points given as:\n\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i."
  },
  {
    "objectID": "slides/slide3.html#predicted-values",
    "href": "slides/slide3.html#predicted-values",
    "title": "Simple linear regression",
    "section": "Predicted values",
    "text": "Predicted values\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe response can be predicted from the fitted model for a given x as:\n\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x."
  },
  {
    "objectID": "slides/slide3.html#making-inferences",
    "href": "slides/slide3.html#making-inferences",
    "title": "Simple linear regression",
    "section": "Making inferences",
    "text": "Making inferences\n\n\nThe standard deviation of an estimator is referred to as the standard error.\nIn making inferences, you may like to know:\n\nwhat is the standard error of \\hat{\\beta}_1?\nis \\beta_1 \\neq 0?\nwhat is the confidence interval of the average y for a given x?\nwhat is the prediction interval of y for a given x?\n\n It‚Äôs important to note that making inferences require the assumptions of the linear regression model to be satisfied.\nSo check model assumptions first!"
  },
  {
    "objectID": "slides/slide3.html#assumptions-for-linear-regression",
    "href": "slides/slide3.html#assumptions-for-linear-regression",
    "title": "Simple linear regression",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\nRecall for i=1,\\ldots,n, \\epsilon_i \\sim NID(0,\\sigma^2) which means:\n\n(A1) \\text{E}(\\epsilon_i) = 0\n(A2) \\epsilon_1, \\ldots ,\\epsilon_n are independent.\n(A3) \\text{Var}(\\epsilon_i) = \\sigma^2 which is called the homoscedasticity assumption.\n(A4) \\epsilon_1, \\ldots ,\\epsilon_n are normally distributed\n(A5) the predictors are known without error.\n\n\n\n\nAn unbiased estimate of \\sigma is given by:"
  },
  {
    "objectID": "slides/slide3.html#checking-assumptions",
    "href": "slides/slide3.html#checking-assumptions",
    "title": "Simple linear regression",
    "section": "Checking assumptions",
    "text": "Checking assumptions\n\nA1 is satisfied by definition for the least squares estimates.\n\n\n\n\n\n\n\n\n\n\n\nA2 and A3 can be checked by plotting the residuals against the fitted values and ensuring that there is no pattern or trends.\n\n\n\n\n\n\n\n\n\n\n\n\nAlso checked by plotting the residuals against the predictor(s).\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes plotting the residuals against the order of data entry can also be useful in identifying potential violations of A2.\n\n\n\n\n\n\n\n\n\n\n\n\nA4 can be checked by plotting the normal quantile-quantile plot of the residuals. If it roughly straight then A4 is satisfied.\n\n\n\n\n\n\n\n\n\n\nThere are no standard ways to check A5 easily."
  },
  {
    "objectID": "slides/slide3.html#influence-measures",
    "href": "slides/slide3.html#influence-measures",
    "title": "Simple linear regression",
    "section": "Influence measures",
    "text": "Influence measures\n\nThe data may contain outliers, high leverage values, and other unusual values that can affect the regression model.\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs check the ‚Äúinfluential‚Äù observations:\n\n\n\n\n\n\n\n\n\n\n\n\nRed points are the observations to scrutinize further."
  },
  {
    "objectID": "slides/slide3.html#box-cox-transformation",
    "href": "slides/slide3.html#box-cox-transformation",
    "title": "Simple linear regression",
    "section": "Box cox transformation",
    "text": "Box cox transformation\n\n\n\nBox-cox transformation modifies the response for a given value of \\lambda such that:\n\ny(\\lambda) = \\begin{cases} \\frac{y^{\\lambda} - 1}{\\lambda} & \\text{if } \\lambda \\neq 0, \\\\ \\log(y) & \\text{if } \\lambda = 0. \\end{cases}\n\n\nThe transformation is equivalent to:\n\n\n\n\n\\lambda\nTransformation\n\n\n\n\n2\ny^2\n\n\n1\ny\n\n\n0.5\n\\sqrt{y}\n\n\n0\n\\log(y)\n\n\n-0.5\n\\sqrt{y}\n\n\n-1\n\\frac{1}{y}\n\n\n-2\n\\frac{1}{y^2}"
  },
  {
    "objectID": "slides/slide3.html#selecting-lambda-for-box-cox-transformation",
    "href": "slides/slide3.html#selecting-lambda-for-box-cox-transformation",
    "title": "Simple linear regression",
    "section": "Selecting \\lambda for box-cox transformation",
    "text": "Selecting \\lambda for box-cox transformation\n\n\n\n\n\n\n\n\n\n\nProfile log-likelihood plot suggests \\lambda \\approx 0.5 which is equivalent to taking the square root of the response."
  },
  {
    "objectID": "slides/slide3.html#transforming-the-response",
    "href": "slides/slide3.html#transforming-the-response",
    "title": "Simple linear regression",
    "section": "Transforming the response",
    "text": "Transforming the response\n\n\n\n\n\n\n\n\n\n\nRemember the fitted or predicted value need to be squared to get the original scale."
  },
  {
    "objectID": "slides/slide3.html#quick-diagnostic-plots",
    "href": "slides/slide3.html#quick-diagnostic-plots",
    "title": "Simple linear regression",
    "section": "Quick diagnostic plots",
    "text": "Quick diagnostic plots\n\nAn easy way to generate some of the diagnostic plots at once is to use the ggResidpanel package.\n\n\n\n\n\n\n\n\n\n\n\nBut the QQ-plot still doesn‚Äôt look good enough??"
  },
  {
    "objectID": "slides/slide3.html#visual-inference",
    "href": "slides/slide3.html#visual-inference",
    "title": "Simple linear regression",
    "section": "Visual inference",
    "text": "Visual inference\n\nWhen making inference from plots, it‚Äôs best to calibrate the plot with simulations.\nLet‚Äôs assume that \\sqrt{\\texttt{Weight}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\texttt{Length} + \\epsilon, where \\epsilon \\sim N(0, \\hat{\\sigma}^2) is the correct model.\nThen simulate from this model 9 times:\n\n\n\n\n\n\n\n\n\n\nThen let‚Äôs look at the QQ-plot of the residuals from the simulated data:"
  },
  {
    "objectID": "slides/slide3.html#hypothesis-testing-for-regression-parameters",
    "href": "slides/slide3.html#hypothesis-testing-for-regression-parameters",
    "title": "Simple linear regression",
    "section": "Hypothesis testing for regression parameters",
    "text": "Hypothesis testing for regression parameters\n\nSource: xkcd\n\nConsider testing if the j-th regression parameter is significant for j = 1, \\ldots, p = 2:\n\nH_0: \\beta_j = 0 \\quad \\text{vs} \\quad H_A: \\beta_j \\neq 0\n\nAssumption: suppose the residuals are normally distributed.\nThe test statistic and its distribution is\n\n\\dfrac{\\hat{\\beta}_j - \\beta_j}{\\text{SE}(\\hat{\\beta}_j)} \\sim t_{n-p}."
  },
  {
    "objectID": "slides/slide3.html#confidence-interval-for-regression-parameters",
    "href": "slides/slide3.html#confidence-interval-for-regression-parameters",
    "title": "Simple linear regression",
    "section": "Confidence interval for regression parameters",
    "text": "Confidence interval for regression parameters\n\nThe 100(1-\\alpha)\\% confidence interval for the j-th regression parameter is\n\n\\hat{\\beta}_j \\pm t_{n-p, 1-\\alpha/2} \\times \\text{SE}(\\hat{\\beta}_j).\n\nFor \\alpha = 0.05, the 95% confidence interval for the regression parameters are:"
  },
  {
    "objectID": "slides/slide3.html#confidence-interval-and-prediction-interval",
    "href": "slides/slide3.html#confidence-interval-and-prediction-interval",
    "title": "Simple linear regression",
    "section": "Confidence interval and prediction interval",
    "text": "Confidence interval and prediction interval\n\nThe 95% confidence interval for the mean response at x = 5 is\n\n\n\n\n\n\n\n\n\n\nThe 95% prediction interval for the response at x = 5 is\n\n\n\n\n\n\n\n\n\n\nThe prediction interval is always wider as it considers the uncertainty in the response as well."
  },
  {
    "objectID": "slides/slide3.html#functions-for-model-object",
    "href": "slides/slide3.html#functions-for-model-object",
    "title": "Simple linear regression",
    "section": " Functions for model object",
    "text": "Functions for model object\n\nGetting the model summary:\n\n\n\n\n\n\n\n\n\n\nGetting just the regression coefficient estimates\n\n\n\n\n\n\n\n\n\n\nGetting the regression coefficient table in the model summary as a tibble:\n\n\n\n\n\n\n\n\n\n\nGetting the fit_sqrtted values \\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i:\n\n\n\n\n\n\n\n\n\n\nGetting the residuals (y_i - \\hat{y}_i):\n\n\n\n\n\n\n\n\n\n\nAugment the data with fit_sqrtted values, residuals, etc:\n\n\n\n\n\n\n\n\n\n\nGetting the deviance (residual sum of squares):\n\n\n\n\n\n\n\n\n\n\nThe estimate of the error standard deviation \\hat{\\sigma}:\n\n\n\n\n\n\n\n\n\n\nGetting a single numerical summaries about the model (e.g.¬†coefficient of determination, adjusted R^2, AIC, BIC, etc):\n\n\n\n\n\n\n\n\n\n\nGetting the influence measures and find which observations are influential:\n\n\n\n\n\n\n\n\n\n\nSelecting \\lambda for box-cox transformation:\n\n\n\n\n\n\n\n\n\n\nQuick diagnostic plots:"
  },
  {
    "objectID": "slides/slide0.html#workshop-website",
    "href": "slides/slide0.html#workshop-website",
    "title": "Introductions",
    "section": "Workshop Website",
    "text": "Workshop Website"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Statistics with R",
    "section": "",
    "text": "Optimal viewing experience\n\n\n\nPlease note that this website is best viewed using desktop or laptop computers using Google Chrome."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Introduction to Statistics with R",
    "section": "",
    "text": "Optimal viewing experience\n\n\n\nPlease note that this website is best viewed using desktop or laptop computers using Google Chrome."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Introduction to Statistics with R",
    "section": "üéØ Learning objectives",
    "text": "üéØ Learning objectives"
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Introduction to Statistics with R",
    "section": "üîß Software requirements",
    "text": "üîß Software requirements\nPlease ensure that you have:\n\na computer or laptop with a stable (and preferably fast) internet connection, and\na modern web browser like Google Chrome.\n\nIn this workshop, all R code and exercises are run in the browser using Quarto live. As such, you don‚Äôt need to install R or any R packages to participate in this workshop. But should you wish to know use the R packages used, these include:\nc('tidyverse', 'ggdist', 'ggbeeswarm', 'broom', 'patchwork', 'GGally', 'ggpubr',\n  'emmeans', 'modelsummary', 'ggResidpanel', 'agridat', 'faraway', 'abd')"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Introduction to Statistics with R",
    "section": "üïú Schedule",
    "text": "üïú Schedule\n\n\n\n\n\nDay\nPerth\nBrisbane\nAdelaide\nAEDT\nContent\n\n\n\n\nTue\n08:00am\n10:00am\n10:30am\n11:00am\nIntroductions\n\n\n\n08:10am\n10:10am\n10:40am\n11:10am\nParametric distributions to describe and simulate data\n\n\n\n09:30am\n11:30am\n12:00pm\n12:30pm\nBreak\n\n\n\n10:30am\n12:30pm\n01:00pm\n01:30pm\nIntroduction to statistical inference\n\n\n\n12:00pm\n02:00pm\n02:30pm\n03:00pm\nBreak\n\n\n\n12:15pm\n02:15pm\n02:45pm\n03:15pm\nSimple linear regression\n\n\nWed\n08:00am\n10:00am\n10:30am\n11:00am\nModelling with continuous responses\n\n\n\n09:30am\n11:30am\n12:00pm\n12:30pm\nBreak\n\n\n\n10:30am\n12:30pm\n01:00pm\n01:30pm\nModelling with categorical predictors\n\n\n\n12:00pm\n02:00pm\n02:30pm\n03:00pm\nBreak\n\n\n\n12:15pm\n02:15pm\n02:45pm\n03:15pm\nModelling with categorical response\n\n\n\n01:35pm\n03:35pm\n04:05pm\n04:35pm\nWrap-up"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Introduction to Statistics with R",
    "section": "üìö Slides",
    "text": "üìö Slides\n\n\n\n\n\n\n\n\n\n\nIntroductions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParametric distributions to describe and simulate data\n\n\nSlide 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to statistical inference\n\n\nSlide 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple linear regression\n\n\nSlide 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with continuous responses\n\n\nSlide 4\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical predictors\n\n\nSlide 5\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical response\n\n\nSlide 6\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrap-up\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Introduction to Statistics with R",
    "section": "Ô∏è Exercises",
    "text": "Ô∏è Exercises\n\n\n\n\n\n\n\n\n\n\nParametric distributions\n\n\nExercise 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical inference\n\n\nExercise 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple linear regression\n\n\nExercise 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple linear regression\n\n\nExercise 4\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical variables\n\n\nExercise 5\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelling with categorical responses\n\n\nExercise 6\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#games",
    "href": "index.html#games",
    "title": "Introduction to Statistics with R",
    "section": "Ô∏è Games",
    "text": "Ô∏è Games\nThe games below open up an interactive dashboard for you to play around with. There is no coding required so you can focus on distilling the statistical concepts.\n\n\n\n\n\n\n\n\nPlaying with parametric distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentral limit theorem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSignificance testing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind the line of best fit with visual inspection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuess the correlation\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#sec-license",
    "href": "index.html#sec-license",
    "title": "Introduction to Statistics with R",
    "section": " License",
    "text": "License\nThese  workshop materials by Emi Tanaka is licensed under CC BY-NC-ND 4.0 ‚Äì which means you can share the link with your colleagues, peers, friends, family and so on, so long as due credit is given to the author. However, you cannot commercialise or create derivatives from this work without the permission of the author (emi.tanaka@anu.edu.au)."
  },
  {
    "objectID": "slides/slide1.html#distribution-of-data",
    "href": "slides/slide1.html#distribution-of-data",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Distribution of data",
    "text": "Distribution of data\n\nThe distribution of data can tells about the frequency of a range of values.\n\n\n\nFor discrete data, we can use a barplot to visualise the distribution.\n\n\n\n\n\n\n\n\n\n\nFor continuous data, we can use a histogram or density plot to visualise the distribution.\n\n\n\n\n\n\n\n\n\n\nviewof nbins = Inputs.number([5, 100], {step: 1, label: \"Number of bins for histogram\", value: 30})\n\n\n\n\n\n\n\n\n The number of bins does affect the histogram appearance, so explore different values to see how it changes the plot."
  },
  {
    "objectID": "slides/slide1.html#parametric-distributions",
    "href": "slides/slide1.html#parametric-distributions",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Parametric distributions",
    "text": "Parametric distributions\n\nParametric distribution are defined by just a handful of parameters.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBernoulli distribution\n\nviewof p2 = Inputs.range([0, 1], {step: 0.01, label: \"p\", value: 0.5})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial distribution\n\nviewof n = Inputs.number([1, Infinity], {step: 1, label: \"n\", value: 10})\nviewof p = Inputs.range([0, 1], {step: 0.01, label: \"p\", value: 0.5})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson distribution\n\nviewof lambda = Inputs.number([0, Infinity], {step: 0.1, label: \"Œª\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNegative binomial distribution\n\nviewof nbsize = Inputs.number([1, Infinity], {step: 1, label: \"n\", value: 10})\nviewof nbprob = Inputs.range([0, 1], {step: 0.01, label: \"p\", value: 0.5})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormal distribution\n\nviewof mu2 = Inputs.number({step: 0.5, label: \"Œº\", value: 0})\nviewof sd2 = Inputs.number({step: 0.01, label: \"œÉ\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt distribution\n\nviewof df2 = Inputs.number([0, Infinity], {step: 1, label: \"degrees of freedom\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniform distribution\n\nviewof xmin = Inputs.number({step: 0.1, label: \"min\", value: 0})\nviewof xmax = Inputs.number({step: 0.1, label: \"max\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGamma distribution\n\nviewof shape = Inputs.number({step: 0.1, label: \"shape\", value: 1})\nviewof rate = Inputs.number({step: 0.1, label: \"rate\", value: 1})"
  },
  {
    "objectID": "slides/slide1.html#binary-events-in-the-wild",
    "href": "slides/slide1.html#binary-events-in-the-wild",
    "title": "Parametric distributions to describe and simulate data",
    "section": " Binary events in the wild",
    "text": "Binary events in the wild\n\n\n\nFlipping a coin ü™ô\n\nPossible outcomes: (A) tail  or (B) head \nFor an unbiased coin, probability for each outcome is 0.5.\n\n\n\nSingleton pregnancy in women ü§∞\n\nPossible outcomes: (A) a baby girl üëß or (B) a baby boy üë¶ ignoring miscarriages, irregularities, intersex, etc\nProbability for each outcome is 0.5.\n\n\n\n\nAustralian Federal election üá¶üá∫\n\nPossible outcomes: (A) Labor party üî¥ or (B) Liberal party üîµ (ignoring other parties and formation of majority or minority government)\nProbability for Labor party winning??\n\n\n\nWinning a chess match ‚ôüÔ∏è\n\nPossible outcomes: (A) Win üèÜ or (B) Lose ‚ùå\nProbability of winning depends on the skill level of the players"
  },
  {
    "objectID": "slides/slide1.html#bernoulli-distribution",
    "href": "slides/slide1.html#bernoulli-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\n\nA random event with two possible outcomes: A or B.\nThe probability of A is p and the probability of B is 1-p.\n\n\n\n\nA Bernoulli trial for say p = 0.5 in  is shown below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOr we encode A = 1 and B = 0:"
  },
  {
    "objectID": "slides/slide1.html#binomial-distribution",
    "href": "slides/slide1.html#binomial-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Binomial distribution",
    "text": "Binomial distribution\n\nSuppose we have n = 30 independent Bernoulli trials with p = 0.2.\n\n\n\n\n\n\n\n\n\n\n\n\nThe number of ‚Äúsuccesses‚Äù out of n independent Bernoulli trials with probability of success, p, follows a binomial distribution with parameters n and p.\n\n\n\n\n\n\n\n\n\n\n\n\n\nOr we can simulate the sum directly:"
  },
  {
    "objectID": "slides/slide1.html#a-binomial-random-variable",
    "href": "slides/slide1.html#a-binomial-random-variable",
    "title": "Parametric distributions to describe and simulate data",
    "section": "A Binomial random variable",
    "text": "A Binomial random variable\nX = X_1 + X_2 + \\cdots + X_n \\sim B(n, p)\n\nX_i \\sim \\text{Bernoulli}(p) where p is the probability of success,\nX_i = 1 if i-th trial is a success, otherwise X_i = 0,\nall the trials are independent and p is constant for all trials,\nX \\in \\{0, 1, \\ldots, n\\} is the number of successes out of n trials.\n\n\n\n\n\nExpected value: E(X) = np\nVariance: \\text{Var}(X) = np(1-p)\nStandard deviation: \\text{SD}(X) = \\sqrt{np(1-p)}\n\n\n\n\nProbability mass function:\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}"
  },
  {
    "objectID": "slides/slide1.html#binomial-probability-and-distribution-function",
    "href": "slides/slide1.html#binomial-probability-and-distribution-function",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Binomial probability and distribution function",
    "text": "Binomial probability and distribution function\n\nSuppose I flip an unbiased coin 10 times (so n = 10, p = 0.5).\n\n\nWhat is the probability that exactly 3 are heads?\n\n\n\n\n\n\n\n\n\n\n\nWhat is the probability that there are 3 or less heads?\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the probability that there are 3 or more heads?"
  },
  {
    "objectID": "slides/slide1.html#simulating-binomial-random-variables",
    "href": "slides/slide1.html#simulating-binomial-random-variables",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Simulating Binomial random variables",
    "text": "Simulating Binomial random variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating coin flips and count the number of heads"
  },
  {
    "objectID": "slides/slide1.html#use-in-silico-experiments-to-understand-statistics",
    "href": "slides/slide1.html#use-in-silico-experiments-to-understand-statistics",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Use in-silico experiments to understand statistics",
    "text": "Use in-silico experiments to understand statistics\n\nComputer-based simulations are ‚Äúcheap‚Äù.\nUnderstand how statistics behave under known data-generating process.\n\n\n\n\nviewof n_exp = Inputs.number([5, Infinity], {step: 1, label: \"n_exp\", value: 5})\nviewof n_trials = Inputs.number([1, Infinity], {step: 1, label: \"n_trials\", value: 10})\nviewof prob = Inputs.range([0, 1], {step: 0.05, label: \"prob\", value: 0.5})"
  },
  {
    "objectID": "slides/slide1.html#continuous-data-in-the-wild",
    "href": "slides/slide1.html#continuous-data-in-the-wild",
    "title": "Parametric distributions to describe and simulate data",
    "section": " Continuous data in the wild",
    "text": "Continuous data in the wild\n\n\n\nHeights of adults\n\n\n\n\n\n\n\n\n\n\n\nYields of a sorghum variety at a location in India\n\n\n\n\n\n\n\n\n\n\n\n\nWheat flour retail prices in India, 2022 April\n\n\n\n\n\n\n\n\n\n\n\nTotal download of R packages on February 2024"
  },
  {
    "objectID": "slides/slide1.html#normal-distribution",
    "href": "slides/slide1.html#normal-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Normal distribution",
    "text": "Normal distribution\n\n\nA continuous distribution that is symmetric and bell-shaped.\nThe probability density function is:\n\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{exp}\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n\n\n\n\nX \\sim N(\\mu, \\sigma^2) where\n\nE(X) = \\mu is the mean/expected value and\n\\text{Var}(X) = \\sigma^2 is the variance.\n\nThe standard normal distribution is N(0, 1).\n\n\n\n\nviewof mu = Inputs.number({step: 0.5, label: \"Œº\", value: 0})\nviewof sd = Inputs.number({step: 0.5, label: \"œÉ\", value: 1})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTotal area under the curve = 1."
  },
  {
    "objectID": "slides/slide1.html#probability-calculation-for-continuous-distributions",
    "href": "slides/slide1.html#probability-calculation-for-continuous-distributions",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Probability calculation for continuous distributions",
    "text": "Probability calculation for continuous distributions\n\nThe probability of a continuous random variable falling in a specific range is the area under the curve.\n\n\n\n\n\n\n\n\n\n\n\n\nP(X &lt; 2) where X \\sim N(0, 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP(X &gt; 2) where X \\sim N(1, 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP(0 &lt; X &lt; 2) where X \\sim N(0, 1)"
  },
  {
    "objectID": "slides/slide1.html#fitting-a-normal-distribution-to-data",
    "href": "slides/slide1.html#fitting-a-normal-distribution-to-data",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Fitting a normal distribution to data",
    "text": "Fitting a normal distribution to data\n\n Yields of a sorghum variety at a location in India\n\n\n\n\n\n\n\n\n\n\n\n\nVisualise a normal distribution fitted to the data:\n\n\n\n\n\n\n\n\n\n\n\n\nCalculate the probability of a yield being greater than 1.5 tolas per plot:"
  },
  {
    "objectID": "slides/slide1.html#t-distribution",
    "href": "slides/slide1.html#t-distribution",
    "title": "Parametric distributions to describe and simulate data",
    "section": "t distribution",
    "text": "t distribution\n Source: xkcd\n\nThe t-distribution is a continuous distribution that is symmetric and bell-shaped, but has heavier tails than the standard normal distribution.\nThe t-distribution is used when the sample size is small and the population standard deviation is estimated from the sample.\nThe grey area is N(0, 1) for comparison.\n\n\n\n\n\nviewof df = Inputs.number([0, Infinity], {step: 1, label: \"degrees of freedom\", value: 1})\n\n\n\n\n\n\n\n\nAs the degrees of freedom increases, the t-distribution approaches the standard normal distribution."
  },
  {
    "objectID": "slides/slide1.html#summary-of-parametric-distributions",
    "href": "slides/slide1.html#summary-of-parametric-distributions",
    "title": "Parametric distributions to describe and simulate data",
    "section": "Summary of Parametric distributions",
    "text": "Summary of Parametric distributions\n\n\n\n\n\n\n\n\n\nName\nDistribution\nDescription\nFunctions\n\n\n\n\nBernoulli\nB(1, p)\nBinary outcomes\nrbinom, dbinom, pbinom, qbinom\n\n\nBinomial\nB(n, p)\nNumber of successes in a fixed number of Bernoulli trials\nrbinom, dbinom, pbinom, qbinom\n\n\nNormal\nN(\\mu, \\sigma^2)\nContinuous distribution that is symmetric and bell-shaped\nrnorm, dnorm, pnorm, qnorm\n\n\nt-distribution\nt_d\nContinuous distribution that is symmetric and bell-shaped, but has heavier tails than the normal distribution\nrt, dt, pt, qt\n\n\n\nr - random number generation, d - density function, p - cumulative distribution function, q - quantile function"
  },
  {
    "objectID": "slides/slide2.html#is-this-coin-unbiased",
    "href": "slides/slide2.html#is-this-coin-unbiased",
    "title": "Introduction to statistical inference",
    "section": "Is this coin unbiased?",
    "text": "Is this coin unbiased?\n\n\n\n\n\n\n\n\n\nSuppose I have a coin that I‚Äôm going to flip \nIf the coin is unbiased, what is the probability it will show heads?\nYup, the probability should be 0.5.\nSo how would I test if a coin is biased or unbiased?\nWe‚Äôll collect some data.\nExperiment 1: I flipped the coin 10 times and this is the result:\n\n\n\n\n\nThe result is 7 head and 3 tails. So 70% are heads.\nDo you believe the coin is biased based on this data?"
  },
  {
    "objectID": "slides/slide2.html#testing-coin-bias",
    "href": "slides/slide2.html#testing-coin-bias",
    "title": "Introduction to statistical inference",
    "section": "Testing coin bias",
    "text": "Testing coin bias\n\nExperiment 2: Suppose now I flip the coin 100 times and this is the outcome:\n\n\n\nWe observe 70 heads and 30 tails. So again 70% are heads.\nBased on this data, do you think the coin is biased?"
  },
  {
    "objectID": "slides/slide2.html#null-hypothesis-significance-testing",
    "href": "slides/slide2.html#null-hypothesis-significance-testing",
    "title": "Introduction to statistical inference",
    "section": "Null hypothesis significance testing",
    "text": "Null hypothesis significance testing\nHypothesis and Assumptions\n\nSuppose X is the number of heads out of n independent tosses.\nLet p be the probability of getting a head for this coin.\nHypotheses: H_0: p = 0.5 vs.¬†H_A: p \\neq 0.5\n\nAssumptions: Each toss is independent with equal chance of getting a head."
  },
  {
    "objectID": "slides/slide2.html#null-hypothesis-significance-testing-1",
    "href": "slides/slide2.html#null-hypothesis-significance-testing-1",
    "title": "Introduction to statistical inference",
    "section": "Null hypothesis significance testing",
    "text": "Null hypothesis significance testing\nTest statistic, Verify and Conclusion\n\nTest statistic: X \\sim B(n, p). Recall E(X) = np. The observed test statistic is denoted x.\nVerify: P-value P(\\mid X - np\\mid \\geq \\mid x - np\\mid ), critical value or confidence interval\n Conclusion: Reject null hypothesis when the p-value is less than some significance level \\alpha. Usually \\alpha = 0.05."
  },
  {
    "objectID": "slides/slide2.html#hatpc",
    "href": "slides/slide2.html#hatpc",
    "title": "Introduction to statistical inference",
    "section": " HATPC",
    "text": "HATPC\nHypothesis, Assumption, Test statistic, V-erify, Conclusion"
  },
  {
    "objectID": "slides/slide2.html#binomial-test-two-sided",
    "href": "slides/slide2.html#binomial-test-two-sided",
    "title": "Introduction to statistical inference",
    "section": "Binomial test (two-sided)",
    "text": "Binomial test (two-sided)\nH_0: p = 0.5 vs.¬†H_A: p \\neq 0.5\nAssumption: each toss is independent with equal chance of getting a head.\n\n\n\nExperiment 1\n\nx = 7 heads, out of n = 10 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 5| \\geq 2) \\approx 0.34\n\n\n\nExperiment 2\n\nx = 70 heads, out of n = 100 tosses\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is P(|X - 50| \\geq 20) \\approx 0.000079."
  },
  {
    "objectID": "slides/slide2.html#binomial-test-one-sided",
    "href": "slides/slide2.html#binomial-test-one-sided",
    "title": "Introduction to statistical inference",
    "section": "Binomial test (one-sided)",
    "text": "Binomial test (one-sided)\nH_0: p = 0.5 vs.¬†H_A: p &gt; 0.5\n\n\n\n\n\n\n\n\nH_0: p = 0.5 vs.¬†H_A: p &lt; 0.5"
  },
  {
    "objectID": "slides/slide2.html#p-values",
    "href": "slides/slide2.html#p-values",
    "title": "Introduction to statistical inference",
    "section": "P-values",
    "text": "P-values\n\n Reject null hypothesis when the p-value is less than some significance level \\alpha.\nUsually \\alpha = 0.05.\nThe p-value is the probability of observing a test statistic as extreme as the one observed, under the null hypothesis H_0.\nIf the p-value is small, it suggests that the observed data is unlikely to have occurred under the null hypothesis.\nA high p-value suggests that the observed data is consistent with the null hypothesis, it doesn‚Äôt mean that the null hypothesis is true.\n\nPopular misconception:\n\nThe p-value is not the probability that the null hypothesis is true or false.\nRemember that NHST is a test of significance, not a test of acceptance or truth."
  },
  {
    "objectID": "slides/slide2.html#binomial-proportion-confidence-interval",
    "href": "slides/slide2.html#binomial-proportion-confidence-interval",
    "title": "Introduction to statistical inference",
    "section": "Binomial proportion confidence interval",
    "text": "Binomial proportion confidence interval\n\nA confidence interval is a range of values that is likely to contain the true value of the parameter.\n\n\nA (two-sided) 95% confidence interval for p (using Clopper and Pearson method) is given as:\n\n\n\n\n\n\n\n\n\n\nIf H_0: p = p_0 vs H_A: p \\neq p_0 and the 100(1-\\alpha)% confidence interval contains p_0, then we fail to reject the null hypothesis at \\alpha significance level.\n\\alpha = 0.05 \\rightarrow 95% confidence interval is a common choice."
  },
  {
    "objectID": "slides/slide2.html#power-of-a-hypothesis-test",
    "href": "slides/slide2.html#power-of-a-hypothesis-test",
    "title": "Introduction to statistical inference",
    "section": "Power of a hypothesis test",
    "text": "Power of a hypothesis test\n\nThe power of a test is the probability of rejecting H_0 when H_A is true.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor H_0: p = 0.5 vs.¬†H_A: p \\neq 0.5, if the number of trials is 5, then it doesn‚Äôt matter what your test statistic is, the p-value is always greater than 0.05!\n\n This means that this test has zero power."
  },
  {
    "objectID": "slides/slide2.html#judicial-system-vs-statistical-significance",
    "href": "slides/slide2.html#judicial-system-vs-statistical-significance",
    "title": "Introduction to statistical inference",
    "section": "Judicial system vs Statistical significance",
    "text": "Judicial system vs Statistical significance\n\n\n\n\n\n\n\n\n\n\n Evidence by test statistic\n Judgement by p-value, critical value or confidence interval"
  },
  {
    "objectID": "slides/slide2.html#type-1-and-2-errors",
    "href": "slides/slide2.html#type-1-and-2-errors",
    "title": "Introduction to statistical inference",
    "section": "Type 1 and 2 errors",
    "text": "Type 1 and 2 errors\n\n\n\n\nProbability to reject H_0\nProbability to not reject H_0\n\n\n\n\nIf H_0 is true\n\\alpha\n1 - \\alpha\n\n\nIf H_A is true\n1 - \\beta\n\\beta"
  },
  {
    "objectID": "slides/slide2.html#one-sample-t-test-testing-for-the-mean",
    "href": "slides/slide2.html#one-sample-t-test-testing-for-the-mean",
    "title": "Introduction to statistical inference",
    "section": "One-sample t-test: testing for the mean",
    "text": "One-sample t-test: testing for the mean\nH_0: \\mu = \\mu_0 vs.¬†H_A: \\mu \\neq \\mu_0\nSample n times from a population with mean \\mu.\n\nAssumptions: Population data is normally distributed, or otherwise the sample size n is large.\nTest statistic: t = \\dfrac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} \\sim t_{n-1}, where:\n\n\\bar{X} is the sample mean,\nS is the sample standard deviation,\nn is the sample size."
  },
  {
    "objectID": "slides/slide2.html#one-sample-t-test-p-value",
    "href": "slides/slide2.html#one-sample-t-test-p-value",
    "title": "Introduction to statistical inference",
    "section": "One-sample t-test: P-value",
    "text": "One-sample t-test: P-value\n\nVerify: P-value = P(|t| \\geq |t^*|)"
  },
  {
    "objectID": "slides/slide2.html#two-sample-t-test-testing-for-the-difference-in-means",
    "href": "slides/slide2.html#two-sample-t-test-testing-for-the-difference-in-means",
    "title": "Introduction to statistical inference",
    "section": "Two-sample t-test: testing for the difference in means",
    "text": "Two-sample t-test: testing for the difference in means\n\nSample n_1 times from population 1 with mean \\mu_1.\nSample n_2 times from population 2 with mean \\mu_2.\nSampling from populations 1 and 2 should be independent.\n\nH_0: \\mu_1 = \\mu_2 vs.¬†H_A: \\mu_1 \\neq \\mu_2\n\nAssumptions: Both populations are normally distributed (or sample sizes n_1 and n_2 are sufficiently large).\nTest statistic: t = \\dfrac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\dfrac{S_1^2}{n_1} + \\dfrac{S_2^2}{n_2}}} \\sim t_{n_1 + n_2 - 2}, where:\n\n\\bar{X}_i and S_i are the sample mean and standard deviation, respectively, of population i.\n\nVerify: P-value = P(|t| \\geq |t^*|)"
  },
  {
    "objectID": "slides/slide2.html#paired-t-test-testing-for-the-difference-in-means",
    "href": "slides/slide2.html#paired-t-test-testing-for-the-difference-in-means",
    "title": "Introduction to statistical inference",
    "section": "Paired t-test: testing for the difference in means",
    "text": "Paired t-test: testing for the difference in means\n\nSample n times from a population with observation pairs.\nd_i = X_{1i} - X_{2i} is the difference between the two observations in pair i. H_0: \\mu_1 = \\mu_2 vs.¬†H_A: \\mu_1 \\neq \\mu_2 H_0: \\mu_d = 0 vs.¬†H_A: \\mu_d \\neq 0"
  },
  {
    "objectID": "slides/slide2.html#multiple-testing",
    "href": "slides/slide2.html#multiple-testing",
    "title": "Introduction to statistical inference",
    "section": "Multiple testing",
    "text": "Multiple testing\n Source: xkcd"
  },
  {
    "objectID": "slides/slide2.html#summary",
    "href": "slides/slide2.html#summary",
    "title": "Introduction to statistical inference",
    "section": "Summary",
    "text": "Summary\n\nHATVC - Hypothesis, Assumption, Test statistic, Verify, Conclusion\nBinomial test for testing probability of an event\nt-test for comparing means\nP-value, critical value or confidence interval for decision making\nStatistical significance is not the same as practical significance"
  },
  {
    "objectID": "slides/slide6.html#hello",
    "href": "slides/slide6.html#hello",
    "title": "Modelling with categorical response",
    "section": "Hello",
    "text": "Hello"
  },
  {
    "objectID": "slides/slide6.html#summary",
    "href": "slides/slide6.html#summary",
    "title": "Modelling with categorical response",
    "section": "Summary",
    "text": "Summary\n‚Ä¢ Logistic regression ‚Ä¢ Relative risk and odds ratio ‚Ä¢ Chi-square test"
  },
  {
    "objectID": "slides/slide5.html#options",
    "href": "slides/slide5.html#options",
    "title": "Modelling with categorical predictors",
    "section": "Options",
    "text": "Options"
  },
  {
    "objectID": "slides/slide5.html#summary",
    "href": "slides/slide5.html#summary",
    "title": "Modelling with categorical predictors",
    "section": "Summary",
    "text": "Summary\n\nDummy variables\nConstraints and contrasts\nInterpretation for categorical predictors"
  },
  {
    "objectID": "exercises/exercise06.html#exercise-1",
    "href": "exercises/exercise06.html#exercise-1",
    "title": "Modelling with categorical responses",
    "section": "Exercise 1",
    "text": "Exercise 1\nTry simulating a sequence of 100 Bernoulli trials with a success probability of 0.3.\n\n\n\n\n\n\n\n\n\n\n\nrbinom(100, 1, 0.3)\nrbinom(100, 1, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nBernoulli trials are a special case of binomial trials.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nA Bernoulli trial has only one trial and the probability of success is 0.3.\nHow many trials do you want to simulate?\nrbinom(______, 1, 0.3)"
  },
  {
    "objectID": "exercises/exercise05.html#exercise-1",
    "href": "exercises/exercise05.html#exercise-1",
    "title": "Modelling with categorical variables",
    "section": "Exercise 1",
    "text": "Exercise 1\nTry simulating a sequence of 100 Bernoulli trials with a success probability of 0.3.\n\n\n\n\n\n\n\n\n\n\n\nrbinom(100, 1, 0.3)\nrbinom(100, 1, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nBernoulli trials are a special case of binomial trials.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nA Bernoulli trial has only one trial and the probability of success is 0.3.\nHow many trials do you want to simulate?\nrbinom(______, 1, 0.3)"
  },
  {
    "objectID": "exercises/exercise02.html#exercise-2.1",
    "href": "exercises/exercise02.html#exercise-2.1",
    "title": "Statistical inference",
    "section": "Exercise 2.1",
    "text": "Exercise 2.1\nTry simulating a sequence of 100 Bernoulli trials with a success probability of 0.3.\n\n\n\n\n\n\n\n\n\n\n\nrbinom(100, 1, 0.3)\nrbinom(100, 1, 0.3)\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nBernoulli trials are a special case of binomial trials.\nrbinom(______)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nA Bernoulli trial has only one trial and the probability of success is 0.3.\nHow many trials do you want to simulate?\nrbinom(______, 1, 0.3)"
  },
  {
    "objectID": "cheatsheet.html",
    "href": "cheatsheet.html",
    "title": "Cheatsheet",
    "section": "",
    "text": "Name\nDensity function\nDistribution function\nQuantile function\nRandom number generator\n\n\n\n\nBinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\nNormal\ndnorm\npnorm\nqnorm\nrnorm\n\n\nStudent‚Äôs t\ndt\npt\nqt\nrt\n\n\nUniform\ndunif\npunif\nqunif\nrunif\n\n\nF\ndf\npf\nqf\nrf\n\n\nChi-squared\ndchisq\npchisq\nqchisq\nrchisq"
  },
  {
    "objectID": "cheatsheet.html#parametric-distributions",
    "href": "cheatsheet.html#parametric-distributions",
    "title": "Cheatsheet",
    "section": "",
    "text": "Name\nDensity function\nDistribution function\nQuantile function\nRandom number generator\n\n\n\n\nBinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\nNormal\ndnorm\npnorm\nqnorm\nrnorm\n\n\nStudent‚Äôs t\ndt\npt\nqt\nrt\n\n\nUniform\ndunif\npunif\nqunif\nrunif\n\n\nF\ndf\npf\nqf\nrf\n\n\nChi-squared\ndchisq\npchisq\nqchisq\nrchisq"
  },
  {
    "objectID": "cheatsheet.html#statistical-inference",
    "href": "cheatsheet.html#statistical-inference",
    "title": "Cheatsheet",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nFor Binomial proportions\nFor x observed number of successes and n number of trials:\n\nbinom.test(x, n, p = 0.5, alternative = \"two.sided\")$p.value\nbinom.test(x, n, conf.level = 0.95)$conf.int\n\n\n\nFor means\n\nOne-sample\n\nt.test(x, mu = 0, alternative = \"two.sided\")$p.value\nt.test(x, mu = 0, conf.level = 0.95)$conf.int\n\n\n\nTwo-sample\n\nt.test(x, y, alternative = \"two.sided\")$p.value\nt.test(x, y, conf.level = 0.95)$conf.int\nt.test(x, y, var.equal = FALSE) # unequal variance (default)\nt.test(x, y, var.equal = TRUE) # equal variance\n\n\n\nPaired\n\nt.test(x - y, alternative = \"two.sided\")\nt.test(x, y, alternative = \"two.sided\", paired = TRUE)"
  },
  {
    "objectID": "cheatsheet.html#exploring-multivariate-data",
    "href": "cheatsheet.html#exploring-multivariate-data",
    "title": "Cheatsheet",
    "section": "Exploring multivariate data",
    "text": "Exploring multivariate data\n\nres &lt;- correlation::correlation(data)\nsummary(res)\nplot(res)\nplot(summary(res))\nGGally::ggpairs(data)"
  },
  {
    "objectID": "cheatsheet.html#linear-regression",
    "href": "cheatsheet.html#linear-regression",
    "title": "Cheatsheet",
    "section": "Linear regression",
    "text": "Linear regression\n\nx1 and x2 are continuous variables\nf1 and f2 are factors\ny is the response variable\ndata is a data frame with all of the above variables\n\n\nModel fit, summary, and diagnostics\n\nfit &lt;- lm(y ~ x1 + x2 + x1:x2, data = data)\n\n\ncoef(fit)\nfitted(fit)\nresiduals(fit)\ndeviance(fit)\nsigma(fit)\nsummary(fit)\ncooks.distance(fit)\ninfluence.measures(fit)\ninfluence(fit)\nconfint(fit)\npredict(fit, newdata = newdata, interval = \"confidence\", level = 0.95)\n\nA tidy approach:\n\nbroom::tidy(fit, conf.int = TRUE, conf.level = 0.95)\nbroom::glance(fit)\nbroom::augment(fit, newdata = newdata, se.fit = TRUE, interval = \"confidence\", conf.level = 0.95)\nggResidpanel::resid_panel(fit)\n\n\n\nANOVA (regression with categorical predictors)\n\nfit1 &lt;- lm(y ~ f1 + f2 + f1:f2, data = data)\nanova(fit1)\nfit2 &lt;- aov(y ~ f1 + f2 + f1:f2, data = data)\nsummary(fit2)\nemm &lt;- emmmeans::emmeans(fit1, \"f1\")\npairs(emm)\nplot(emm)\n\n\n\nChi-square test\n\nchisq.test(table(x))\n\nM &lt;- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))\ndimnames(M) &lt;- list(gender = c(\"F\", \"M\"),\n                    party = c(\"Democrat\",\"Independent\", \"Republican\"))\n(Xsq &lt;- chisq.test(M))  # Prints test summary\nXsq$observed   # observed counts (same as M)\nXsq$expected   # expected counts under the null\nXsq$residuals  # Pearson residuals\nXsq$stdres     # standardized residuals\n\n\n\nLogistic regression\n\nfit &lt;- glm(y ~ x1 + x2 + x1:x2, data = data, family = binomial)"
  },
  {
    "objectID": "cheatsheet.html#reporting-results",
    "href": "cheatsheet.html#reporting-results",
    "title": "Cheatsheet",
    "section": "Reporting results",
    "text": "Reporting results\n\nmodelsummary::datasummary((mean + sd) * len ~ factor(dose)* supp, data = ToothGrowth)\nmodelsummary::modelsummary(fit)\nmodelsummary::modelplot(fit)\nmodelsummary::modelsummary(list(\"M1\" = fit1, \"M2\" = fit2))"
  }
]